{
    "url": "https://api.github.com/repos/rapidsai/cudf/issues/12039",
    "repository_url": "https://api.github.com/repos/rapidsai/cudf",
    "labels_url": "https://api.github.com/repos/rapidsai/cudf/issues/12039/labels{/name}",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/12039/comments",
    "events_url": "https://api.github.com/repos/rapidsai/cudf/issues/12039/events",
    "html_url": "https://github.com/rapidsai/cudf/issues/12039",
    "id": 1431846296,
    "node_id": "I_kwDOBWUGps5VWD2Y",
    "number": 12039,
    "title": "[ENH/QST]: Behaviour of type promotion in `__setitem__`",
    "user": {
        "login": "wence-",
        "id": 1126981,
        "node_id": "MDQ6VXNlcjExMjY5ODE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1126981?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/wence-",
        "html_url": "https://github.com/wence-",
        "followers_url": "https://api.github.com/users/wence-/followers",
        "following_url": "https://api.github.com/users/wence-/following{/other_user}",
        "gists_url": "https://api.github.com/users/wence-/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/wence-/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/wence-/subscriptions",
        "organizations_url": "https://api.github.com/users/wence-/orgs",
        "repos_url": "https://api.github.com/users/wence-/repos",
        "events_url": "https://api.github.com/users/wence-/events{/privacy}",
        "received_events_url": "https://api.github.com/users/wence-/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 599626561,
            "node_id": "MDU6TGFiZWw1OTk2MjY1NjE=",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        },
        {
            "id": 599626564,
            "node_id": "MDU6TGFiZWw1OTk2MjY1NjQ=",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/question",
            "name": "question",
            "color": "D4C5F9",
            "default": true,
            "description": "Further information is requested"
        },
        {
            "id": 1013987503,
            "node_id": "MDU6TGFiZWwxMDEzOTg3NTAz",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/2%20-%20In%20Progress",
            "name": "2 - In Progress",
            "color": "fef2c0",
            "default": false,
            "description": "Currently a work in progress"
        },
        {
            "id": 1013987921,
            "node_id": "MDU6TGFiZWwxMDEzOTg3OTIx",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/proposal",
            "name": "proposal",
            "color": "2a2c89",
            "default": false,
            "description": "Change current process or code"
        },
        {
            "id": 1139741213,
            "node_id": "MDU6TGFiZWwxMTM5NzQxMjEz",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/Python",
            "name": "Python",
            "color": "1d76db",
            "default": false,
            "description": "Affects Python cuDF API."
        },
        {
            "id": 2546521024,
            "node_id": "MDU6TGFiZWwyNTQ2NTIxMDI0",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/improvement",
            "name": "improvement",
            "color": "bfd4f2",
            "default": false,
            "description": "Improvement / enhancement to an existing function"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 13,
    "created_at": "2022-11-01T18:01:16Z",
    "updated_at": "2024-05-16T05:12:38Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "# Summary\r\n\r\nCUDF is not consistent with Pandas (under a bunch of circumstances) in\r\nits behaviour when upcasting during `__setitem__`. In some cases, we\r\nmight want to mimic pandas behaviour (though they are very keen to use\r\nvalue-based type promotion). In others, where we have more structured\r\ndtypes than pandas, we need to decide what to do (current behaviour is\r\ninternally inconsistent and buggy in a bunch of cases).\r\n\r\nI summarise what I think the current state is (by way of experiment),\r\nand then discuss some options. Opinions welcome!\r\n\r\ncc: @vyasr, @mroeschke, @shwina\r\n# Pandas behaviour\r\n\r\nPandas version 1.5.1, MacOS (Apple Silicon)\r\n\r\nEdit: updated code for generating more tables.\r\n\r\nI should note that these tables are for single index `__setitem__` (`s.iloc[i] = value`). I should check if the same behaviour also occurs for:\r\n- [x] slice-based `__setitem__` with single value `s.iloc[:1] = [value]`\r\n- [x] slice-based `__setitem__` with list of values `s.iloc[:2] = [value for _ in range(2)]`\r\n- [x] mask-based `__setitem__` with singleton value `s.iloc[[True, False]] = [value]`\r\n- [x] mask-based `__setitem__` with multiple values `s.iloc[[True, False, True]] = [value, value]`\r\n- [x] index-based `__setitem__` with single value `s.iloc[[1]] = value`\r\n- [x] index-based `__setitem__` with multiple values `s.iloc[[1, 2]] = [value, value]`\r\n\r\n<details>\r\n<summary>Code to generate tables</summary>\r\n\r\n```python\r\nfrom __future__ import annotations\r\n\r\nimport os\r\nfrom enum import Enum, IntEnum, auto\r\nfrom itertools import filterfalse, repeat\r\nfrom operator import not_\r\nfrom pathlib import Path\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport typer\r\n\r\ntry:\r\n    import cudf\r\n    import cupy\r\n\r\n    class Backend(str, Enum):\r\n        PANDAS = \"pandas\"\r\n        CUDF = \"cudf\"\r\n\r\nexcept ImportError:\r\n\r\n    class Backend(str, Enum):\r\n        PANDAS = \"pandas\"\r\n\r\n\r\ndef numeric_series(values, dtype, *, pandas):\r\n    if pandas:\r\n        return pd.Series(values, dtype=dtype)\r\n    else:\r\n        return cudf.Series(values, dtype=dtype)\r\n\r\n\r\ndef format_val(v):\r\n    try:\r\n        dt = v.dtype\r\n        return f\"np.{dt.type.__name__}({v})\"\r\n    except AttributeError:\r\n        return f\"{v}\"\r\n\r\n\r\nclass IndexType(IntEnum):\r\n    SINGLE_INT = auto()\r\n    SINGLETON_SLICE = auto()\r\n    CONTIG_SLICE = auto()\r\n    STRIDED_SLICE = auto()\r\n    SINGLETON_MASK = auto()\r\n    GENERAL_MASK = auto()\r\n    SINGLETON_SCATTER = auto()\r\n    GENERAL_SCATTER = auto()\r\n\r\n\r\ndef indexing(index_type: IndexType, n: int) -> tuple[int | slice | list, slice | list]:\r\n    assert n >= 3\r\n    if index_type == IndexType.SINGLE_INT:\r\n        return n - 1, slice(0, n - 1, None)\r\n    elif index_type == IndexType.SINGLETON_SLICE:\r\n        return slice(1, 2, 1), [0, *range(2, n)]\r\n    elif index_type == IndexType.CONTIG_SLICE:\r\n        return slice(1, n - 2, 1), [0, *range(n - 2, n)]\r\n    elif index_type == IndexType.STRIDED_SLICE:\r\n        return slice(0, n, 2), slice(1, n, 2)\r\n    elif index_type == IndexType.SINGLETON_MASK:\r\n        yes = [False, True, *repeat(False, n - 2)]\r\n        no = list(map(not_, yes))\r\n        return yes, no\r\n    elif index_type == IndexType.GENERAL_MASK:\r\n        yes = [True, False, True, *repeat(False, n - 3)]\r\n        no = list(map(not_, yes))\r\n        return yes, no\r\n    elif index_type == IndexType.SINGLETON_SCATTER:\r\n        yes = [1]\r\n        # Oh for Haskell-esque sections\r\n        no = list(filterfalse(yes.__contains__, range(n)))\r\n        return yes, no\r\n    elif index_type == IndexType.GENERAL_SCATTER:\r\n        yes = [0, 2]\r\n        no = list(filterfalse(yes.__contains__, range(n)))\r\n        return yes, no\r\n    else:\r\n        raise ValueError(\"Unhandled case\")\r\n\r\n\r\ndef generate_table(f, initial_values, values_to_try, dtype, *, index_type, pandas):\r\n    initial_values = np.asarray(initial_values, dtype=object)\r\n    f.write(\"| Initial dtype | New value | Final dtype | Lossy? |\\n\")\r\n    f.write(\"|---------------|-----------|-------------|--------|\\n\")\r\n\r\n    yes, no = indexing(index_type, len(initial_values))\r\n    for value in values_to_try:\r\n        s = numeric_series(initial_values, dtype=dtype, pandas=pandas)\r\n        otype = f\"np.{type(s.dtype).__name__}\"\r\n        try:\r\n            if index_type == IndexType.SINGLETON_SLICE:\r\n                value = cupy.asarray([value])\r\n            s.iloc[yes] = value\r\n        except BaseException as e:\r\n            f.write(f\"| `{otype}` | `{format_val(value)}` | N/A | {e} |\\n\")\r\n            continue\r\n        ntype = f\"np.{type(s.dtype).__name__}\"\r\n        expect = (np.asarray if pandas else cupy.asarray)(\r\n            initial_values[no], dtype=dtype\r\n        )\r\n        original_lost_info = (s.iloc[no].astype(dtype) != expect).any()\r\n        try:\r\n            new_vals = s.iloc[yes].astype(value.dtype)\r\n        except AttributeError:\r\n            if pandas:\r\n                new_vals = np.asarray(s.iloc[yes])\r\n            else:\r\n                new_vals = cupy.asarray(s.iloc[yes])\r\n        new_lost_info = (new_vals != value).any()\r\n        lossy = \"Yes\" if original_lost_info or new_lost_info else \"No\"\r\n        f.write(f\"| `{otype}` | `{format_val(value)}` | `{ntype}` | {lossy} |\\n\")\r\n\r\n\r\ndef generate_tables(output_directory: Path, backend: Backend, index_type: IndexType):\r\n    integer_column_values_to_try = [\r\n        10,\r\n        np.int64(10),\r\n        2**40,\r\n        np.int64(2**40),\r\n        2**80,\r\n        10.5,\r\n        np.float64(10),\r\n        np.float64(10.5),\r\n        np.float32(10),\r\n        np.float32(10.5),\r\n    ]\r\n    float_column_values_to_try = [\r\n        10,\r\n        np.int64(10),\r\n        2**40,\r\n        np.int64(2**40),\r\n        np.int32(2**31 - 100),\r\n        np.int64(2**63 - 100),\r\n        2**80 - 100,\r\n        10.5,\r\n        np.float64(10),\r\n        np.float64(10.5),\r\n        np.float64(np.finfo(np.float32).max.astype(np.float64) * 10),\r\n        np.float32(10),\r\n        np.float32(10.5),\r\n    ]\r\n\r\n    pandas = backend == Backend.PANDAS\r\n    filename = f\"{backend}-setitem-{index_type.name}.md\"\r\n    with open(output_directory / filename, \"w\") as f:\r\n        if pandas:\r\n            f.write(f\"Pandas {pd.__version__} behaviour for {index_type!r}\\n\\n\")\r\n        else:\r\n            f.write(f\"CUDF {cudf.__version__} behaviour for {index_type!r}\\n\\n\")\r\n\r\n        generate_table(\r\n            f,\r\n            [2**31 - 10, 2**31 - 100, 3, 4, 5],\r\n            integer_column_values_to_try,\r\n            np.int32,\r\n            index_type=index_type,\r\n            pandas=pandas,\r\n        )\r\n        f.write(\"\\n\")\r\n        generate_table(\r\n            f,\r\n            [2**63 - 10, 2**63 - 100, 3, 4, 5],\r\n            integer_column_values_to_try,\r\n            np.int64,\r\n            index_type=index_type,\r\n            pandas=pandas,\r\n        )\r\n        f.write(\"\\n\")\r\n        generate_table(\r\n            f,\r\n            [np.finfo(np.float32).max, np.float32(np.inf), 3, 4, 5],\r\n            float_column_values_to_try,\r\n            np.float32,\r\n            index_type=index_type,\r\n            pandas=pandas,\r\n        )\r\n        f.write(\"\\n\")\r\n        generate_table(\r\n            f,\r\n            [np.finfo(np.float64).max, np.float64(np.inf), 3, 4, 5],\r\n            float_column_values_to_try,\r\n            np.float64,\r\n            index_type=index_type,\r\n            pandas=pandas,\r\n        )\r\n\r\n\r\ndef main(\r\n    output_directory: Path = typer.Argument(Path(\".\"), help=\"Output directory for results\"),\r\n    backend: Backend = typer.Option(\"pandas\", help=\"Dataframe backend to test\"),\r\n):\r\n    os.makedirs(output_directory, exist_ok=True)\r\n    for index_type in IndexType.__members__.values():\r\n        generate_tables(output_directory, backend, index_type)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    typer.run(main)\r\n```\r\n\r\n</details>\r\n\r\n## Numeric columns\r\n\r\n### Integer column dtypes\r\n\r\n#### dtype width < max integer width\r\n\r\nInitial values `[2**31 - 10, 2**31 - 100, 3]`. `np.int32` is\r\nrepresentative of any integer type that is smaller than the max width.\r\n\r\n| Initial dtype     | New value                   | Final dtype          | Lossy? |\r\n|-------------------|-----------------------------|----------------------|--------|\r\n| `np.dtype[int32]` | `10`                        | `np.dtype[int32]`    | No[^1] |\r\n| `np.dtype[int32]` | `np.int64(10)`              | `np.dtype[int32]`    | No[^1] |\r\n| `np.dtype[int32]` | `1099511627776`             | `np.dtype[longlong]` | No[^2] |\r\n| `np.dtype[int32]` | `np.int64(1099511627776)`   | `np.dtype[longlong]` | No[^2] |\r\n| `np.dtype[int32]` | `1208925819614629174706176` | `np.dtype[object_]`  | No[^3] |\r\n| `np.dtype[int32]` | `10.5`                      | `np.dtype[float64]`  | No[^4] |\r\n| `np.dtype[int32]` | `np.float64(10.0)`          | `np.dtype[int32]`    | No[^1] |\r\n| `np.dtype[int32]` | `np.float64(10.5)`          | `np.dtype[float64]`  | No[^2] |\r\n| `np.dtype[int32]` | `np.float32(10.0)`          | `np.dtype[int32]`    | No[^1] |\r\n| `np.dtype[int32]` | `np.float32(10.5)`          | `np.dtype[float64]`  | No[^5] |\r\n\r\n[^1]: value is exact in the initial dtype\r\n[^2]: next largest numpy type that contains the value\r\n[^3]: not representable in a numpy type, so coercion to object column\r\n[^4]: default float type is float64\r\n[^5]: `np.int32` is losslessly convertible to `np.float64`\r\n\r\n#### dtype width == max integer width\r\n\r\nInitial values `[2 ** 63 - 10, 2 ** 63 - 100, 3]`. These provoke edge\r\ncases in upcasting because:\r\n```python\r\nimport numpy as np\r\nnp.find_common_type([], [np.int64, np.float64])\r\n# => np.float64 Noooooo! Hates it\r\n# Yes, I know this is the same as the integer to float promotion in\r\n# C/C++, I'm allowed to hate that too.\r\n```\r\n\r\n| Initial dtype     | New value                   | Final dtype         | Lossy?  |\r\n|-------------------|-----------------------------|---------------------|---------|\r\n| `np.dtype[int64]` | `10`                        | `np.dtype[int64]`   | No[^1]  |\r\n| `np.dtype[int64]` | `np.int64(10)`              | `np.dtype[int64]`   | No[^1]  |\r\n| `np.dtype[int64]` | `1099511627776`             | `np.dtype[int64]`   | No[^1]  |\r\n| `np.dtype[int64]` | `np.int64(1099511627776)`   | `np.dtype[int64]`   | No[^1]  |\r\n| `np.dtype[int64]` | `1208925819614629174706176` | `np.dtype[object_]` | No[^3]  |\r\n| `np.dtype[int64]` | `10.5`                      | `np.dtype[float64]` | Yes[^6] |\r\n| `np.dtype[int64]` | `np.float64(10.0)`          | `np.dtype[int64]`   | No[^1]  |\r\n| `np.dtype[int64]` | `np.float64(10.5)`          | `np.dtype[float64]` | Yes[^6] |\r\n| `np.dtype[int64]` | `np.float32(10.0)`          | `np.dtype[int64]`   | No[^1]  |\r\n| `np.dtype[int64]` | `np.float32(10.5)`          | `np.dtype[float64]` | Yes[^6] |\r\n\r\n[^6]: `np.int64` is _not_ losslessly convertible `np.float64`\r\n\r\n### Float column dtypes\r\n\r\n#### dtype width < max float width\r\n\r\nInitial values `[np.finfo(np.float32).max, np.float32(np.inf), 3]`\r\n\r\n| Initial dtype       | New value                            | Final dtype         | Lossy?   |\r\n|---------------------|--------------------------------------|---------------------|----------|\r\n| `np.dtype[float32]` | `10`                                 | `np.dtype[float32]` | No[^1]   |\r\n| `np.dtype[float32]` | `np.int64(10)`                       | `np.dtype[float32]` | No[^1]   |\r\n| `np.dtype[float32]` | `1099511627776`                      | `np.dtype[float32]` | No[^1]   |\r\n| `np.dtype[float32]` | `np.int64(1099511627776)`            | `np.dtype[float32]` | No[^1]   |\r\n| `np.dtype[float32]` | `np.int32(2147483548)`               | `np.dtype[float64]` | No[^1]   |\r\n| `np.dtype[float32]` | `np.int64(9223372036854775708)`      | `np.dtype[float32]` | Yes[^7] |\r\n| `np.dtype[float32]` | `1208925819614629174706076`          | `np.dtype[object_]` | No[^3]  |\r\n| `np.dtype[float32]` | `10.5`                               | `np.dtype[float32]` | No[^1]   |\r\n| `np.dtype[float32]` | `np.float64(10.0)`                   | `np.dtype[float32]` | No[^1]   |\r\n| `np.dtype[float32]` | `np.float64(10.5)`                   | `np.dtype[float32]` | No[^1]   |\r\n| `np.dtype[float32]` | `np.float64(3.4028234663852886e+39)` | `np.dtype[float64]` | No[^2]  |\r\n| `np.dtype[float32]` | `np.float32(10.0)`                   | `np.dtype[float32]` | No[^1]   |\r\n| `np.dtype[float32]` | `np.float32(10.5)`                   | `np.dtype[float32]` | No[^1]   |\r\n\r\n[^7]: value is not losslessly representable, but also, expecting\r\n    `np.float64`!\r\n\r\n#### dtype width == max float width\r\n\r\nInitial values `[np.finfo(np.float64).max, np.float64(np.inf), 3]`\r\n\r\n| Initial dtype       | New value                            | Final dtype         | Lossy?   |\r\n|---------------------|--------------------------------------|---------------------|----------|\r\n| `np.dtype[float64]` | `10`                                 | `np.dtype[float64]` | No[^1]  |\r\n| `np.dtype[float64]` | `np.int64(10)`                       | `np.dtype[float64]` | No[^1]  |\r\n| `np.dtype[float64]` | `1099511627776`                      | `np.dtype[float64]` | No[^1]  |\r\n| `np.dtype[float64]` | `np.int64(1099511627776)`            | `np.dtype[float64]` | No[^1]  |\r\n| `np.dtype[float64]` | `np.int32(2147483548)`               | `np.dtype[float64]` | No[^1]  |\r\n| `np.dtype[float64]` | `np.int64(9223372036854775708)`      | `np.dtype[float64]` | Yes[^6] |\r\n| `np.dtype[float64]` | `1208925819614629174706076`          | `np.dtype[object_]` | No[^3]  |\r\n| `np.dtype[float64]` | `10.5`                               | `np.dtype[float64]` | No[^1]  |\r\n| `np.dtype[float64]` | `np.float64(10.0)`                   | `np.dtype[float64]` | No[^1]  |\r\n| `np.dtype[float64]` | `np.float64(10.5)`                   | `np.dtype[float64]` | No[^1]  |\r\n| `np.dtype[float64]` | `np.float64(3.4028234663852886e+39)` | `np.dtype[float64]` | No[^1]  |\r\n| `np.dtype[float64]` | `np.float32(10.0)`                   | `np.dtype[float64]` | No[^1]  |\r\n| `np.dtype[float64]` | `np.float32(10.5)`                   | `np.dtype[float64]` | No[^1]  |\r\n\r\n## Everything else\r\n\r\nBasically, you can put anything in a column and you get an object out,\r\nbut numpy types are converted to `object` first.\r\n\r\n# CUDF behaviour\r\n\r\nCUDF trunk, and state in #11904.\r\n\r\n## Numeric columns\r\n\r\n### Integer column dtypes\r\n\r\n#### dtype width < max integer width\r\n\r\nInitial values `[2**31 - 10, 2**31 - 100, 3]`. `np.int32` is\r\nrepresentative of any integer type that is smaller than the max width.\r\n\r\n| Initial dtype     | New value                   | Final dtype (trunk)   | Final dtype (#11904)    | Lossy? (trunk) | Lossy? (#11904) |\r\n|-------------------|-----------------------------|-----------------------|-------------------------|----------------|-----------------|\r\n| `np.dtype[int32]` | `10`                        | `np.dtype[int32]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |\r\n| `np.dtype[int32]` | `np.int64(10)`              | `np.dtype[int32]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |\r\n| `np.dtype[int32]` | `1099511627776`             | `np.dtype[int32]`[^8] | `np.dtype[int64]`[^9]   | Yes            | No              |\r\n| `np.dtype[int32]` | `np.int64(1099511627776)`   | `np.dtype[int32]`[^8] | `np.dtype[int64]`[^9]   | Yes            | No              |\r\n| `np.dtype[int32]` | `1208925819614629174706176` | OverflowError         | OverflowError           | N/A            | N/A             |\r\n| `np.dtype[int32]` | `10.5`                      | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | Yes            | No              |\r\n| `np.dtype[int32]` | `np.float64(10.0)`          | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\r\n| `np.dtype[int32]` | `np.float64(10.5)`          | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | Yes            | No              |\r\n| `np.dtype[int32]` | `np.float32(10.0)`          | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\r\n| `np.dtype[int32]` | `np.float32(10.5)`          | `np.dtype[int32]`[^8] | `np.dtype[float64]`[^9] | Yes            | No              |\r\n\r\n[^8]: Bug fixed by #11904\r\n[^9]: CUDF doesn't inspect values, so type-based promotion (difference\r\n    from pandas)\r\n\r\n#### dtype width == max integer width\r\n\r\nInitial values `[2 ** 63 - 10, 2 ** 63 - 100, 3]`.\r\n\r\n| Initial dtype     | New value                   | Final dtype (trunk)   | Final dtype (#11904)    | Lossy? (trunk) | Lossy? (#11904) |\r\n|-------------------|-----------------------------|-----------------------|-------------------------|----------------|-----------------|\r\n| `np.dtype[int64]` | `10`                        | `np.dtype[int64]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |\r\n| `np.dtype[int64]` | `np.int64(10)`              | `np.dtype[int64]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |\r\n| `np.dtype[int64]` | `1099511627776`             | `np.dtype[int64]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |\r\n| `np.dtype[int64]` | `np.int64(1099511627776)`   | `np.dtype[int64]`[^8] | `np.dtype[int64]`[^9]   | No             | No              |\r\n| `np.dtype[int64]` | `1208925819614629174706176` | OverflowError         | OverflowError           | N/A            | N/A             |\r\n| `np.dtype[int64]` | `10.5`                      | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | Yes            | Yes[^6]         |\r\n| `np.dtype[int64]` | `np.float64(10.0)`          | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | No             | Yes[^6]         |\r\n| `np.dtype[int64]` | `np.float64(10.5)`          | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | Yes            | Yes[^6]         |\r\n| `np.dtype[int64]` | `np.float32(10.0)`          | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | No             | Yes[^6]         |\r\n| `np.dtype[int64]` | `np.float32(10.5)`          | `np.dtype[int64]`[^8] | `np.dtype[float64]`[^9] | Yes            | Yes[^6]         |\r\n\r\n### Float column dtypes\r\n\r\n#### dtype width < max float width\r\n\r\nInitial values `[np.finfo(np.float32).max, np.float32(np.inf), 3]`\r\n\r\n| Initial dtype       | New value                            | Final dtype (trunk)     | Final dtype (#11904)    | Lossy? (trunk) | Lossy? (#11904) |\r\n|---------------------|--------------------------------------|-------------------------|-------------------------|----------------|-----------------|\r\n| `np.dtype[float32]` | `10`                                 | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\r\n| `np.dtype[float32]` | `np.int64(10)`                       | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\r\n| `np.dtype[float32]` | `1099511627776`                      | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\r\n| `np.dtype[float32]` | `np.int64(1099511627776)`            | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\r\n| `np.dtype[float32]` | `np.int32(2147483548)`               | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | Yes[^10]       | No              |\r\n| `np.dtype[float32]` | `np.int64(9223372036854775708)`      | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | Yes[^10]       | Yes[^6]         |\r\n| `np.dtype[float32]` | `1208925819614629174706076`          | OverflowError           | OverflowError           | N/A            | N/A             |\r\n| `np.dtype[float32]` | `10.5`                               | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\r\n| `np.dtype[float32]` | `np.float64(10.0)`                   | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\r\n| `np.dtype[float32]` | `np.float64(10.5)`                   | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | No             | No              |\r\n| `np.dtype[float32]` | `np.float64(3.4028234663852886e+39)` | `np.dtype[float32]`[^8] | `np.dtype[float64]`[^9] | Yes[^8]        | No              |\r\n| `np.dtype[float32]` | `np.float32(10.0)`                   | `np.dtype[float32]`[^8] | `np.dtype[float32]`[^9] | No             | No              |\r\n| `np.dtype[float32]` | `np.float32(10.5)`                   | `np.dtype[float32]`[^8] | `np.dtype[float32]`[^9] | No             | No              |\r\n\r\n[^10]: As for [^6], but promotion from `np.int32` to `np.float32` is\r\n    also not lossless.\r\n\r\n#### dtype width == max float width\r\n\r\nInitial values `[np.finfo(np.float64).max, np.float64(np.inf), 3]`\r\n\r\n| Initial dtype       | New value                            | Final dtype (trunk) | Final dtype (#11904) | Lossy? (trunk) | Lossy? (#11904) |\r\n|---------------------|--------------------------------------|---------------------|----------------------|----------------|-----------------|\r\n| `np.dtype[float64]` | `10`                                 | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\r\n| `np.dtype[float64]` | `np.int64(10)`                       | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\r\n| `np.dtype[float64]` | `1099511627776`                      | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\r\n| `np.dtype[float64]` | `np.int64(1099511627776)`            | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\r\n| `np.dtype[float64]` | `np.int32(2147483548)`               | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\r\n| `np.dtype[float64]` | `np.int64(9223372036854775708)`      | `np.dtype[float64]` | `np.dtype[float64]`  | Yes[^6]        | Yes[^6]         |\r\n| `np.dtype[float64]` | `1208925819614629174706076`          | OverflowError       | OverflowError        | N/A            | N/A             |\r\n| `np.dtype[float64]` | `10.5`                               | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\r\n| `np.dtype[float64]` | `np.float64(10.0)`                   | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\r\n| `np.dtype[float64]` | `np.float64(10.5)`                   | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\r\n| `np.dtype[float64]` | `np.float64(3.4028234663852886e+39)` | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\r\n| `np.dtype[float64]` | `np.float32(10.0)`                   | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\r\n| `np.dtype[float64]` | `np.float32(10.5)`                   | `np.dtype[float64]` | `np.dtype[float64]`  | No             | No              |\r\n\r\n## Everything else\r\n\r\nThis is where it starts to get _really_ messy. This section is a work\r\nin progress. We should decide what we _want_ the semantics to be,\r\nbecause in most cases pandas doesn't have the same dtypes that CUDF does.\r\n\r\n### Inserting strings into numerical columns\r\n\r\nThis \"works\", for some value of \"works\" on #11904 if the string value\r\nis parseable as the target dtype.\r\n\r\nSo\r\n\r\n```python\r\ns = cudf.Series([1, 2, 3], dtype=int)\r\ns.iloc[2] = \"4\" # works\r\ns.iloc[2] = \"0xf\" # => ValueError: invalid literal for int() with base 10: '0xf'\r\n```\r\n\r\nAnd similarly for float strings and float dtypes.\r\n\r\nThis is probably a nice feature.\r\n\r\n### Inserting things into string columns\r\n\r\nWorks if the the \"thing\" is convertible to a string (so numbers work),\r\nbut Scalars with list or struct dtypes don't work.\r\n\r\nI would argue that explicit casting from the user here is probably\r\nbetter.\r\n\r\n### List columns\r\n\r\nThe new value must have an identical dtype to that of the target column.\r\n\r\n### Struct columns\r\n\r\nThe new value must have leaf dtypes that are considered compatible in\r\nsome sense, but then the leaves are downcast to the leaf dtypes of the\r\ntarget column. So this is lossy and likely a bug:\r\n\r\n```python\r\n sr = cudf.Series([{\"a\": 1, \"b\": 2}])\r\n sr.iloc[0] = {\"a\": 10.5, \"b\": 2}\r\n sr[0] # => {\"a\": 10, \"b\": 2} (lost data in \"a\")\r\n```\r\n## What I think we want (for composite columns)\r\n\r\nFor composite columns, if the dtype shapes match, I think the casting\r\nrule should be to traverse to the leaf dtypes and promote using the\r\nrules for non-composite columns. If shapes don't match, `__setitem__`\r\nshould not be allowed.\r\n\r\nThis, to me, exhibits principle of least surprise.\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/12039/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/rapidsai/cudf/issues/12039/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}