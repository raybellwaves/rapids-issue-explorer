{
    "url": "https://api.github.com/repos/rapidsai/cudf/issues/13525",
    "repository_url": "https://api.github.com/repos/rapidsai/cudf",
    "labels_url": "https://api.github.com/repos/rapidsai/cudf/issues/13525/labels{/name}",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/13525/comments",
    "events_url": "https://api.github.com/repos/rapidsai/cudf/issues/13525/events",
    "html_url": "https://github.com/rapidsai/cudf/issues/13525",
    "id": 1746281193,
    "node_id": "I_kwDOBWUGps5oFiLp",
    "number": 13525,
    "title": "[FEA] JSON reader improvements for Spark-RAPIDS",
    "user": {
        "login": "GregoryKimball",
        "id": 12725111,
        "node_id": "MDQ6VXNlcjEyNzI1MTEx",
        "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/GregoryKimball",
        "html_url": "https://github.com/GregoryKimball",
        "followers_url": "https://api.github.com/users/GregoryKimball/followers",
        "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
        "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
        "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
        "repos_url": "https://api.github.com/users/GregoryKimball/repos",
        "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
        "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 599626561,
            "node_id": "MDU6TGFiZWw1OTk2MjY1NjE=",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        },
        {
            "id": 1013987352,
            "node_id": "MDU6TGFiZWwxMDEzOTg3MzUy",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/0%20-%20Backlog",
            "name": "0 - Backlog",
            "color": "d4c5f9",
            "default": false,
            "description": "In queue waiting for assignment"
        },
        {
            "id": 1139740666,
            "node_id": "MDU6TGFiZWwxMTM5NzQwNjY2",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/libcudf",
            "name": "libcudf",
            "color": "c5def5",
            "default": false,
            "description": "Affects libcudf (C++/CUDA) code."
        },
        {
            "id": 1185244142,
            "node_id": "MDU6TGFiZWwxMTg1MjQ0MTQy",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/cuIO",
            "name": "cuIO",
            "color": "fef2c0",
            "default": false,
            "description": "cuIO issue"
        },
        {
            "id": 1405146975,
            "node_id": "MDU6TGFiZWwxNDA1MTQ2OTc1",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/Spark",
            "name": "Spark",
            "color": "7400ff",
            "default": false,
            "description": "Functionality that helps Spark RAPIDS"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": {
        "url": "https://api.github.com/repos/rapidsai/cudf/milestones/13",
        "html_url": "https://github.com/rapidsai/cudf/milestone/13",
        "labels_url": "https://api.github.com/repos/rapidsai/cudf/milestones/13/labels",
        "id": 8139578,
        "node_id": "MI_kwDOBWUGps4AfDM6",
        "number": 13,
        "title": "Nested JSON reader",
        "description": "Data-parallel reader for nested JSON text data",
        "creator": {
            "login": "GregoryKimball",
            "id": 12725111,
            "node_id": "MDQ6VXNlcjEyNzI1MTEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregoryKimball",
            "html_url": "https://github.com/GregoryKimball",
            "followers_url": "https://api.github.com/users/GregoryKimball/followers",
            "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
            "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
            "repos_url": "https://api.github.com/users/GregoryKimball/repos",
            "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
            "type": "User",
            "site_admin": false
        },
        "open_issues": 14,
        "closed_issues": 63,
        "state": "open",
        "created_at": "2022-06-28T04:14:28Z",
        "updated_at": "2024-05-31T22:24:52Z",
        "due_on": null,
        "closed_at": null
    },
    "comments": 4,
    "created_at": "2023-06-07T16:30:32Z",
    "updated_at": "2024-04-01T19:29:22Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "libcudf includes a GPU-accelerated JSON reader that uses a finite-state transducer parser combined with token-processing tree algorithms to transform character buffers into columnar data. This issue tracks the technical work leading up to the launch of libcudf's JSON reader as a default component of the Spark-RAPIDS plugin. Please also refer to the [Nested JSON reader milestone](https://github.com/rapidsai/cudf/milestone/13) and [Spark-RAPIDS JSON epic](https://github.com/NVIDIA/spark-rapids/issues/9458).\r\n\r\n\r\n### Spark compatibility issues: Blockers\r\n| Status | Impact for Spark | Change to libcudf |\r\n|---|---|---|\r\n| \u2705 #13344  | #12532, Blocker: if any line has an error, libcudf throws an exception  | Rework state machine to include error states and scrub tokens from lines with error | \r\n| \u2705 #14252 | #14227, Blocker: Incorrect parsing | Fix bug in error recovery state transitions |  \r\n\u2705 #14279 | #14226, Blocker: requesting alternate error recovery behavior from #13344, where valid data before an error state are preserved  | Changes in JSON parser pushdown automaton for JSON_LINES_RECOVER option  | \r\n| \u2705 #14936 | #14288, Blocker: libcudf does not have an efficient representation for map types in Spark |  libcudf does not support map types, and modeling the map types as structs results in poor performance due to one child column per unique key. We will return the struct data that represents map types as string and then the plugin can use [unify_json_strings](https://github.com/NVIDIA/spark-rapids-jni/blob/54ef9991f46fa873d580315212aeae345da7152a/src/main/cpp/src/map_utils.cu#L63-L112) to parse tokens |\r\n| \u2705 #14572  | #14239, Blocker: fields with mixed types raise an exception | add libcudf reader option to return mixed types as strings. Also see improvements in  #15236 and  #14939 | \r\n| \u2705 #14545 | #10004, Blocker: Can't parse data with single quote variant of JSON when `allowSingleQuotes` is enabled in Spark | Introduce a preprocessing function to normalize single and double quotes as double quotes | \r\n| \u2705 #15324 | #15303, escaped single quotes have their escapes dropped during quote normalization | Adjust quote normalization FST |\r\n| \ud83d\udd04 #15419 | #15390 + #15409, Blocker: race conditions found in nested JSON reader | Solve synchronization problems in nested JSON reader  |\r\n| | #15260, Blocker: crash in mixed type support | |\r\n| \ud83d\udd04 | #15278, Blocker: allow list type to be coerced to string, also see #14239. Without this, Spark-RAPIDS will fallback when user requests a field as \"string\" | Support List types coercion to string | \r\n| | #15277, Blocker: we need to support multi-line JSON objects. Also see #10267 | libcudf is scoping a \"multi-object\" reader |  \r\n\r\n\r\n\r\n### Spark compatibility issues: non-blockers\r\n\r\n| Status  | Impact for Spark | Change to libcudf  | \r\n|---|---|---|\r\n| | #15222, compatibility problems with leading zeros, \"NAN\" and escape options | None for now. This feature should live in Spark-RAPIDS as a post-processing option for now, based on the approach for `get_json_object` modeled after Spark CPU code (see https://github.com/NVIDIA/spark-rapids-jni/pull/1836). Then the plugin can set to null any entries from objects that Spark would treat as invalid. Later we could provide Spark-RAPIDS access to raw tokens that they could run through a more efficient validator.  |\r\n| \u2705 #15033 |  #14865, Strip whitespace from JSON inputs, otherwise Spark will have to add this in post-processing the coerced strings types | Create new normalization pre-processing tool for whitespace | \r\n| \ud83d\udd04 #14996 | #13473, Performance: only process columns in the schema | Skip parsing and column creation for keys not specified in the schema |\r\n| \ud83d\udd04 #15124 | Reader option performance is unknown | #15041, add JSON reader option benchmarking | |\r\n| | Performance: Avoid preprocessing to replace empty lines with `{}`. Also see #5712 |  libcudf provides strings column data source | \r\n|  | #15280 find a solution when whitespace normalization fixes a line that originally was invalid | We could move whitespace normalization after tokenization. Also we would like to address #15277 so that we can remove unquoted newline characters as well. |\r\n| | n/a, Spark-RAPIDS doesn't use byte range reading | #15185, reduce IO overhead in JSON byte range reading |\r\n| | n/a, Spark-RAPIDS doesn't use byte range reading | #15186, address data loss edge case for byte range reading |\r\n|  | reduce peak memory usage | add chunking to the JSON reader | \r\n| | #15222, Spark-RAPIDS must return null if any field is invalid | Provide token stream to Spark-RAPIDS for validation, including checks or leading zeros, special string numbers like `NaN`, `+INF`, `-INF`, and optional limits for which characters can be escaped |\r\n\r\n\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/13525/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/rapidsai/cudf/issues/13525/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}