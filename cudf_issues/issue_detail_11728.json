{
    "url": "https://api.github.com/repos/rapidsai/cudf/issues/11728",
    "repository_url": "https://api.github.com/repos/rapidsai/cudf",
    "labels_url": "https://api.github.com/repos/rapidsai/cudf/issues/11728/labels{/name}",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/11728/comments",
    "events_url": "https://api.github.com/repos/rapidsai/cudf/issues/11728/events",
    "html_url": "https://github.com/rapidsai/cudf/issues/11728",
    "id": 1380691968,
    "node_id": "I_kwDOBWUGps5SS7AA",
    "number": 11728,
    "title": "[FEA] `read_csv` context-passing interface for distributed/segmented parsing",
    "user": {
        "login": "upsj",
        "id": 1693511,
        "node_id": "MDQ6VXNlcjE2OTM1MTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1693511?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/upsj",
        "html_url": "https://github.com/upsj",
        "followers_url": "https://api.github.com/users/upsj/followers",
        "following_url": "https://api.github.com/users/upsj/following{/other_user}",
        "gists_url": "https://api.github.com/users/upsj/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/upsj/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/upsj/subscriptions",
        "organizations_url": "https://api.github.com/users/upsj/orgs",
        "repos_url": "https://api.github.com/users/upsj/repos",
        "events_url": "https://api.github.com/users/upsj/events{/privacy}",
        "received_events_url": "https://api.github.com/users/upsj/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 599626561,
            "node_id": "MDU6TGFiZWw1OTk2MjY1NjE=",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        },
        {
            "id": 1139740666,
            "node_id": "MDU6TGFiZWwxMTM5NzQwNjY2",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/libcudf",
            "name": "libcudf",
            "color": "c5def5",
            "default": false,
            "description": "Affects libcudf (C++/CUDA) code."
        },
        {
            "id": 1185244142,
            "node_id": "MDU6TGFiZWwxMTg1MjQ0MTQy",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/cuIO",
            "name": "cuIO",
            "color": "fef2c0",
            "default": false,
            "description": "cuIO issue"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": {
        "login": "upsj",
        "id": 1693511,
        "node_id": "MDQ6VXNlcjE2OTM1MTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1693511?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/upsj",
        "html_url": "https://github.com/upsj",
        "followers_url": "https://api.github.com/users/upsj/followers",
        "following_url": "https://api.github.com/users/upsj/following{/other_user}",
        "gists_url": "https://api.github.com/users/upsj/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/upsj/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/upsj/subscriptions",
        "organizations_url": "https://api.github.com/users/upsj/orgs",
        "repos_url": "https://api.github.com/users/upsj/repos",
        "events_url": "https://api.github.com/users/upsj/events{/privacy}",
        "received_events_url": "https://api.github.com/users/upsj/received_events",
        "type": "User",
        "site_admin": false
    },
    "assignees": [
        {
            "login": "upsj",
            "id": 1693511,
            "node_id": "MDQ6VXNlcjE2OTM1MTE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1693511?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/upsj",
            "html_url": "https://github.com/upsj",
            "followers_url": "https://api.github.com/users/upsj/followers",
            "following_url": "https://api.github.com/users/upsj/following{/other_user}",
            "gists_url": "https://api.github.com/users/upsj/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/upsj/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/upsj/subscriptions",
            "organizations_url": "https://api.github.com/users/upsj/orgs",
            "repos_url": "https://api.github.com/users/upsj/repos",
            "events_url": "https://api.github.com/users/upsj/events{/privacy}",
            "received_events_url": "https://api.github.com/users/upsj/received_events",
            "type": "User",
            "site_admin": false
        }
    ],
    "milestone": {
        "url": "https://api.github.com/repos/rapidsai/cudf/milestones/12",
        "html_url": "https://github.com/rapidsai/cudf/milestone/12",
        "labels_url": "https://api.github.com/repos/rapidsai/cudf/milestones/12/labels",
        "id": 8136720,
        "node_id": "MI_kwDOBWUGps4AfCgQ",
        "number": 12,
        "title": "CSV continuous improvement",
        "description": "",
        "creator": {
            "login": "GregoryKimball",
            "id": 12725111,
            "node_id": "MDQ6VXNlcjEyNzI1MTEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregoryKimball",
            "html_url": "https://github.com/GregoryKimball",
            "followers_url": "https://api.github.com/users/GregoryKimball/followers",
            "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
            "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
            "repos_url": "https://api.github.com/users/GregoryKimball/repos",
            "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
            "type": "User",
            "site_admin": false
        },
        "open_issues": 32,
        "closed_issues": 5,
        "state": "open",
        "created_at": "2022-06-27T23:01:53Z",
        "updated_at": "2024-05-22T20:21:00Z",
        "due_on": null,
        "closed_at": null
    },
    "comments": 8,
    "created_at": "2022-09-21T10:22:51Z",
    "updated_at": "2022-09-27T23:15:06Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\nTo parse files from a regular language like CSV, we can only safely parse data inside a byte range if we know the parsing context from before this range. Without this information, we may accidentally interpret a record delimiter (newline) inside a quoted field as an actual delimiter.\r\n\r\nMore formally, when starting from a byte range, we don't know what state the DFA of the token language is in, so we need to store the transition vector starting from every possible state, and combine the vectors by function composition in the associative scan operation. This is pretty much identical to what is happening in [the finite state transducer](https://github.com/rapidsai/cudf/pull/11242).\r\n\r\nInstead of just running the scan on a full file, we can run it only on a byte range, and combine the resulting transition vectors in an exclusive scan over all byte ranges to establish local parsing context.\r\n\r\n**Describe the solution you'd like**\r\nI want to propose a slight extension to the `read_csv` interface to handle this case:\r\n\r\n1. add a `class csv_parse_context` that opaquely wraps `packed_rowctx_t`, only exposing the `merge_row_contexts` functionality to combine the parsing context from adjacent byte ranges, and a `finalize` operation that turns the transition vector into its value starting from the initial DFA state.\r\n2. add a `read_csv_context` function that only scans the local byte range to compute its `csv_parse_context` transition vector. It can probably take the same parameters as `read_csv`\r\n3. add a `csv_parse_context initial_parsing_state` parameter to `csv_reader_options` that defaults to the initial state. The `read_csv` function can then use this initial state to determine record offsets and do the actual parsing.\r\n\r\n**Describe alternatives you've considered**\r\nAlternatively, we could implement backtracking by reading chunks before the byte range until we figured out an unambiguous parser state (that is not the error state). This could in the worst case lead to reading the entire prefix up to the byte range.\r\n\r\n**Additional context**\r\nThis is relevant if we want `dask.read_csv` to be able to handle quoted record delimiters (i.e. newlines) where the opening quote occurs before the byte range.\r\n\r\nThe interface has the advantage that it can be tested in isolation on a single node, without having to rely on dask.\r\n\r\nThe same kind of pattern could also apply to `read_json`, where on top of the regular parsing state, we also need to pass the stack transition operations from the beginning to the end of the byte range.\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/11728/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 1,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/rapidsai/cudf/issues/11728/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}