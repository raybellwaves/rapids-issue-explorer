{
    "url": "https://api.github.com/repos/rapidsai/cudf/issues/14016",
    "repository_url": "https://api.github.com/repos/rapidsai/cudf",
    "labels_url": "https://api.github.com/repos/rapidsai/cudf/issues/14016/labels{/name}",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/14016/comments",
    "events_url": "https://api.github.com/repos/rapidsai/cudf/issues/14016/events",
    "html_url": "https://github.com/rapidsai/cudf/issues/14016",
    "id": 1875049817,
    "node_id": "I_kwDOBWUGps5vwv1Z",
    "number": 14016,
    "title": "[QST] Dask-cudf/Xgboost out of memory error",
    "user": {
        "login": "rohanpaul14855",
        "id": 18453604,
        "node_id": "MDQ6VXNlcjE4NDUzNjA0",
        "avatar_url": "https://avatars.githubusercontent.com/u/18453604?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/rohanpaul14855",
        "html_url": "https://github.com/rohanpaul14855",
        "followers_url": "https://api.github.com/users/rohanpaul14855/followers",
        "following_url": "https://api.github.com/users/rohanpaul14855/following{/other_user}",
        "gists_url": "https://api.github.com/users/rohanpaul14855/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/rohanpaul14855/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/rohanpaul14855/subscriptions",
        "organizations_url": "https://api.github.com/users/rohanpaul14855/orgs",
        "repos_url": "https://api.github.com/users/rohanpaul14855/repos",
        "events_url": "https://api.github.com/users/rohanpaul14855/events{/privacy}",
        "received_events_url": "https://api.github.com/users/rohanpaul14855/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 599626564,
            "node_id": "MDU6TGFiZWw1OTk2MjY1NjQ=",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/question",
            "name": "question",
            "color": "D4C5F9",
            "default": true,
            "description": "Further information is requested"
        },
        {
            "id": 1013987352,
            "node_id": "MDU6TGFiZWwxMDEzOTg3MzUy",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/0%20-%20Backlog",
            "name": "0 - Backlog",
            "color": "d4c5f9",
            "default": false,
            "description": "In queue waiting for assignment"
        },
        {
            "id": 1139741213,
            "node_id": "MDU6TGFiZWwxMTM5NzQxMjEz",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/Python",
            "name": "Python",
            "color": "1d76db",
            "default": false,
            "description": "Affects Python cuDF API."
        },
        {
            "id": 1185240898,
            "node_id": "MDU6TGFiZWwxMTg1MjQwODk4",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/dask",
            "name": "dask",
            "color": "fcc25d",
            "default": false,
            "description": "Dask issue"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": {
        "url": "https://api.github.com/repos/rapidsai/cudf/milestones/20",
        "html_url": "https://github.com/rapidsai/cudf/milestone/20",
        "labels_url": "https://api.github.com/repos/rapidsai/cudf/milestones/20/labels",
        "id": 8568142,
        "node_id": "MI_kwDOBWUGps4Agr1O",
        "number": 20,
        "title": "Stabilizing large workflows (OOM, spilling, partitioning)",
        "description": "",
        "creator": {
            "login": "GregoryKimball",
            "id": 12725111,
            "node_id": "MDQ6VXNlcjEyNzI1MTEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregoryKimball",
            "html_url": "https://github.com/GregoryKimball",
            "followers_url": "https://api.github.com/users/GregoryKimball/followers",
            "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
            "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
            "repos_url": "https://api.github.com/users/GregoryKimball/repos",
            "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
            "type": "User",
            "site_admin": false
        },
        "open_issues": 16,
        "closed_issues": 3,
        "state": "open",
        "created_at": "2022-10-21T19:29:07Z",
        "updated_at": "2024-05-22T23:20:04Z",
        "due_on": null,
        "closed_at": null
    },
    "comments": 0,
    "created_at": "2023-08-31T08:34:47Z",
    "updated_at": "2023-09-27T02:34:02Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "I'm trying to train an xgboost model on a machine with 8xA100 GPUs with 80GB memory each but I'm getting an out of memory error:\r\n`MemoryError('std::bad_alloc: out_of_memory: CUDA error at: .../include/rmm/mr/device/cuda_memory_resource.hpp')`. The error is slightly different if I use `rmm_pool_size` parameter but it is still a memory error `\"MemoryError('std::bad_alloc: out_of_memory: RMM failure at:../include/rmm/mr/device/pool_memory_resource.hpp:196: Maximum pool size exceeded')`\r\n\r\nI'm using a `LocalCUDACluster` to distribute the workload amongst the 8 GPUs. I can tell by looking at the dask dashboard, that the data is mostly loading into a single GPU and all of the other GPUs are sitting empty and idle. \r\n\r\nI read the data using `dask_cudf.read_parquet(file_name, blocksize=int(2e4))` and it is a dataframe of size `(20459297, 213)`. Though I would like to try it with much larger datasets.  The training completes successfully with a smaller dataframe of size `(16304159, 213)` and fewer workers but it still mostly uses a single GPU. \r\n\r\nEdit: Here's a screenshot of the dashboard when the model is successfully training - note this is with only 2 GPUs and the smaller dataframe noted above\r\n\r\n<img width=\"1672\" alt=\"Screenshot\" src=\"https://github.com/rapidsai/cudf/assets/18453604/98706b71-19e3-4266-9c9c-23472994675c\">\r\n\r\nThe GPUs are running CUDA 12.0 and driver  525.60.13\r\nHere are the versions of some relevant packages\r\n\r\n```\r\nxgboost                   1.7.4           rapidsai_py310h1395376_6    rapidsai\r\nrapids                    23.08.00        cuda12_py310_230809_g2a5b6f0_0    rapidsai\r\npython                    3.10.12         hd12c33a_0_cpython    conda-forge\r\nrapids-xgboost            23.08.00        cuda12_py310_230809_g2a5b6f0_0    rapidsai\r\ncuda-version              12.0                 hffde075_2    conda-forge\r\ncudf                      23.08.00        cuda12_py310_230809_g8150d38e08_0    rapidsai\r\ndask                      2023.7.1           pyhd8ed1ab_0    conda-forge\r\ndask-core                 2023.7.1           pyhd8ed1ab_0    conda-forge\r\ndask-cuda                 23.08.00        py310_230809_gefbd6ca_0    rapidsai\r\ndask-cudf                 23.08.00        cuda12_py310_230809_g8150d38e08_0    rapidsai\r\n```\r\n\r\nAny help on the memory issue would be much appreciated\r\n\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/14016/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/rapidsai/cudf/issues/14016/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}