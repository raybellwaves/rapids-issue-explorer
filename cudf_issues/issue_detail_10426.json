{
    "url": "https://api.github.com/repos/rapidsai/cudf/issues/10426",
    "repository_url": "https://api.github.com/repos/rapidsai/cudf",
    "labels_url": "https://api.github.com/repos/rapidsai/cudf/issues/10426/labels{/name}",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/10426/comments",
    "events_url": "https://api.github.com/repos/rapidsai/cudf/issues/10426/events",
    "html_url": "https://github.com/rapidsai/cudf/issues/10426",
    "id": 1167589251,
    "node_id": "I_kwDOBWUGps5Fl_-D",
    "number": 10426,
    "title": "[BUG] .to_parquet() and .to_csv() fails and get OOM with large DataFrames.",
    "user": {
        "login": "titericz",
        "id": 6519754,
        "node_id": "MDQ6VXNlcjY1MTk3NTQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6519754?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/titericz",
        "html_url": "https://github.com/titericz",
        "followers_url": "https://api.github.com/users/titericz/followers",
        "following_url": "https://api.github.com/users/titericz/following{/other_user}",
        "gists_url": "https://api.github.com/users/titericz/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/titericz/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/titericz/subscriptions",
        "organizations_url": "https://api.github.com/users/titericz/orgs",
        "repos_url": "https://api.github.com/users/titericz/repos",
        "events_url": "https://api.github.com/users/titericz/events{/privacy}",
        "received_events_url": "https://api.github.com/users/titericz/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 599626559,
            "node_id": "MDU6TGFiZWw1OTk2MjY1NTk=",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 1139740666,
            "node_id": "MDU6TGFiZWwxMTM5NzQwNjY2",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/libcudf",
            "name": "libcudf",
            "color": "c5def5",
            "default": false,
            "description": "Affects libcudf (C++/CUDA) code."
        },
        {
            "id": 1185244142,
            "node_id": "MDU6TGFiZWwxMTg1MjQ0MTQy",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/cuIO",
            "name": "cuIO",
            "color": "fef2c0",
            "default": false,
            "description": "cuIO issue"
        },
        {
            "id": 1322252617,
            "node_id": "MDU6TGFiZWwxMzIyMjUyNjE3",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/Performance",
            "name": "Performance",
            "color": "C2E0C6",
            "default": false,
            "description": "Performance related issue"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": {
        "url": "https://api.github.com/repos/rapidsai/cudf/milestones/20",
        "html_url": "https://github.com/rapidsai/cudf/milestone/20",
        "labels_url": "https://api.github.com/repos/rapidsai/cudf/milestones/20/labels",
        "id": 8568142,
        "node_id": "MI_kwDOBWUGps4Agr1O",
        "number": 20,
        "title": "Stabilizing large workflows (OOM, spilling, partitioning)",
        "description": "",
        "creator": {
            "login": "GregoryKimball",
            "id": 12725111,
            "node_id": "MDQ6VXNlcjEyNzI1MTEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregoryKimball",
            "html_url": "https://github.com/GregoryKimball",
            "followers_url": "https://api.github.com/users/GregoryKimball/followers",
            "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
            "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
            "repos_url": "https://api.github.com/users/GregoryKimball/repos",
            "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
            "type": "User",
            "site_admin": false
        },
        "open_issues": 16,
        "closed_issues": 3,
        "state": "open",
        "created_at": "2022-10-21T19:29:07Z",
        "updated_at": "2024-05-22T23:20:04Z",
        "due_on": null,
        "closed_at": null
    },
    "comments": 7,
    "created_at": "2022-03-13T14:00:51Z",
    "updated_at": "2024-02-23T18:42:52Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nWritting large DataFrames to disk fails and gets memory error:\r\n>>>df.to_parquet('myfile.parquet')\r\n>>>RuntimeError: CUDA error at: /home/giba/anaconda3/envs/rapids-22.02/include/rmm/cuda_stream_view.hpp:81: cudaErrorIllegalAddress an illegal memory access was encountered\r\n\r\n**Steps/Code to reproduce bug**\r\nMy DataFrame have shape: (414395052, 4)\r\ndtypes: var0 int32, var1 int32, var2 int8, var3 int8\r\ndf.memory_usage().sum() returns: 4143950520  (4GB)\r\n\r\n**Expected behavior**\r\nFile write to disk in .parquet or .csv format without issues.\r\n\r\n**Environment overview (please complete the following information)**\r\nUsed conda with default RAPIDS 22.02 install.\r\n\r\n**Environment details**\r\nUsing a 32GB V100 GPU.\r\n\r\n**Additional context**\r\nSending cudf Dataframe to Pandas then calling .to_parquet() works:\r\n>>> df.to_pandas().to_parquet('myfile.parquet')\r\n\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/10426/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/rapidsai/cudf/issues/10426/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}