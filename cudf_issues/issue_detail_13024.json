{
    "url": "https://api.github.com/repos/rapidsai/cudf/issues/13024",
    "repository_url": "https://api.github.com/repos/rapidsai/cudf",
    "labels_url": "https://api.github.com/repos/rapidsai/cudf/issues/13024/labels{/name}",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/13024/comments",
    "events_url": "https://api.github.com/repos/rapidsai/cudf/issues/13024/events",
    "html_url": "https://github.com/rapidsai/cudf/issues/13024",
    "id": 1644346189,
    "node_id": "I_kwDOBWUGps5iArtN",
    "number": 13024,
    "title": "[FEA] Performance issue with the Parquet reader for very large schemas (especially when containing strings)",
    "user": {
        "login": "nvdbaranec",
        "id": 56695930,
        "node_id": "MDQ6VXNlcjU2Njk1OTMw",
        "avatar_url": "https://avatars.githubusercontent.com/u/56695930?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/nvdbaranec",
        "html_url": "https://github.com/nvdbaranec",
        "followers_url": "https://api.github.com/users/nvdbaranec/followers",
        "following_url": "https://api.github.com/users/nvdbaranec/following{/other_user}",
        "gists_url": "https://api.github.com/users/nvdbaranec/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/nvdbaranec/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/nvdbaranec/subscriptions",
        "organizations_url": "https://api.github.com/users/nvdbaranec/orgs",
        "repos_url": "https://api.github.com/users/nvdbaranec/repos",
        "events_url": "https://api.github.com/users/nvdbaranec/events{/privacy}",
        "received_events_url": "https://api.github.com/users/nvdbaranec/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 599626561,
            "node_id": "MDU6TGFiZWw1OTk2MjY1NjE=",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        },
        {
            "id": 1139740666,
            "node_id": "MDU6TGFiZWwxMTM5NzQwNjY2",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/libcudf",
            "name": "libcudf",
            "color": "c5def5",
            "default": false,
            "description": "Affects libcudf (C++/CUDA) code."
        },
        {
            "id": 1185244142,
            "node_id": "MDU6TGFiZWwxMTg1MjQ0MTQy",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/cuIO",
            "name": "cuIO",
            "color": "fef2c0",
            "default": false,
            "description": "cuIO issue"
        },
        {
            "id": 1322252617,
            "node_id": "MDU6TGFiZWwxMzIyMjUyNjE3",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/Performance",
            "name": "Performance",
            "color": "C2E0C6",
            "default": false,
            "description": "Performance related issue"
        },
        {
            "id": 2546521024,
            "node_id": "MDU6TGFiZWwyNTQ2NTIxMDI0",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/improvement",
            "name": "improvement",
            "color": "bfd4f2",
            "default": false,
            "description": "Improvement / enhancement to an existing function"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": {
        "login": "SrikarVanavasam",
        "id": 26264495,
        "node_id": "MDQ6VXNlcjI2MjY0NDk1",
        "avatar_url": "https://avatars.githubusercontent.com/u/26264495?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/SrikarVanavasam",
        "html_url": "https://github.com/SrikarVanavasam",
        "followers_url": "https://api.github.com/users/SrikarVanavasam/followers",
        "following_url": "https://api.github.com/users/SrikarVanavasam/following{/other_user}",
        "gists_url": "https://api.github.com/users/SrikarVanavasam/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/SrikarVanavasam/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/SrikarVanavasam/subscriptions",
        "organizations_url": "https://api.github.com/users/SrikarVanavasam/orgs",
        "repos_url": "https://api.github.com/users/SrikarVanavasam/repos",
        "events_url": "https://api.github.com/users/SrikarVanavasam/events{/privacy}",
        "received_events_url": "https://api.github.com/users/SrikarVanavasam/received_events",
        "type": "User",
        "site_admin": false
    },
    "assignees": [],
    "milestone": {
        "url": "https://api.github.com/repos/rapidsai/cudf/milestones/22",
        "html_url": "https://github.com/rapidsai/cudf/milestone/22",
        "labels_url": "https://api.github.com/repos/rapidsai/cudf/milestones/22/labels",
        "id": 8672393,
        "node_id": "MI_kwDOBWUGps4AhFSJ",
        "number": 22,
        "title": "Parquet continuous improvement",
        "description": "",
        "creator": {
            "login": "GregoryKimball",
            "id": 12725111,
            "node_id": "MDQ6VXNlcjEyNzI1MTEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregoryKimball",
            "html_url": "https://github.com/GregoryKimball",
            "followers_url": "https://api.github.com/users/GregoryKimball/followers",
            "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
            "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
            "repos_url": "https://api.github.com/users/GregoryKimball/repos",
            "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
            "type": "User",
            "site_admin": false
        },
        "open_issues": 38,
        "closed_issues": 37,
        "state": "open",
        "created_at": "2022-11-19T18:08:31Z",
        "updated_at": "2024-06-06T18:40:39Z",
        "due_on": null,
        "closed_at": null
    },
    "comments": 2,
    "created_at": "2023-03-28T17:01:42Z",
    "updated_at": "2024-02-17T00:03:10Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "\r\nFor parquet files that contain very large schemas with strings (either large numbers of columns, or large numbers of nested columns) we pay a very heavy price postprocessing the string data after the core decode kernels runs.  \r\n\r\nEssentially, the \"decode\" process for strings is just emitting a large array of pointer/size pairs that are then passed to other cudf functions to reconstruct actual columns.    The problem is that we are doing this with no batching - each output string column results in an entire cudf function call (`make_strings_column`) with multiple internal kernel calls each.  In situations with thousands of columns, this gets very expensive.\r\n\r\n![image](https://user-images.githubusercontent.com/56695930/228312025-67ea3177-9d67-4e84-84e5-cb317c895001.png)\r\n\r\nIn the image above, the green span represents the time spent in the decode kernel and the time spent in all of the `make_strings_column` calls afterwards.  The time is totally dominated by the many many calls to `make_strings_column` (the red span).  \r\n\r\nIdeally, we would have some kind of batched interface to `make_strings_column`  (`make_strings_columns` ?) that can do the work for the thousands of output columns coalesced into fewer kernels.  \r\n\r\n\r\nOn a related note, the area under the blue line represents a similar problem involving preprocessing the file (thousands of calls to `thrust::reduce` and `thrust::exclusive_scan_by_key`).   This has been largely addressed by this PR  https://github.com/rapidsai/cudf/pull/12931  \r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/13024/reactions",
        "total_count": 1,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 1,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/rapidsai/cudf/issues/13024/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}