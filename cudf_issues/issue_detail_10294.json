{
    "url": "https://api.github.com/repos/rapidsai/cudf/issues/10294",
    "repository_url": "https://api.github.com/repos/rapidsai/cudf",
    "labels_url": "https://api.github.com/repos/rapidsai/cudf/issues/10294/labels{/name}",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/10294/comments",
    "events_url": "https://api.github.com/repos/rapidsai/cudf/issues/10294/events",
    "html_url": "https://github.com/rapidsai/cudf/issues/10294",
    "id": 1138863589,
    "node_id": "I_kwDOBWUGps5D4a3l",
    "number": 10294,
    "title": "[FEA] Dask support for groupby correlation and covariance",
    "user": {
        "login": "beckernick",
        "id": 8457388,
        "node_id": "MDQ6VXNlcjg0NTczODg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/8457388?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/beckernick",
        "html_url": "https://github.com/beckernick",
        "followers_url": "https://api.github.com/users/beckernick/followers",
        "following_url": "https://api.github.com/users/beckernick/following{/other_user}",
        "gists_url": "https://api.github.com/users/beckernick/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/beckernick/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/beckernick/subscriptions",
        "organizations_url": "https://api.github.com/users/beckernick/orgs",
        "repos_url": "https://api.github.com/users/beckernick/repos",
        "events_url": "https://api.github.com/users/beckernick/events{/privacy}",
        "received_events_url": "https://api.github.com/users/beckernick/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 599626561,
            "node_id": "MDU6TGFiZWw1OTk2MjY1NjE=",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        },
        {
            "id": 1139741213,
            "node_id": "MDU6TGFiZWwxMTM5NzQxMjEz",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/Python",
            "name": "Python",
            "color": "1d76db",
            "default": false,
            "description": "Affects Python cuDF API."
        },
        {
            "id": 1185240898,
            "node_id": "MDU6TGFiZWwxMTg1MjQwODk4",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/dask",
            "name": "dask",
            "color": "fcc25d",
            "default": false,
            "description": "Dask issue"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2022-02-15T15:42:17Z",
    "updated_at": "2024-02-23T18:42:55Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "Today, cuDF Python supports `groupby.corr` and has a PR in review for `groupby.cov`. I'd like to be able to use these with Dask on GPUs, like I can with Dask on CPUs (note that the distributed algorithm doesn't actually rely on these primitives).\r\n\r\nThe Dask [implementation](https://github.com/dask/dask/blob/20e924618999febeac706b20212104fe4f3ea61d/dask/dataframe/groupby.py#L355-L507) looks to have some challenges to running with a cuDF backend, including:\r\n- Hardcoded pandas return types in some functions\r\n- Passing arguments to groupby.apply (which cuDF doesn't currently support)\r\n- Using groupby.apply(arbitrary_func), which can be slow in cuDF\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\nimport dask_cudf\r\nimport cudf\r\n\u200b\r\ndf = pd.DataFrame({\r\n    \"a\": [0,0,1,0,0,1,1,1,1,1],\r\n    \"b\": [0,0.3,0,-4,0,-3,1,1,11,1],\r\n    \"c\": [19,0,30,0,0,1,41,1,1,1],\r\n})\r\ngdf = cudf.from_pandas(df)\r\nddf = dd.from_pandas(df, 2)\r\ngddf = dask_cudf.from_dask_dataframe(ddf)\r\n\u200b\r\nprint(ddf.groupby(\"a\").corr().compute())\r\nprint(gddf.groupby(\"a\").corr().compute())\r\n            b         c\r\na                      \r\n0 b  1.000000  0.300100\r\n  c  0.300100  1.000000\r\n1 b  1.000000 -0.200625\r\n  c -0.200625  1.000000\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nFile ~/conda/envs/rapids-22.04/lib/python3.8/site-packages/dask/dataframe/utils.py:176, in raise_on_meta_error(funcname, udf)\r\n    175 try:\r\n--> 176     yield\r\n    177 except Exception as e:\r\n\r\nFile ~/conda/envs/rapids-22.04/lib/python3.8/site-packages/dask/dataframe/core.py:5984, in _emulate(func, udf, *args, **kwargs)\r\n   5983 with raise_on_meta_error(funcname(func), udf=udf):\r\n-> 5984     return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n\r\nFile ~/conda/envs/rapids-22.04/lib/python3.8/site-packages/dask/dataframe/groupby.py:447, in _cov_chunk(df, *by)\r\n    445 x = g.sum()\r\n--> 447 mul = g.apply(_mul_cols, cols=cols).reset_index(level=-1, drop=True)\r\n    449 n = g[x.columns].count().rename(columns=lambda c: f\"{c}-count\")\r\n\r\nTypeError: apply() got an unexpected keyword argument 'cols'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nValueError                                Traceback (most recent call last)\r\nInput In [85], in <module>\r\n     13 gddf = dask_cudf.from_dask_dataframe(ddf)\r\n     15 print(ddf.groupby(\"a\").corr().compute())\r\n---> 16 print(gddf.groupby(\"a\").corr().compute())\r\n\r\nFile ~/conda/envs/rapids-22.04/lib/python3.8/site-packages/dask/dataframe/groupby.py:1475, in _GroupBy.corr(self, ddof, split_every, split_out)\r\n   1470 @derived_from(pd.DataFrame)\r\n   1471 def corr(self, ddof=1, split_every=None, split_out=1):\r\n   1472     \"\"\"Groupby correlation:\r\n   1473     corr(X, Y) = cov(X, Y) / (std_x * std_y)\r\n   1474     \"\"\"\r\n-> 1475     return self.cov(split_every=split_every, split_out=split_out, std=True)\r\n\r\nFile ~/conda/envs/rapids-22.04/lib/python3.8/site-packages/dask/dataframe/groupby.py:1500, in _GroupBy.cov(self, ddof, split_every, split_out, std)\r\n   1497         sliced_plus = list(self._slice) + list(self.by)\r\n   1498         self.obj = self.obj[sliced_plus]\r\n-> 1500 result = aca(\r\n   1501     [self.obj, self.by]\r\n   1502     if not isinstance(self.by, list)\r\n   1503     else [self.obj] + self.by,\r\n   1504     chunk=_cov_chunk,\r\n   1505     aggregate=_cov_agg,\r\n   1506     combine=_cov_combine,\r\n   1507     token=self._token_prefix + \"cov\",\r\n   1508     aggregate_kwargs={\"ddof\": ddof, \"levels\": levels, \"std\": std},\r\n   1509     combine_kwargs={\"levels\": levels},\r\n   1510     split_every=split_every,\r\n   1511     split_out=split_out,\r\n   1512     split_out_setup=split_out_on_index,\r\n   1513     sort=self.sort,\r\n   1514 )\r\n   1516 if isinstance(self.obj, Series):\r\n   1517     result = result[result.columns[0]]\r\n\r\nFile ~/conda/envs/rapids-22.04/lib/python3.8/site-packages/dask/dataframe/core.py:5935, in apply_concat_apply(args, chunk, aggregate, combine, meta, token, chunk_kwargs, aggregate_kwargs, combine_kwargs, split_every, split_out, split_out_setup, split_out_setup_kwargs, sort, ignore_index, **kwargs)\r\n   5932         dsk[(b, j)] = (aggregate, conc)\r\n   5934 if meta is no_default:\r\n-> 5935     meta_chunk = _emulate(chunk, *args, udf=True, **chunk_kwargs)\r\n   5936     meta = _emulate(\r\n   5937         aggregate, _concat([meta_chunk], ignore_index), udf=True, **aggregate_kwargs\r\n   5938     )\r\n   5939 meta = make_meta(\r\n   5940     meta,\r\n   5941     index=(getattr(make_meta(dfs[0]), \"index\", None) if dfs else None),\r\n   5942     parent_meta=dfs[0]._meta,\r\n   5943 )\r\n\r\nFile ~/conda/envs/rapids-22.04/lib/python3.8/site-packages/dask/dataframe/core.py:5984, in _emulate(func, udf, *args, **kwargs)\r\n   5979 \"\"\"\r\n   5980 Apply a function using args / kwargs. If arguments contain dd.DataFrame /\r\n   5981 dd.Series, using internal cache (``_meta``) for calculation\r\n   5982 \"\"\"\r\n   5983 with raise_on_meta_error(funcname(func), udf=udf):\r\n-> 5984     return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n\r\nFile ~/conda/envs/rapids-22.04/lib/python3.8/contextlib.py:131, in _GeneratorContextManager.__exit__(self, type, value, traceback)\r\n    129     value = type()\r\n    130 try:\r\n--> 131     self.gen.throw(type, value, traceback)\r\n    132 except StopIteration as exc:\r\n    133     # Suppress StopIteration *unless* it's the same exception that\r\n    134     # was passed to throw().  This prevents a StopIteration\r\n    135     # raised inside the \"with\" statement from being suppressed.\r\n    136     return exc is not value\r\n\r\nFile ~/conda/envs/rapids-22.04/lib/python3.8/site-packages/dask/dataframe/utils.py:197, in raise_on_meta_error(funcname, udf)\r\n    188 msg += (\r\n    189     \"Original error is below:\\n\"\r\n    190     \"------------------------\\n\"\r\n   (...)\r\n    194     \"{2}\"\r\n    195 )\r\n    196 msg = msg.format(f\" in `{funcname}`\" if funcname else \"\", repr(e), tb)\r\n--> 197 raise ValueError(msg) from e\r\n\r\nValueError: Metadata inference failed in `_cov_chunk`.\r\n\r\nYou have supplied a custom function and Dask is unable to \r\ndetermine the type of output that that function returns. \r\n\r\nTo resolve this please provide a meta= keyword.\r\nThe docstring of the Dask function you ran should have more information.\r\n\r\nOriginal error is below:\r\n------------------------\r\nTypeError(\"apply() got an unexpected keyword argument 'cols'\")\r\n\r\nTraceback:\r\n---------\r\n  File \"/home/nicholasb/conda/envs/rapids-22.04/lib/python3.8/site-packages/dask/dataframe/utils.py\", line 176, in raise_on_meta_error\r\n    yield\r\n  File \"/home/nicholasb/conda/envs/rapids-22.04/lib/python3.8/site-packages/dask/dataframe/core.py\", line 5984, in _emulate\r\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\r\n  File \"/home/nicholasb/conda/envs/rapids-22.04/lib/python3.8/site-packages/dask/dataframe/groupby.py\", line 447, in _cov_chunk\r\n    mul = g.apply(_mul_cols, cols=cols).reset_index(level=-1, drop=True)\r\n```",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/10294/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/rapidsai/cudf/issues/10294/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}