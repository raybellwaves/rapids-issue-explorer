{
    "url": "https://api.github.com/repos/rapidsai/cudf/issues/14795",
    "repository_url": "https://api.github.com/repos/rapidsai/cudf",
    "labels_url": "https://api.github.com/repos/rapidsai/cudf/issues/14795/labels{/name}",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/14795/comments",
    "events_url": "https://api.github.com/repos/rapidsai/cudf/issues/14795/events",
    "html_url": "https://github.com/rapidsai/cudf/issues/14795",
    "id": 2090437127,
    "node_id": "I_kwDOBWUGps58mYoH",
    "number": 14795,
    "title": "[BUG] Can't append cudf pandas dataframe to an open file with UnicodeEncodeError",
    "user": {
        "login": "jacobtomlinson",
        "id": 1610850,
        "node_id": "MDQ6VXNlcjE2MTA4NTA=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1610850?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jacobtomlinson",
        "html_url": "https://github.com/jacobtomlinson",
        "followers_url": "https://api.github.com/users/jacobtomlinson/followers",
        "following_url": "https://api.github.com/users/jacobtomlinson/following{/other_user}",
        "gists_url": "https://api.github.com/users/jacobtomlinson/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/jacobtomlinson/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/jacobtomlinson/subscriptions",
        "organizations_url": "https://api.github.com/users/jacobtomlinson/orgs",
        "repos_url": "https://api.github.com/users/jacobtomlinson/repos",
        "events_url": "https://api.github.com/users/jacobtomlinson/events{/privacy}",
        "received_events_url": "https://api.github.com/users/jacobtomlinson/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 599626559,
            "node_id": "MDU6TGFiZWw1OTk2MjY1NTk=",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-01-19T12:17:38Z",
    "updated_at": "2024-03-04T15:41:58Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nThis bug was found while playing around with the [One Billion Row Challenge](https://medium.com/coiled-hq/1brc-in-python-with-dask-3cdee6a56a2d).\r\n\r\nIf I have a string column that contains utf-8 characters and I try and append that DataFrame to an open file I get a `UnicodeEncodeError`. It only happens if I use CuPy to generate the random data, it works with NumPy but is much slower at the scale I'm working at.\r\n\r\n**Steps/Code to reproduce bug**\r\n\r\n```python\r\n%load_ext cudf.pandas\r\nimport pandas as pd\r\nimport cupy as cp\r\n\r\n# Generate some data\r\nstations = pd.Series(['San Jos\u00e9', 'Ankara', 'Kampala', 'Tallinn', 'Gjoa Haven', 'Luanda', 'Cairo', 'Phnom Penh', 'Thessaloniki', 'Split', 'Palermo', 'Ouarzazate', 'Mandalay'])\r\ndf = pd.DataFrame({\"station\": cp.random.randint(0, len(stations)-1, 10_000)})\r\ndf.station = df.station.map(stations)\r\n\r\n# Append to the output file\r\nwith open(\"foo.txt\", \"a\") as fh:\r\n    df.to_csv(fh, sep=\";\", header=False, index=False)\r\n```\r\n\r\n```pytb\r\n---------------------------------------------------------------------------\r\nException                                 Traceback (most recent call last)\r\nFile /opt/conda/lib/python3.10/site-packages/cudf/pandas/fast_slow_proxy.py:836, in _fast_slow_function_call(func, *args, **kwargs)\r\n    831 with nvtx.annotate(\r\n    832     \"EXECUTE_FAST\",\r\n    833     color=_CUDF_PANDAS_NVTX_COLORS[\"EXECUTE_FAST\"],\r\n    834     domain=\"cudf_pandas\",\r\n    835 ):\r\n--> 836     fast_args, fast_kwargs = _fast_arg(args), _fast_arg(kwargs)\r\n    837     result = func(*fast_args, **fast_kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/cudf/pandas/fast_slow_proxy.py:955, in _fast_arg(arg)\r\n    954 seen: Set[int] = set()\r\n--> 955 return _transform_arg(arg, \"_fsproxy_fast\", seen)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/cudf/pandas/fast_slow_proxy.py:882, in _transform_arg(arg, attribute_name, seen)\r\n    880 if type(arg) is tuple:\r\n    881     # Must come first to avoid infinite recursion\r\n--> 882     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)\r\n    883 elif hasattr(arg, \"__getnewargs_ex__\"):\r\n    884     # Partial implementation of to reconstruct with\r\n    885     # transformed pieces\r\n    886     # This handles scipy._lib._bunch._make_tuple_bunch\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/cudf/pandas/fast_slow_proxy.py:882, in <genexpr>(.0)\r\n    880 if type(arg) is tuple:\r\n    881     # Must come first to avoid infinite recursion\r\n--> 882     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)\r\n    883 elif hasattr(arg, \"__getnewargs_ex__\"):\r\n    884     # Partial implementation of to reconstruct with\r\n    885     # transformed pieces\r\n    886     # This handles scipy._lib._bunch._make_tuple_bunch\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/cudf/pandas/fast_slow_proxy.py:882, in _transform_arg(arg, attribute_name, seen)\r\n    880 if type(arg) is tuple:\r\n    881     # Must come first to avoid infinite recursion\r\n--> 882     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)\r\n    883 elif hasattr(arg, \"__getnewargs_ex__\"):\r\n    884     # Partial implementation of to reconstruct with\r\n    885     # transformed pieces\r\n    886     # This handles scipy._lib._bunch._make_tuple_bunch\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/cudf/pandas/fast_slow_proxy.py:882, in <genexpr>(.0)\r\n    880 if type(arg) is tuple:\r\n    881     # Must come first to avoid infinite recursion\r\n--> 882     return tuple(_transform_arg(a, attribute_name, seen) for a in arg)\r\n    883 elif hasattr(arg, \"__getnewargs_ex__\"):\r\n    884     # Partial implementation of to reconstruct with\r\n    885     # transformed pieces\r\n    886     # This handles scipy._lib._bunch._make_tuple_bunch\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/cudf/pandas/fast_slow_proxy.py:938, in _transform_arg(arg, attribute_name, seen)\r\n    933 elif isinstance(arg, Iterator) and attribute_name == \"_fsproxy_fast\":\r\n    934     # this may include consumable objects like generators or\r\n    935     # IOBase objects, which we don't want unavailable to the slow\r\n    936     # path in case of fallback. So, we raise here and ensure the\r\n    937     # slow path is taken:\r\n--> 938     raise Exception()\r\n    939 elif isinstance(arg, types.FunctionType):\r\n\r\nException: \r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nUnicodeEncodeError                        Traceback (most recent call last)\r\nCell In[1], line 13\r\n     11 # Append to the output file\r\n     12 with open(\"foo.txt\", \"a\") as fh:\r\n---> 13     df.to_csv(fh, sep=\";\", header=False, index=False)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/cudf/pandas/fast_slow_proxy.py:785, in _CallableProxyMixin.__call__(self, *args, **kwargs)\r\n    784 def __call__(self, *args, **kwargs) -> Any:\r\n--> 785     result, _ = _fast_slow_function_call(\r\n    786         # We cannot directly call self here because we need it to be\r\n    787         # converted into either the fast or slow object (by\r\n    788         # _fast_slow_function_call) to avoid infinite recursion.\r\n    789         # TODO: When Python 3.11 is the minimum supported Python version\r\n    790         # this can use operator.call\r\n    791         lambda fn, args, kwargs: fn(*args, **kwargs),\r\n    792         self,\r\n    793         args,\r\n    794         kwargs,\r\n    795     )\r\n    796     return result\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/cudf/pandas/fast_slow_proxy.py:850, in _fast_slow_function_call(func, *args, **kwargs)\r\n    848         slow_args, slow_kwargs = _slow_arg(args), _slow_arg(kwargs)\r\n    849         with disable_module_accelerator():\r\n--> 850             result = func(*slow_args, **slow_kwargs)\r\n    851 return _maybe_wrap_result(result, func, *args, **kwargs), fast\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/cudf/pandas/fast_slow_proxy.py:791, in _CallableProxyMixin.__call__.<locals>.<lambda>(fn, args, kwargs)\r\n    784 def __call__(self, *args, **kwargs) -> Any:\r\n    785     result, _ = _fast_slow_function_call(\r\n    786         # We cannot directly call self here because we need it to be\r\n    787         # converted into either the fast or slow object (by\r\n    788         # _fast_slow_function_call) to avoid infinite recursion.\r\n    789         # TODO: When Python 3.11 is the minimum supported Python version\r\n    790         # this can use operator.call\r\n--> 791         lambda fn, args, kwargs: fn(*args, **kwargs),\r\n    792         self,\r\n    793         args,\r\n    794         kwargs,\r\n    795     )\r\n    796     return result\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211, in deprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper(*args, **kwargs)\r\n    209     else:\r\n    210         kwargs[new_arg_name] = new_arg_value\r\n--> 211 return func(*args, **kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:3720, in NDFrame.to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\r\n   3709 df = self if isinstance(self, ABCDataFrame) else self.to_frame()\r\n   3711 formatter = DataFrameFormatter(\r\n   3712     frame=df,\r\n   3713     header=header,\r\n   (...)\r\n   3717     decimal=decimal,\r\n   3718 )\r\n-> 3720 return DataFrameRenderer(formatter).to_csv(\r\n   3721     path_or_buf,\r\n   3722     lineterminator=lineterminator,\r\n   3723     sep=sep,\r\n   3724     encoding=encoding,\r\n   3725     errors=errors,\r\n   3726     compression=compression,\r\n   3727     quoting=quoting,\r\n   3728     columns=columns,\r\n   3729     index_label=index_label,\r\n   3730     mode=mode,\r\n   3731     chunksize=chunksize,\r\n   3732     quotechar=quotechar,\r\n   3733     date_format=date_format,\r\n   3734     doublequote=doublequote,\r\n   3735     escapechar=escapechar,\r\n   3736     storage_options=storage_options,\r\n   3737 )\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211, in deprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper(*args, **kwargs)\r\n    209     else:\r\n    210         kwargs[new_arg_name] = new_arg_value\r\n--> 211 return func(*args, **kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/formats/format.py:1189, in DataFrameRenderer.to_csv(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\r\n   1168     created_buffer = False\r\n   1170 csv_formatter = CSVFormatter(\r\n   1171     path_or_buf=path_or_buf,\r\n   1172     lineterminator=lineterminator,\r\n   (...)\r\n   1187     formatter=self.fmt,\r\n   1188 )\r\n-> 1189 csv_formatter.save()\r\n   1191 if created_buffer:\r\n   1192     assert isinstance(path_or_buf, StringIO)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/formats/csvs.py:261, in CSVFormatter.save(self)\r\n    241 with get_handle(\r\n    242     self.filepath_or_buffer,\r\n    243     self.mode,\r\n   (...)\r\n    249 \r\n    250     # Note: self.encoding is irrelevant here\r\n    251     self.writer = csvlib.writer(\r\n    252         handles.handle,\r\n    253         lineterminator=self.lineterminator,\r\n   (...)\r\n    258         quotechar=self.quotechar,\r\n    259     )\r\n--> 261     self._save()\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/formats/csvs.py:266, in CSVFormatter._save(self)\r\n    264 if self._need_to_save_header:\r\n    265     self._save_header()\r\n--> 266 self._save_body()\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/formats/csvs.py:304, in CSVFormatter._save_body(self)\r\n    302 if start_i >= end_i:\r\n    303     break\r\n--> 304 self._save_chunk(start_i, end_i)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/formats/csvs.py:315, in CSVFormatter._save_chunk(self, start_i, end_i)\r\n    312 data = [res.iget_values(i) for i in range(len(res.items))]\r\n    314 ix = self.data_index[slicer]._format_native_types(**self._number_format)\r\n--> 315 libwriters.write_csv_rows(\r\n    316     data,\r\n    317     ix,\r\n    318     self.nlevels,\r\n    319     self.cols,\r\n    320     self.writer,\r\n    321 )\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/pandas/_libs/writers.pyx:72, in pandas._libs.writers.write_csv_rows()\r\n\r\nUnicodeEncodeError: 'ascii' codec can't encode character '\\xe9' in position 7: ordinal not in range(128)\r\n```\r\n\r\n**Expected behavior**\r\n\r\nThe dataframe should be appended to the file.\r\n\r\n**Environment overview (please complete the following information)**\r\n\r\n```bash\r\ndocker run --gpus all --pull always --rm -it \\\r\n    --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 \\\r\n    -p 8888:8888 -p 8787:8787 -p 8786:8786 \\\r\n    rapidsai/notebooks:23.12-cuda12.0-py3.10\r\n```\r\n\r\n**Additional context**\r\n\r\nIf I do a plain `df.to_csv(\"foo.txt\", ...` it works, but I need to be able to append to the file.\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/14795/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/rapidsai/cudf/issues/14795/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}