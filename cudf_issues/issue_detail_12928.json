{
    "url": "https://api.github.com/repos/rapidsai/cudf/issues/12928",
    "repository_url": "https://api.github.com/repos/rapidsai/cudf",
    "labels_url": "https://api.github.com/repos/rapidsai/cudf/issues/12928/labels{/name}",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/12928/comments",
    "events_url": "https://api.github.com/repos/rapidsai/cudf/issues/12928/events",
    "html_url": "https://github.com/rapidsai/cudf/issues/12928",
    "id": 1621673262,
    "node_id": "I_kwDOBWUGps5gqMUu",
    "number": 12928,
    "title": "[FEA] Faster dataframe to cupy conversion when dataframe is a single allocation",
    "user": {
        "login": "beckernick",
        "id": 8457388,
        "node_id": "MDQ6VXNlcjg0NTczODg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/8457388?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/beckernick",
        "html_url": "https://github.com/beckernick",
        "followers_url": "https://api.github.com/users/beckernick/followers",
        "following_url": "https://api.github.com/users/beckernick/following{/other_user}",
        "gists_url": "https://api.github.com/users/beckernick/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/beckernick/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/beckernick/subscriptions",
        "organizations_url": "https://api.github.com/users/beckernick/orgs",
        "repos_url": "https://api.github.com/users/beckernick/repos",
        "events_url": "https://api.github.com/users/beckernick/events{/privacy}",
        "received_events_url": "https://api.github.com/users/beckernick/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 599626561,
            "node_id": "MDU6TGFiZWw1OTk2MjY1NjE=",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        },
        {
            "id": 1013987352,
            "node_id": "MDU6TGFiZWwxMDEzOTg3MzUy",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/0%20-%20Backlog",
            "name": "0 - Backlog",
            "color": "d4c5f9",
            "default": false,
            "description": "In queue waiting for assignment"
        },
        {
            "id": 1139741213,
            "node_id": "MDU6TGFiZWwxMTM5NzQxMjEz",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/Python",
            "name": "Python",
            "color": "1d76db",
            "default": false,
            "description": "Affects Python cuDF API."
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2023-03-13T14:59:58Z",
    "updated_at": "2024-05-17T18:29:20Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "When we convert a dataframe to a cupy array, we iterate over each column (as they\u2019re independent allocations) and assign each one to a column in an empty matrix. This means it can be slow for thousands or millions of small columns.\r\n\r\nIn a select set of circumstances, all of the columns in a DataFrame may be part of a single, contiguous allocation of memory. One scenario in which this can occur is after a call to transpose. It would be nice if, in this scenario, we didn't need to iterate over every column when converting to a cupy array.\r\n\r\nA real-world example of when this can matter is if a user is trying to run a dot product after a calling transpose. Because of the bottleneck, we're slower than pandas by quite a bit.\r\n\r\n```python\r\nimport cudf\r\nimport cupy as cp\r\nimport pandas as pd\r\n\r\nnrows = 10000\r\nncols = 4\r\n\r\ngdf = cudf.DataFrame(cp.random.randint(0, 1000, size=(nrows, ncols)))\r\npdf = gdf.to_pandas()\r\n\r\n%time gdf.T.dot(gdf)\r\n%time pdf.T.dot(pdf)\r\nCPU times: user 1.52 s, sys: 3.96 ms, total: 1.53 s\r\nWall time: 1.53 s\r\nCPU times: user 912 \u00b5s, sys: 41 \u00b5s, total: 953 \u00b5s\r\nWall time: 855 \u00b5s\r\n```\r\n\r\nIf we were to do any special casing here, we'd want to closely evaluate any impact on performance for the more general case, as the dataframe to cupy codepath is used across the board.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/12928/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/rapidsai/cudf/issues/12928/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}