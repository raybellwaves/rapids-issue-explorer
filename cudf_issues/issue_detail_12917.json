{
    "url": "https://api.github.com/repos/rapidsai/cudf/issues/12917",
    "repository_url": "https://api.github.com/repos/rapidsai/cudf",
    "labels_url": "https://api.github.com/repos/rapidsai/cudf/issues/12917/labels{/name}",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/12917/comments",
    "events_url": "https://api.github.com/repos/rapidsai/cudf/issues/12917/events",
    "html_url": "https://github.com/rapidsai/cudf/issues/12917",
    "id": 1618044646,
    "node_id": "I_kwDOBWUGps5gcWbm",
    "number": 12917,
    "title": "[BUG] Slow performance with high cardinality category columns",
    "user": {
        "login": "vaceslav",
        "id": 24871,
        "node_id": "MDQ6VXNlcjI0ODcx",
        "avatar_url": "https://avatars.githubusercontent.com/u/24871?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/vaceslav",
        "html_url": "https://github.com/vaceslav",
        "followers_url": "https://api.github.com/users/vaceslav/followers",
        "following_url": "https://api.github.com/users/vaceslav/following{/other_user}",
        "gists_url": "https://api.github.com/users/vaceslav/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/vaceslav/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/vaceslav/subscriptions",
        "organizations_url": "https://api.github.com/users/vaceslav/orgs",
        "repos_url": "https://api.github.com/users/vaceslav/repos",
        "events_url": "https://api.github.com/users/vaceslav/events{/privacy}",
        "received_events_url": "https://api.github.com/users/vaceslav/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 599626559,
            "node_id": "MDU6TGFiZWw1OTk2MjY1NTk=",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 1013987352,
            "node_id": "MDU6TGFiZWwxMDEzOTg3MzUy",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/0%20-%20Backlog",
            "name": "0 - Backlog",
            "color": "d4c5f9",
            "default": false,
            "description": "In queue waiting for assignment"
        },
        {
            "id": 1139741213,
            "node_id": "MDU6TGFiZWwxMTM5NzQxMjEz",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/Python",
            "name": "Python",
            "color": "1d76db",
            "default": false,
            "description": "Affects Python cuDF API."
        },
        {
            "id": 1322252617,
            "node_id": "MDU6TGFiZWwxMzIyMjUyNjE3",
            "url": "https://api.github.com/repos/rapidsai/cudf/labels/Performance",
            "name": "Performance",
            "color": "C2E0C6",
            "default": false,
            "description": "Performance related issue"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2023-03-09T21:53:26Z",
    "updated_at": "2023-03-24T11:03:54Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nI'm not sure if it is a bug or just limitation of cuDF architecture.\r\nPlease correct me. \r\n \r\nI have DataFrames with lot of columns and some of columns are strings with type **category**.\r\nMy data sets have about 5_000_000 rows. And category columns have more than 500_000 unique values. \r\nWhat I'm wondering is that copy of categorical columns (CPU -> GPU) takes a lot time in comparison the same data  not categorized. \r\nMore strange is that **groupby** function on categorical columns is many times slower that on non categorical columns. (Same content)   \r\n\r\n**Steps/Code to reproduce bug**\r\ncreate 2 arrays with categorical data. There are 500_000 unique values\r\n```\r\ncat1 = [ 'col1_cat_' + str(i)  for i in range(1, 500_000)] \r\ncat2 = [ 'col2_cat_' + str(i)  for i in range(1, 500_000)]\r\n```\r\ninitialize Panda DataFrame with 5_000_000 rows\r\n```\r\nrng = np.random.default_rng()\r\ncol1 = np.random.choice(a=cat1,  size=5_000_000)  \r\ncol2 = np.random.choice(a=cat2,  size=5_000_000)  \r\n\r\ndf = pd.DataFrame( {  'col1': col1,  'col2': col2,  'col3': col1,  'col4': col2  })\r\n```\r\n\r\nsize of DataFrame is about 1.5 GB\r\n```\r\n>> df.memory_usage(deep=True) / 1024 / 1024\r\nIndex      0.000122\r\ncol1     342.262686\r\ncol2     342.264298\r\ncol3     342.262686\r\ncol4     342.264298\r\ndtype: float64\r\n```\r\nWe execute groupby on CPU.  \r\n```\r\n%%time\r\ndf.groupby(['col1']).count()\r\n```\r\n*CPU times: user 2.43 s, sys: 23.8 ms, total: 2.46 s\r\nWall time: 2.46 s*\r\n\r\nNow we convert string data to category type.\r\n```\r\ndf_cat = df[['col1', 'col2', 'col3', 'col4']].astype('category')\r\n>>df_cat.memory_usage(deep=True) / 1024 / 1024\r\nIndex     0.000122\r\ncol1     69.423543\r\ncol2     69.423198\r\ncol3     69.423543\r\ncol4     69.423198\r\ndtype: float64\r\n```\r\nDF size is about 300 MB\r\n```\r\n%%time\r\ndf_cat.groupby(['col1']).count()\r\n```\r\n*CPU times: user 50.5 ms, sys: 8.29 ms, total: 58.8 ms\r\nWall time: 57.7 ms*\r\n\r\nWith categorical data we are __40 times__ faster that with non categorical data. That is expected performance.\r\nNow we copy non categorized data to the GPU\r\n```\r\n%%time\r\ngdf = cudf.DataFrame.from_pandas(df)\r\n```\r\n*CPU times: user 511 ms, sys: 221 ms, total: 731 ms\r\nWall time: 730 ms*\r\nCopy of date takes about 700ms for 1.5GB\r\n\r\n```\r\n%%time\r\ngdf.groupby(['col1']).count()\r\n```\r\n*CPU times: user 30.6 ms, sys: 3.8 ms, total: 34.4 ms\r\nWall time: 33 ms*\r\n**groupby** is about 70 times faster that on CPU (2.46s). Very good performance. IMPORTANT data is **NOT CATEGORIZED**\r\n\r\nNow we copy categorized data to the GPU and execute **groupby**\r\n```\r\n%%time\r\ngdf_cat = cudf.DataFrame.from_pandas(df_cat)\r\n```\r\n*CPU times: user 711 ms, sys: 136 ms, total: 847 ms\r\nWall time: 846 ms*\r\n```\r\n%%time\r\ngdf_cat.groupby(['col1']).count()\r\n```\r\n*CPU times: user 134 ms, sys: 55.8 ms, total: 190 ms\r\nWall time: 189 ms*\r\n\r\nAmount of data is about 300MB. cuDf needs more time to copy the data to the GPU: 846ms (730ms by non categorized 1.5 GB raw strings)\r\nBut really strange behaviour is that **groupby**  on categorized data is more than 5 times slower than with raw string data!!!\r\n**Even groupby on CPU is faster that on GPU by categorical data 57ms --> 189ms!!!!!**\r\n\r\nWhy is performance of cuDF groupy with categorical data so poor?\r\n\r\n**Expected behavior**\r\n**groupby** function on GPU should work faster or at least equal than on CPU\r\n\r\n**Environment overview (please complete the following information)**\r\nCPU RAM: 64 GB\r\nGPU RAM: 8GB\r\n\r\n**Environment details**\r\ntested on 3 different systems with 3 different NVIDIA cards\r\n\r\n**Additional context**\r\nIn attachments you can find my Jupiter Notebook with example. \r\n[category.ipynb.zip](https://github.com/rapidsai/cudf/files/10936367/category.ipynb.zip)\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/12917/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/rapidsai/cudf/issues/12917/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}