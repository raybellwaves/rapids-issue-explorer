[
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1697789452",
        "html_url": "https://github.com/rapidsai/cudf/issues/13995#issuecomment-1697789452",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13995",
        "id": 1697789452,
        "node_id": "IC_kwDOBWUGps5lMjYM",
        "user": {
            "login": "nvdbaranec",
            "id": 56695930,
            "node_id": "MDQ6VXNlcjU2Njk1OTMw",
            "avatar_url": "https://avatars.githubusercontent.com/u/56695930?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nvdbaranec",
            "html_url": "https://github.com/nvdbaranec",
            "followers_url": "https://api.github.com/users/nvdbaranec/followers",
            "following_url": "https://api.github.com/users/nvdbaranec/following{/other_user}",
            "gists_url": "https://api.github.com/users/nvdbaranec/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nvdbaranec/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nvdbaranec/subscriptions",
            "organizations_url": "https://api.github.com/users/nvdbaranec/orgs",
            "repos_url": "https://api.github.com/users/nvdbaranec/repos",
            "events_url": "https://api.github.com/users/nvdbaranec/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nvdbaranec/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-08-29T16:34:18Z",
        "updated_at": "2023-08-29T16:34:18Z",
        "author_association": "CONTRIBUTOR",
        "body": "@vuule ",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1697789452/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1705884972",
        "html_url": "https://github.com/rapidsai/cudf/issues/13995#issuecomment-1705884972",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13995",
        "id": 1705884972,
        "node_id": "IC_kwDOBWUGps5lrb0s",
        "user": {
            "login": "etseidl",
            "id": 25541553,
            "node_id": "MDQ6VXNlcjI1NTQxNTUz",
            "avatar_url": "https://avatars.githubusercontent.com/u/25541553?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/etseidl",
            "html_url": "https://github.com/etseidl",
            "followers_url": "https://api.github.com/users/etseidl/followers",
            "following_url": "https://api.github.com/users/etseidl/following{/other_user}",
            "gists_url": "https://api.github.com/users/etseidl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/etseidl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/etseidl/subscriptions",
            "organizations_url": "https://api.github.com/users/etseidl/orgs",
            "repos_url": "https://api.github.com/users/etseidl/repos",
            "events_url": "https://api.github.com/users/etseidl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/etseidl/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-09-05T03:09:30Z",
        "updated_at": "2023-09-05T16:55:56Z",
        "author_association": "CONTRIBUTOR",
        "body": "Looking at the files, the BIT_PACKED is a bit of a red herring.\r\n```\r\n    col1 TV=822216 RL=0 DL=1 DS:  102777 DE:PLAIN_DICTIONARY\r\n    ----------------------------------------------------------------------------\r\n    page 0:                        DLE:RLE RLE:BIT_PACKED VLE:PLAIN_DICTIONARY [more]... SZ:7509\r\n\r\n```\r\nThe file metadata claims the repetition level data is BIT_PACKED, but the max repetition level is 0, so there is no data to encode. I'm surprised to see BIT_PACKED listed since it's been deprecated for at least a decade now. \ud83d\ude09 \r\n\r\nDigging deeper, the CPU pages are 7509 bytes for the first 26 pages, and then 10009 bytes for the remaining pages of the column chunk. It seems that the encoder is using a variable bit width for the dictionary encoding. 3 bits for 20000 values would be 7500 bytes, 4 bits for 20000 values is 10000 bytes. (Actually, there are runs of 8 values in the data, so it's really where the dictionary switches from <= 16 bits to >= 17 bits that the bump in page size occurs). libcudf uses a fixed bit width for the entire column chunk based on the number of dictionary keys present. I think it would be a lot of work to use variable bit widths in cudf.\r\n\r\nYou can try limiting the rowgroup size to 400k rows. That might keep the dictionaries in the ~3~ 16 bit range.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1705884972/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1736579009",
        "html_url": "https://github.com/rapidsai/cudf/issues/13995#issuecomment-1736579009",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13995",
        "id": 1736579009,
        "node_id": "IC_kwDOBWUGps5nghfB",
        "user": {
            "login": "GregoryKimball",
            "id": 12725111,
            "node_id": "MDQ6VXNlcjEyNzI1MTEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregoryKimball",
            "html_url": "https://github.com/GregoryKimball",
            "followers_url": "https://api.github.com/users/GregoryKimball/followers",
            "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
            "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
            "repos_url": "https://api.github.com/users/GregoryKimball/repos",
            "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-09-27T02:33:17Z",
        "updated_at": "2023-09-27T02:33:17Z",
        "author_association": "CONTRIBUTOR",
        "body": "Thank you @abellina for sharing the file size difference you observed, and thank you @etseidl for your triage of this issue. Once we finish the work around DELTA decoding and encoding, we can consider the feasibility of variable bit width dictionary encoding.\r\n\r\nI'll close this issue for now. ",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1736579009/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1785879607",
        "html_url": "https://github.com/rapidsai/cudf/issues/13995#issuecomment-1785879607",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13995",
        "id": 1785879607,
        "node_id": "IC_kwDOBWUGps5qclw3",
        "user": {
            "login": "GregoryKimball",
            "id": 12725111,
            "node_id": "MDQ6VXNlcjEyNzI1MTEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregoryKimball",
            "html_url": "https://github.com/GregoryKimball",
            "followers_url": "https://api.github.com/users/GregoryKimball/followers",
            "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
            "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
            "repos_url": "https://api.github.com/users/GregoryKimball/repos",
            "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-10-30T19:13:41Z",
        "updated_at": "2023-10-30T19:13:41Z",
        "author_association": "CONTRIBUTOR",
        "body": "@etseidl thank you for studying this file. \r\n\r\nWould you please help me understand your observations a bit better?\r\n\r\nI thought that each column chunk has one dictionary page, and this dictionary is used for all of the pages in the column chunk. How could the pages in a column chunk switch between 16-bit and 17-bit dictionaries? \r\n\r\n> libcudf uses a fixed bit width for the entire column chunk based on the number of dictionary keys present. I think it would be a lot of work to use variable bit widths in cudf.\r\n\r\nWould you please share a bit more about this feature idea? How would the encoder choose the bit width for each page?",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1785879607/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1785992338",
        "html_url": "https://github.com/rapidsai/cudf/issues/13995#issuecomment-1785992338",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13995",
        "id": 1785992338,
        "node_id": "IC_kwDOBWUGps5qdBSS",
        "user": {
            "login": "etseidl",
            "id": 25541553,
            "node_id": "MDQ6VXNlcjI1NTQxNTUz",
            "avatar_url": "https://avatars.githubusercontent.com/u/25541553?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/etseidl",
            "html_url": "https://github.com/etseidl",
            "followers_url": "https://api.github.com/users/etseidl/followers",
            "following_url": "https://api.github.com/users/etseidl/following{/other_user}",
            "gists_url": "https://api.github.com/users/etseidl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/etseidl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/etseidl/subscriptions",
            "organizations_url": "https://api.github.com/users/etseidl/orgs",
            "repos_url": "https://api.github.com/users/etseidl/repos",
            "events_url": "https://api.github.com/users/etseidl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/etseidl/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-10-30T20:33:02Z",
        "updated_at": "2023-10-30T20:33:02Z",
        "author_association": "CONTRIBUTOR",
        "body": "@GregoryKimball, it has to do with the size of the dictionary when the page is encoded.  Because parquet-mr is more stream based, it will keep the current dictionary in RAM, and add keys as it goes.  So say that the first page has just under 64k distinct entries; in this case the maximum key size will be 16 bits, and the page will be RLE encoded with that bit width.  Now while encoding the second page, the number of distinct entries exceeds 64k; the RLE encoder will now use 17 bits. cuDF, on the other hand, computes the dictionary up front, and then uses the total number of entries to determine the bit width to use for all pages.\r\n\r\ncuDF could modify the dictionary page-encoder (not dictionary-page encoder :smile:)  to first find the largest dictionary key for the given page, and use that value to determine how many bits to use when doing the RLE encoding. I'm not sure what that would do to pre-computed page sizes and how the encoded values are stuffed into the column buffer.  This could get expensive to compute, but some users might prefer the smallest file possible and be willing to make that trade.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1785992338/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 1,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1786131747",
        "html_url": "https://github.com/rapidsai/cudf/issues/13995#issuecomment-1786131747",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13995",
        "id": 1786131747,
        "node_id": "IC_kwDOBWUGps5qdjUj",
        "user": {
            "login": "GregoryKimball",
            "id": 12725111,
            "node_id": "MDQ6VXNlcjEyNzI1MTEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregoryKimball",
            "html_url": "https://github.com/GregoryKimball",
            "followers_url": "https://api.github.com/users/GregoryKimball/followers",
            "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
            "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
            "repos_url": "https://api.github.com/users/GregoryKimball/repos",
            "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-10-30T22:16:48Z",
        "updated_at": "2024-04-02T03:36:21Z",
        "author_association": "CONTRIBUTOR",
        "body": "> cuDF could modify the dictionary page-encoder (not dictionary-page encoder \ud83d\ude04) to first find the largest dictionary key for the given page, and use that value to determine how many bits to use when doing the RLE encoding.\r\n\r\nThank you @etseidl, I appreciate the explanation. If we added this dynamic bit width, ~we might see smaller file sizes for cuDF than parquet-mr, because parquet-mr can only go up as it writes more pages, but then cuDF could go up or down as needed~ then cuDF would also be able to change the bit width of data pages based on the largest key value in that page. This also makes me wonder if we could add more tricks with dict key order to yield even smaller files.\r\n\r\n>  I'm not sure what that would do to pre-computed page sizes and how the encoded values are stuffed into the column buffer. \r\n\r\nGood points. It seems like it would take more work upfront to re-compute the page sizes depending on the max key.\r\n\r\n> This could get expensive to compute, but some users might prefer the smallest file possible and be willing to make that trade.\r\n\r\nCertainly some users put a huge premium on file size. This also comes up a lot with the nvCOMP team where there are often runtime/filesize tradeoffs.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1786131747/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1786203215",
        "html_url": "https://github.com/rapidsai/cudf/issues/13995#issuecomment-1786203215",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13995",
        "id": 1786203215,
        "node_id": "IC_kwDOBWUGps5qd0xP",
        "user": {
            "login": "etseidl",
            "id": 25541553,
            "node_id": "MDQ6VXNlcjI1NTQxNTUz",
            "avatar_url": "https://avatars.githubusercontent.com/u/25541553?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/etseidl",
            "html_url": "https://github.com/etseidl",
            "followers_url": "https://api.github.com/users/etseidl/followers",
            "following_url": "https://api.github.com/users/etseidl/following{/other_user}",
            "gists_url": "https://api.github.com/users/etseidl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/etseidl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/etseidl/subscriptions",
            "organizations_url": "https://api.github.com/users/etseidl/orgs",
            "repos_url": "https://api.github.com/users/etseidl/repos",
            "events_url": "https://api.github.com/users/etseidl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/etseidl/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-10-30T23:29:58Z",
        "updated_at": "2023-10-30T23:29:58Z",
        "author_association": "CONTRIBUTOR",
        "body": "I did a quick test and found that each page winds up with a wide range of keys due to the parallel nature of the dictionary construction. This will need more thought.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1786203215/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1808909383",
        "html_url": "https://github.com/rapidsai/cudf/issues/13995#issuecomment-1808909383",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13995",
        "id": 1808909383,
        "node_id": "IC_kwDOBWUGps5r0cRH",
        "user": {
            "login": "GregoryKimball",
            "id": 12725111,
            "node_id": "MDQ6VXNlcjEyNzI1MTEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregoryKimball",
            "html_url": "https://github.com/GregoryKimball",
            "followers_url": "https://api.github.com/users/GregoryKimball/followers",
            "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
            "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
            "repos_url": "https://api.github.com/users/GregoryKimball/repos",
            "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-11-13T19:38:31Z",
        "updated_at": "2023-11-13T19:38:31Z",
        "author_association": "CONTRIBUTOR",
        "body": "> I did a quick test and found that each page winds up with a wide range of keys due to the parallel nature of the dictionary construction. This will need more thought.\r\n\r\nThank you @etseidl for testing this. Do you think we could do better by sorting the keys descending based on the number of occurrences in the column chunk? (and then using dynamic bit width for the pages)\r\n\r\nIf sorting on number of occurrences doesn't work well, then I suppose we would be stuck with a more difficult optimization such as filling the first 2^16 keys to cover the most number of pages.\r\n\r\nDoes this sound right to you?",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1808909383/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]