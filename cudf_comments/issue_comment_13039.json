[
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1491245570",
        "html_url": "https://github.com/rapidsai/cudf/issues/13039#issuecomment-1491245570",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13039",
        "id": 1491245570,
        "node_id": "IC_kwDOBWUGps5Y4poC",
        "user": {
            "login": "stucash",
            "id": 6358866,
            "node_id": "MDQ6VXNlcjYzNTg4NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6358866?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stucash",
            "html_url": "https://github.com/stucash",
            "followers_url": "https://api.github.com/users/stucash/followers",
            "following_url": "https://api.github.com/users/stucash/following{/other_user}",
            "gists_url": "https://api.github.com/users/stucash/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stucash/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stucash/subscriptions",
            "organizations_url": "https://api.github.com/users/stucash/orgs",
            "repos_url": "https://api.github.com/users/stucash/repos",
            "events_url": "https://api.github.com/users/stucash/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stucash/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-31T03:44:23Z",
        "updated_at": "2023-03-31T03:44:49Z",
        "author_association": "NONE",
        "body": "Team can you please take a look? This is currently a show stopper for me and I am literally freezed with GPU related development. Thanks a lot!",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1491245570/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1491736604",
        "html_url": "https://github.com/rapidsai/cudf/issues/13039#issuecomment-1491736604",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13039",
        "id": 1491736604,
        "node_id": "IC_kwDOBWUGps5Y6hgc",
        "user": {
            "login": "stucash",
            "id": 6358866,
            "node_id": "MDQ6VXNlcjYzNTg4NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6358866?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stucash",
            "html_url": "https://github.com/stucash",
            "followers_url": "https://api.github.com/users/stucash/followers",
            "following_url": "https://api.github.com/users/stucash/following{/other_user}",
            "gists_url": "https://api.github.com/users/stucash/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stucash/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stucash/subscriptions",
            "organizations_url": "https://api.github.com/users/stucash/orgs",
            "repos_url": "https://api.github.com/users/stucash/repos",
            "events_url": "https://api.github.com/users/stucash/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stucash/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-31T10:54:29Z",
        "updated_at": "2023-03-31T10:54:29Z",
        "author_association": "NONE",
        "body": "I've got a few more bug-like issues, I'll raise them here shortly. ",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1491736604/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1491737840",
        "html_url": "https://github.com/rapidsai/cudf/issues/13039#issuecomment-1491737840",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13039",
        "id": 1491737840,
        "node_id": "IC_kwDOBWUGps5Y6hzw",
        "user": {
            "login": "stucash",
            "id": 6358866,
            "node_id": "MDQ6VXNlcjYzNTg4NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6358866?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stucash",
            "html_url": "https://github.com/stucash",
            "followers_url": "https://api.github.com/users/stucash/followers",
            "following_url": "https://api.github.com/users/stucash/following{/other_user}",
            "gists_url": "https://api.github.com/users/stucash/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stucash/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stucash/subscriptions",
            "organizations_url": "https://api.github.com/users/stucash/orgs",
            "repos_url": "https://api.github.com/users/stucash/repos",
            "events_url": "https://api.github.com/users/stucash/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stucash/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-03-31T10:55:29Z",
        "updated_at": "2023-03-31T10:55:29Z",
        "author_association": "NONE",
        "body": "In the meanwhile if someone has got a good introduction/tutorial about cudf other than the one already posted like 10-minute series, please throw it in here.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1491737840/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1493055395",
        "html_url": "https://github.com/rapidsai/cudf/issues/13039#issuecomment-1493055395",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13039",
        "id": 1493055395,
        "node_id": "IC_kwDOBWUGps5Y_jej",
        "user": {
            "login": "stucash",
            "id": 6358866,
            "node_id": "MDQ6VXNlcjYzNTg4NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6358866?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stucash",
            "html_url": "https://github.com/stucash",
            "followers_url": "https://api.github.com/users/stucash/followers",
            "following_url": "https://api.github.com/users/stucash/following{/other_user}",
            "gists_url": "https://api.github.com/users/stucash/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stucash/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stucash/subscriptions",
            "organizations_url": "https://api.github.com/users/stucash/orgs",
            "repos_url": "https://api.github.com/users/stucash/repos",
            "events_url": "https://api.github.com/users/stucash/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stucash/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-01T17:43:41Z",
        "updated_at": "2023-04-01T17:43:41Z",
        "author_association": "NONE",
        "body": "I've appended full error log below:\r\n\r\n---------------------------------------------------------------------------\r\n```\r\nNotImplementedError                       Traceback (most recent call last)\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/backends.py:133, in CreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper(*args, **kwargs)\r\n    132 try:\r\n--> 133     return func(*args, **kwargs)\r\n    134 except Exception as e:\r\n\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/dataframe/io/parquet/core.py:530, in read_parquet(path, columns, filters, categories, index, storage_options, engine, use_nullable_dtypes, calculate_divisions, ignore_metadata_file, metadata_task_size, split_row_groups, chunksize, aggregate_files, parquet_file_extension, filesystem, **kwargs)\r\n    528     index = [index]\r\n--> 530 read_metadata_result = engine.read_metadata(\r\n    531     fs,\r\n    532     paths,\r\n    533     categories=categories,\r\n    534     index=index,\r\n    535     use_nullable_dtypes=use_nullable_dtypes,\r\n    536     gather_statistics=calculate_divisions,\r\n    537     filters=filters,\r\n    538     split_row_groups=split_row_groups,\r\n    539     chunksize=chunksize,\r\n    540     aggregate_files=aggregate_files,\r\n    541     ignore_metadata_file=ignore_metadata_file,\r\n    542     metadata_task_size=metadata_task_size,\r\n    543     parquet_file_extension=parquet_file_extension,\r\n    544     dataset=dataset_options,\r\n    545     read=read_options,\r\n    546     **other_options,\r\n    547 )\r\n    549 # In the future, we may want to give the engine the\r\n    550 # option to return a dedicated element for `common_kwargs`.\r\n    551 # However, to avoid breaking the API, we just embed this\r\n    552 # data in the first element of `parts` for now.\r\n    553 # The logic below is inteded to handle backward and forward\r\n    554 # compatibility with a user-defined engine.\r\n\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask_cudf/io/parquet.py:41, in CudfEngine.read_metadata(*args, **kwargs)\r\n     39 if parts:\r\n     40     # Re-set \"object\" dtypes align with pa schema\r\n---> 41     set_object_dtypes_from_pa_schema(\r\n     42         new_meta,\r\n     43         parts[0].get(\"common_kwargs\", {}).get(\"schema\", None),\r\n     44     )\r\n     46 # If `strings_to_categorical==True`, convert objects to int32\r\n\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask_cudf/io/parquet.py:403, in set_object_dtypes_from_pa_schema(df, schema)\r\n    402     continue\r\n--> 403 typ = cudf_dtype_from_pa_type(schema.field(col_name).type)\r\n    404 if (\r\n    405     col_name in schema.names\r\n    406     and not isinstance(typ, (cudf.ListDtype, cudf.StructDtype))\r\n    407     and isinstance(col, cudf.core.column.StringColumn)\r\n    408 ):\r\n\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/cudf/utils/dtypes.py:231, in cudf_dtype_from_pa_type(typ)\r\n    230 else:\r\n--> 231     return cudf.api.types.pandas_dtype(typ.to_pandas_dtype())\r\n\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/pyarrow/types.pxi:220, in pyarrow.lib.DataType.to_pandas_dtype()\r\n\r\nNotImplementedError: large_string\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nNotImplementedError                       Traceback (most recent call last)\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/backends.py:133, in CreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper(*args, **kwargs)\r\n    132 try:\r\n--> 133     return func(*args, **kwargs)\r\n    134 except Exception as e:\r\n\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask_cudf/backends.py:497, in CudfBackendEntrypoint.read_parquet(engine, *args, **kwargs)\r\n    495 from dask_cudf.io.parquet import CudfEngine\r\n--> 497 return _default_backend(\r\n    498     dd.read_parquet,\r\n    499     *args,\r\n    500     engine=CudfEngine,\r\n    501     **kwargs,\r\n    502 )\r\n\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask_cudf/backends.py:446, in _default_backend(func, *args, **kwargs)\r\n    445 with config.set({\"dataframe.backend\": \"pandas\"}):\r\n--> 446     return func(*args, **kwargs)\r\n\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/backends.py:135, in CreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper(*args, **kwargs)\r\n    134 except Exception as e:\r\n--> 135     raise type(e)(\r\n    136         f\"An error occurred while calling the {funcname(func)} \"\r\n    137         f\"method registered to the {self.backend} backend.\\n\"\r\n    138         f\"Original Message: {e}\"\r\n    139     ) from e\r\n\r\nNotImplementedError: An error occurred while calling the read_parquet method registered to the pandas backend.\r\nOriginal Message: large_string\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nNotImplementedError                       Traceback (most recent call last)\r\nCell In[9], line 1\r\n----> 1 dask_cudf.read_parquet('/home/demo/Live-usb-storage/projects/.share/data/test_cudf.parquet')\r\n\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask_cudf/io/parquet.py:465, in read_parquet(path, columns, **kwargs)\r\n    462         kwargs[\"read\"] = {}\r\n    463     kwargs[\"read\"][\"check_file_size\"] = check_file_size\r\n--> 465 return dd.read_parquet(path, columns=columns, engine=CudfEngine, **kwargs)\r\n\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask/backends.py:135, in CreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper(*args, **kwargs)\r\n    133     return func(*args, **kwargs)\r\n    134 except Exception as e:\r\n--> 135     raise type(e)(\r\n    136         f\"An error occurred while calling the {funcname(func)} \"\r\n    137         f\"method registered to the {self.backend} backend.\\n\"\r\n    138         f\"Original Message: {e}\"\r\n    139     ) from e\r\n\r\nNotImplementedError: An error occurred while calling the read_parquet method registered to the cudf backend.\r\nOriginal Message: An error occurred while calling the read_parquet method registered to the pandas backend.\r\nOriginal Message: large_string\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1493055395/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1493061714",
        "html_url": "https://github.com/rapidsai/cudf/issues/13039#issuecomment-1493061714",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13039",
        "id": 1493061714,
        "node_id": "IC_kwDOBWUGps5Y_lBS",
        "user": {
            "login": "stucash",
            "id": 6358866,
            "node_id": "MDQ6VXNlcjYzNTg4NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6358866?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stucash",
            "html_url": "https://github.com/stucash",
            "followers_url": "https://api.github.com/users/stucash/followers",
            "following_url": "https://api.github.com/users/stucash/following{/other_user}",
            "gists_url": "https://api.github.com/users/stucash/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stucash/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stucash/subscriptions",
            "organizations_url": "https://api.github.com/users/stucash/orgs",
            "repos_url": "https://api.github.com/users/stucash/repos",
            "events_url": "https://api.github.com/users/stucash/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stucash/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-01T18:02:20Z",
        "updated_at": "2023-04-02T06:22:55Z",
        "author_association": "NONE",
        "body": "Reading the log, I found that `cudf` is converting `pyarrow` explicitly to `pandas` dtypes (before they become `cudf` dtypes); therefore I tried using `pandas` to write the same data to a parquet file. \r\n\r\nThe pandas-written parquet file was successfully converted to a `dask_cudf` dataframe.\r\n\r\nHere's the highlighted line of code in error log that did this:\r\n\r\n```\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask_cudf/io/parquet.py:41, in CudfEngine.read_metadata(*args, **kwargs)\r\n     39 if parts:\r\n     40     # Re-set \"object\" dtypes align with pa schema\r\n---> 41     **set_object_dtypes_from_pa_schema**(\r\n     42         new_meta,\r\n     43         parts[0].get(\"common_kwargs\", {}).get(\"schema\", None),\r\n     44     )\r\n     46 # If `strings_to_categorical==True`, convert objects to int32\r\n\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/dask_cudf/io/parquet.py:403, in set_object_dtypes_from_pa_schema(df, schema)\r\n    402     continue\r\n--> 403 typ = **cudf_dtype_from_pa_type(schema.field(col_name).type)**\r\n    404 if (\r\n    405     col_name in schema.names\r\n    406     and not isinstance(typ, (cudf.ListDtype, cudf.StructDtype))\r\n    407     and isinstance(col, cudf.core.column.StringColumn)\r\n    408 ):\r\n\r\nFile ~/Live-usb-storage/projects/python/alpha/lib/python3.10/site-packages/cudf/utils/dtypes.py:231, in cudf_dtype_from_pa_type(typ)\r\n    230 else:\r\n--> 231     **return cudf.api.types.pandas_dtype(typ.to_pandas_dtype()**)\r\n```\r\n\r\n`parquet` is simply a data container, whoever writes `parquet` is going to write a `parquet`, after all. \r\n\r\nUntil I found that when we write `parquet` using different library, the parquet file can be different! (The original `parquet` that failed was written by `polars`). \r\n\r\nBy the way, `pandas` and `polars` both called `pa.write_table` for `parquet` creation. \r\n\r\nI am not sure whether this involves support for `polars` or we could replace `pandas` dtype conversion with a python dtypes conversion, but at the moment understanding only `parquet` from `pandas` is fairly limited.\r\n\r\nHope you guys can take a look, thanks a lot! \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1493061714/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1494429481",
        "html_url": "https://github.com/rapidsai/cudf/issues/13039#issuecomment-1494429481",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13039",
        "id": 1494429481,
        "node_id": "IC_kwDOBWUGps5ZEy8p",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-03T14:26:39Z",
        "updated_at": "2023-04-03T14:26:39Z",
        "author_association": "MEMBER",
        "body": "Thanks for raising @stucash - I'll take a look at this today to see how I can help.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1494429481/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1494520991",
        "html_url": "https://github.com/rapidsai/cudf/issues/13039#issuecomment-1494520991",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13039",
        "id": 1494520991,
        "node_id": "IC_kwDOBWUGps5ZFJSf",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-03T15:17:57Z",
        "updated_at": "2023-04-03T15:17:57Z",
        "author_association": "MEMBER",
        "body": "@stucash - I cannot be 100% certain without having a complete write + read reproducer to run locally. However, it looks like your original dataset may contain extremely large row-groups. Unfortunately, until [very recently](https://github.com/apache/arrow/issues/34280) the default row-group size in PyArrow was 64Mi rows, which can sometimes result in string columns that cannot be read back by `cudf` (since `cudf` has a 2B character limit for an individual single string column; see: [cudf#3958](https://github.com/rapidsai/cudf/issues/3958)).\r\n\r\nIf the problem is that the row-groups are too large, you will need to rewrite the files with polars or pandas, passing through `row_group_size=<something-smaller>` to the pyarrow backend.\r\n\r\nIt may also be possible that your row-groups are within the cudf limit, but that pyarrow is choosing to use a [large_string](https://arrow.apache.org/docs/python/generated/pyarrow.large_string.html) when converting the dtype to pandas (note that cudf's read_parquet code currently leans on the arrow's native pandas logic to figure out what cudf dtypes to use). If I can get my hands on a reproducer for this, we can probably resolve the problem in cudf/dask-cudf.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1494520991/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1494543621",
        "html_url": "https://github.com/rapidsai/cudf/issues/13039#issuecomment-1494543621",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13039",
        "id": 1494543621,
        "node_id": "IC_kwDOBWUGps5ZFO0F",
        "user": {
            "login": "rjzamora",
            "id": 20461013,
            "node_id": "MDQ6VXNlcjIwNDYxMDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20461013?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rjzamora",
            "html_url": "https://github.com/rjzamora",
            "followers_url": "https://api.github.com/users/rjzamora/followers",
            "following_url": "https://api.github.com/users/rjzamora/following{/other_user}",
            "gists_url": "https://api.github.com/users/rjzamora/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rjzamora/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rjzamora/subscriptions",
            "organizations_url": "https://api.github.com/users/rjzamora/orgs",
            "repos_url": "https://api.github.com/users/rjzamora/repos",
            "events_url": "https://api.github.com/users/rjzamora/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rjzamora/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-03T15:32:45Z",
        "updated_at": "2023-04-03T15:32:45Z",
        "author_association": "MEMBER",
        "body": "> I tried using pandas to write the same data to a parquet file... The pandas-written parquet file was successfully converted to a dask_cudf dataframe.\r\n\r\nHmmm, this is interesting. I was expecting the same pyarrow issue to show up for a pandas-written parquet file as well (since both are presumably using arrow as the backend). Good to know.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1494543621/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1495513611",
        "html_url": "https://github.com/rapidsai/cudf/issues/13039#issuecomment-1495513611",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13039",
        "id": 1495513611,
        "node_id": "IC_kwDOBWUGps5ZI7oL",
        "user": {
            "login": "stucash",
            "id": 6358866,
            "node_id": "MDQ6VXNlcjYzNTg4NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6358866?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stucash",
            "html_url": "https://github.com/stucash",
            "followers_url": "https://api.github.com/users/stucash/followers",
            "following_url": "https://api.github.com/users/stucash/following{/other_user}",
            "gists_url": "https://api.github.com/users/stucash/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stucash/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stucash/subscriptions",
            "organizations_url": "https://api.github.com/users/stucash/orgs",
            "repos_url": "https://api.github.com/users/stucash/repos",
            "events_url": "https://api.github.com/users/stucash/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stucash/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-04-04T07:54:46Z",
        "updated_at": "2023-04-04T07:54:46Z",
        "author_association": "NONE",
        "body": "@rjzamora Thanks for taking the time to investigate;  \r\n\r\nI've got 7 parquet files (1.5GB ish per file) originally from `polars`, all of which failed with `dask_cudf`, and once all were rewritten by `pandas` they could be read by `dask_cudf` in one go with no problem. \r\n\r\nLet me prepare a reproducer with data; in the meanwhile I'll try your suggestion of the `row_group_size` to `pyarrow` backend. ",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1495513611/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1577275840",
        "html_url": "https://github.com/rapidsai/cudf/issues/13039#issuecomment-1577275840",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13039",
        "id": 1577275840,
        "node_id": "IC_kwDOBWUGps5eA1HA",
        "user": {
            "login": "GregoryKimball",
            "id": 12725111,
            "node_id": "MDQ6VXNlcjEyNzI1MTEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregoryKimball",
            "html_url": "https://github.com/GregoryKimball",
            "followers_url": "https://api.github.com/users/GregoryKimball/followers",
            "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
            "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
            "repos_url": "https://api.github.com/users/GregoryKimball/repos",
            "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-05T18:33:33Z",
        "updated_at": "2023-06-05T18:33:33Z",
        "author_association": "CONTRIBUTOR",
        "body": "Thank you @stucash for posting this. It also occurs to me that libcudf does not support the `large_string` type that we see in [pyarrow](https://arrow.apache.org/docs/python/generated/pyarrow.large_string.html). Have you tried converting your column to a `string` type instead of `long_string`?",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1577275840/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/2133527661",
        "html_url": "https://github.com/rapidsai/cudf/issues/13039#issuecomment-2133527661",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13039",
        "id": 2133527661,
        "node_id": "IC_kwDOBWUGps5_Kwxt",
        "user": {
            "login": "CarloNicolini",
            "id": 1758847,
            "node_id": "MDQ6VXNlcjE3NTg4NDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1758847?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/CarloNicolini",
            "html_url": "https://github.com/CarloNicolini",
            "followers_url": "https://api.github.com/users/CarloNicolini/followers",
            "following_url": "https://api.github.com/users/CarloNicolini/following{/other_user}",
            "gists_url": "https://api.github.com/users/CarloNicolini/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/CarloNicolini/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/CarloNicolini/subscriptions",
            "organizations_url": "https://api.github.com/users/CarloNicolini/orgs",
            "repos_url": "https://api.github.com/users/CarloNicolini/repos",
            "events_url": "https://api.github.com/users/CarloNicolini/events{/privacy}",
            "received_events_url": "https://api.github.com/users/CarloNicolini/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-05-27T13:49:42Z",
        "updated_at": "2024-05-27T13:49:59Z",
        "author_association": "NONE",
        "body": "I've been having this kind of issues using NVTabular that relies on cudf.\r\nEverything smooth when dataframes were saved throught pandas.`to_parquet` function, but lot of problems when using Polars `.write_parquet`.\r\n\r\nGiven that pandas was not an option due to its slowness, I managed to save the polars dataframe through a manually crafted function that uses `pyarrow`.\r\n\r\nThis part simplifies the schema removing the  `pa.types.large_string`, `pa.types.large_list` in favor of their non_large counterpart.\r\n\r\n```python\r\n\r\ndef pyarrow_simplified_schema(schema: pa.Schema) -> pa.Schema:\r\n    \"\"\"\r\n    Convert LargeList<LargeString> fields to LargeList<String> in a PyArrow schema.\r\n\r\n    Parameters\r\n    ----------\r\n    schema : pa.Schema\r\n        The original schema of the PyArrow Table.\r\n\r\n    Returns\r\n    -------\r\n    pa.Schema\r\n        A new schema where all LargeList<LargeString> fields are converted to LargeList<String>.\r\n    \"\"\"\r\n    fields = []\r\n    for field in schema:\r\n        if pa.types.is_float64(field.type):\r\n            warn(\r\n                f\"NVTabular does not support double precision, downcasting {field.name} to float32\"\r\n            )\r\n            fields.append(pa.field(field.name, pa.float32()))\r\n        elif pa.types.is_large_list(field.type) or pa.types.is_list(field.type):\r\n            if pa.types.is_large_string(field.type.value_type):\r\n                fields.append(pa.field(field.name, pa.list_(pa.string())))\r\n            elif pa.types.is_float64(field.type.value_type):\r\n                warn(\r\n                    f\"NVTabular does not support double precision, downcasting {field.name} to float32\"\r\n                )\r\n                fields.append(pa.field(field.name, pa.list_(pa.float32())))\r\n            else:\r\n                # passthrough on other types\r\n                fields.append(pa.field(field.name, pa.list_(field.type.value_type)))\r\n        elif pa.types.is_large_string(field.type):\r\n            fields.append(pa.field(field.name, pa.string()))\r\n        else:\r\n            # passthrough on other types\r\n            fields.append(field)\r\n    return pa.schema(fields)\r\n```\r\n\r\nAfter this I was able to load everything correctly using the cudf implementation of NVTabular.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/2133527661/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]