[
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1986675588",
        "html_url": "https://github.com/rapidsai/cudf/issues/15262#issuecomment-1986675588",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/15262",
        "id": 1986675588,
        "node_id": "IC_kwDOBWUGps52akOE",
        "user": {
            "login": "sameerz",
            "id": 7036315,
            "node_id": "MDQ6VXNlcjcwMzYzMTU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7036315?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sameerz",
            "html_url": "https://github.com/sameerz",
            "followers_url": "https://api.github.com/users/sameerz/followers",
            "following_url": "https://api.github.com/users/sameerz/following{/other_user}",
            "gists_url": "https://api.github.com/users/sameerz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sameerz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sameerz/subscriptions",
            "organizations_url": "https://api.github.com/users/sameerz/orgs",
            "repos_url": "https://api.github.com/users/sameerz/repos",
            "events_url": "https://api.github.com/users/sameerz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sameerz/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-09T01:22:34Z",
        "updated_at": "2024-03-09T01:22:34Z",
        "author_association": "CONTRIBUTOR",
        "body": "Related issue https://github.com/NVIDIA/spark-rapids/issues/7529",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1986675588/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1988053351",
        "html_url": "https://github.com/rapidsai/cudf/issues/15262#issuecomment-1988053351",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/15262",
        "id": 1988053351,
        "node_id": "IC_kwDOBWUGps52f0ln",
        "user": {
            "login": "wence-",
            "id": 1126981,
            "node_id": "MDQ6VXNlcjExMjY5ODE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1126981?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wence-",
            "html_url": "https://github.com/wence-",
            "followers_url": "https://api.github.com/users/wence-/followers",
            "following_url": "https://api.github.com/users/wence-/following{/other_user}",
            "gists_url": "https://api.github.com/users/wence-/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wence-/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wence-/subscriptions",
            "organizations_url": "https://api.github.com/users/wence-/orgs",
            "repos_url": "https://api.github.com/users/wence-/repos",
            "events_url": "https://api.github.com/users/wence-/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wence-/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-11T10:14:10Z",
        "updated_at": "2024-03-11T10:14:10Z",
        "author_association": "CONTRIBUTOR",
        "body": "Is the low throughput specifically only for low cardinality data, or also for skewed cardinality data? That is, suppose I have many distinct group keys, but most of the weight of the data is only in a few. In that scenario, as you describe the implementation, I think we will still run slowly. However, dispatching based on absolute cardinality will not be that useful since it is not a true representation of the data distribution.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1988053351/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1999742161",
        "html_url": "https://github.com/rapidsai/cudf/issues/15262#issuecomment-1999742161",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/15262",
        "id": 1999742161,
        "node_id": "IC_kwDOBWUGps53MaTR",
        "user": {
            "login": "sleeepyjack",
            "id": 2955913,
            "node_id": "MDQ6VXNlcjI5NTU5MTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2955913?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sleeepyjack",
            "html_url": "https://github.com/sleeepyjack",
            "followers_url": "https://api.github.com/users/sleeepyjack/followers",
            "following_url": "https://api.github.com/users/sleeepyjack/following{/other_user}",
            "gists_url": "https://api.github.com/users/sleeepyjack/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sleeepyjack/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sleeepyjack/subscriptions",
            "organizations_url": "https://api.github.com/users/sleeepyjack/orgs",
            "repos_url": "https://api.github.com/users/sleeepyjack/repos",
            "events_url": "https://api.github.com/users/sleeepyjack/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sleeepyjack/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-15T14:05:10Z",
        "updated_at": "2024-03-15T14:08:44Z",
        "author_association": "NONE",
        "body": "> What is the throughput difference between hyperloglog and count distinct? We expect the memory footprint of hyperloglog to be much lower, but I don't believe throughput has had controlled measurements.\r\n\r\nHere are the newest benchmark numbers for HLL: https://github.com/NVIDIA/cuCollections/pull/429#issuecomment-1999730719\r\ntl;dr Depending on the parameter, we achieve between 72-89% of the SOL memory bandwidth of an H100.\r\n\r\nThe memory footprint is only a few KB or 1MB max and depends on the precision value. More precisely it is `4 * 2^precision` bytes, where the precision is typically in range [10, 18]. So yes, it should be much smaller compared to a fully fledged exact distinct count algorithm.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1999742161/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/2138373830",
        "html_url": "https://github.com/rapidsai/cudf/issues/15262#issuecomment-2138373830",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/15262",
        "id": 2138373830,
        "node_id": "IC_kwDOBWUGps5_dP7G",
        "user": {
            "login": "PointKernel",
            "id": 12716979,
            "node_id": "MDQ6VXNlcjEyNzE2OTc5",
            "avatar_url": "https://avatars.githubusercontent.com/u/12716979?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PointKernel",
            "html_url": "https://github.com/PointKernel",
            "followers_url": "https://api.github.com/users/PointKernel/followers",
            "following_url": "https://api.github.com/users/PointKernel/following{/other_user}",
            "gists_url": "https://api.github.com/users/PointKernel/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PointKernel/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PointKernel/subscriptions",
            "organizations_url": "https://api.github.com/users/PointKernel/orgs",
            "repos_url": "https://api.github.com/users/PointKernel/repos",
            "events_url": "https://api.github.com/users/PointKernel/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PointKernel/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-05-29T22:42:17Z",
        "updated_at": "2024-05-29T22:42:17Z",
        "author_association": "MEMBER",
        "body": "Using this issue to continue the discussions in https://github.com/NVIDIA/spark-rapids/issues/7529.\r\n\r\nLow cardinality join and low cardinality groupby share some commons but the performance bottlenecks are not the same:\r\n\r\n- Groupby uses a single map so the probing sequence (number of steps for a query key to find a match in hash table) is short (thus few hash collisions). The performance killer for low cardinality cases is the contention with atomic aggregations. Shared memory hash table can help since it splits the atomic aggregation into two levels: a block-level aggregation first and then only one aggregation per block with the final output.\r\n- Hash join uses a multimap so duplicate keys will result in a longer probing sequence thus more hash collisions. The culprit should be high multiplicity as opposed to low cardinality. I need to think more about this but a shared memory hash table probably won't help here.\r\n\r\nWith that, to address this issue:\r\nFor groupby:\r\n\r\n- [ ] implement shared-memory hash table with two-level aggregation\r\n- [ ] evaluate the performance impact of using hyperloglog\r\n\r\nfor high-multiplicity hash join:\r\n\r\n- [ ] verify the impact of CG size tuning (https://github.com/NVIDIA/spark-rapids/issues/7529#issuecomment-2138286065). Expose CG size tuning in public APIs if needed",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/2138373830/reactions",
            "total_count": 2,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]