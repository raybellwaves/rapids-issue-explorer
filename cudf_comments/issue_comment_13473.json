[
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1573103826",
        "html_url": "https://github.com/rapidsai/cudf/issues/13473#issuecomment-1573103826",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13473",
        "id": 1573103826,
        "node_id": "IC_kwDOBWUGps5dw6jS",
        "user": {
            "login": "GregoryKimball",
            "id": 12725111,
            "node_id": "MDQ6VXNlcjEyNzI1MTEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregoryKimball",
            "html_url": "https://github.com/GregoryKimball",
            "followers_url": "https://api.github.com/users/GregoryKimball/followers",
            "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
            "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
            "repos_url": "https://api.github.com/users/GregoryKimball/repos",
            "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-02T03:48:59Z",
        "updated_at": "2023-06-02T03:48:59Z",
        "author_association": "CONTRIBUTOR",
        "body": "Thank you @revans2 for posting this. Would you please share if you exploring JSON file read or JSON strings column parsing when you encountered these issues?\r\n\r\nThe two topics about column projection and empty rows seem like they could be different issues. Would you please let me know if there is a reason to combine them?",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1573103826/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1573936104",
        "html_url": "https://github.com/rapidsai/cudf/issues/13473#issuecomment-1573936104",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13473",
        "id": 1573936104,
        "node_id": "IC_kwDOBWUGps5d0Fvo",
        "user": {
            "login": "karthikeyann",
            "id": 6488848,
            "node_id": "MDQ6VXNlcjY0ODg4NDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6488848?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/karthikeyann",
            "html_url": "https://github.com/karthikeyann",
            "followers_url": "https://api.github.com/users/karthikeyann/followers",
            "following_url": "https://api.github.com/users/karthikeyann/following{/other_user}",
            "gists_url": "https://api.github.com/users/karthikeyann/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/karthikeyann/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/karthikeyann/subscriptions",
            "organizations_url": "https://api.github.com/users/karthikeyann/orgs",
            "repos_url": "https://api.github.com/users/karthikeyann/repos",
            "events_url": "https://api.github.com/users/karthikeyann/events{/privacy}",
            "received_events_url": "https://api.github.com/users/karthikeyann/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-02T15:34:33Z",
        "updated_at": "2023-06-02T15:34:33Z",
        "author_association": "CONTRIBUTOR",
        "body": "The peak memory usage of JSON reader will not reduce if we add this feature. JSON tokenizer, Tree construction and traversal will still be same. Only datatype parsing will be eliminated for non-selected columns. (saves some time, but not that big).\r\n\r\n**A quick analysis on json reader benchmark:**\r\nIn the screenshot attached of a benchmark run for 64 columns, filesize 1.28GB, datatype parsing takes ~21% (green) of the time. Also note that `get_token_stream` and `get_tree_representation` takes the peak memory usage. Not datatype parsing (in green).\r\n![image](https://github.com/rapidsai/cudf/assets/6488848/6dcfe696-6856-41b2-a634-4a69703e7e20)\r\nSpeedup could be <20%.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1573936104/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1577306829",
        "html_url": "https://github.com/rapidsai/cudf/issues/13473#issuecomment-1577306829",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13473",
        "id": 1577306829,
        "node_id": "IC_kwDOBWUGps5eA8rN",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-05T18:59:31Z",
        "updated_at": "2023-06-05T18:59:31Z",
        "author_association": "CONTRIBUTOR",
        "body": "@GregoryKimball this was when we were reading a file, but it is the same for both code paths in this case.\r\n\r\n@karthikeyann \r\n\r\nThanks for the info. I understand that this might not have a huge impact to the memory usage or computation time.  The majority of the memory usage and computation would be going into tokenizing and parsing the data. But even then if I have a case like the following\r\n\r\n```\r\n{\"B\": true, \"A\": [100, 200, 300, 400, 500.... hundreds of values ...]}\r\n... thousands of rows ...\r\n{\"B\": false, \"A\": [1, 2, 3, 4, 5...]}\r\n```\r\n\r\nIf all I save is on not needing to materialize the output for A that is a win. May not be something that you want to prioritize super high for a performance standpoint.\r\n\r\nThe big problem for us in a really odd corner case which we did run into in one of our integration tests, and I am nervous we will run into with a customer at some point.  Spark when it writes out JSON data by default will remove entries that are null.  It is a space savings optimization.  So if we end up with a row that are all nulls we end up with an output row of `{}`. This is not that uncommon in terms of a JSON optimizations.  The problem shows up if all of the rows in a batch show up this way.  \r\n\r\n\r\n```\r\n{}\r\n{}\r\n{}\r\n```\r\n\r\nI don't think it is likely to happen for large runs of rows, but with Spark it is very possible to have a few rows at the end of a file that show up like this and because of splits they would end up in a single batch. CUDF is unable to parse that batch and had us back the number of rows.  The best that we could do as a work around is to count the number of input rows before sending the data to CUDF and catch this exception after it happens. But I am not 100% sure that it will work in all cases, especially if CUDF support [comments](https://github.com/rapidsai/cudf/issues/10265), because Spark strips out lines that are fully comments in files. Then we would not know how many rows there are without some help.\r\n\r\nAgain probably not the highest priority, but it does end up being rather hacky to work around a lack of this type of feature.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1577306829/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1577352347",
        "html_url": "https://github.com/rapidsai/cudf/issues/13473#issuecomment-1577352347",
        "issue_url": "https://api.github.com/repos/rapidsai/cudf/issues/13473",
        "id": 1577352347,
        "node_id": "IC_kwDOBWUGps5eBHyb",
        "user": {
            "login": "GregoryKimball",
            "id": 12725111,
            "node_id": "MDQ6VXNlcjEyNzI1MTEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12725111?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregoryKimball",
            "html_url": "https://github.com/GregoryKimball",
            "followers_url": "https://api.github.com/users/GregoryKimball/followers",
            "following_url": "https://api.github.com/users/GregoryKimball/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregoryKimball/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregoryKimball/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregoryKimball/subscriptions",
            "organizations_url": "https://api.github.com/users/GregoryKimball/orgs",
            "repos_url": "https://api.github.com/users/GregoryKimball/repos",
            "events_url": "https://api.github.com/users/GregoryKimball/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregoryKimball/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-06-05T19:23:48Z",
        "updated_at": "2023-06-05T19:25:02Z",
        "author_association": "CONTRIBUTOR",
        "body": "Linking this issue to #5712 - which seems to capture the empty row issue well.\r\n\r\nLet's leave this issue to focus on the column projection optimization.",
        "reactions": {
            "url": "https://api.github.com/repos/rapidsai/cudf/issues/comments/1577352347/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]