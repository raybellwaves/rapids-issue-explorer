{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9275",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9275/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9275/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9275/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/9275",
    "id": 1905311554,
    "node_id": "I_kwDOD7z77c5xkL9C",
    "number": 9275,
    "title": "[FEA] Have our out of core sort support/be a stable sort",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735884,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODg0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-09-20T16:05:08Z",
    "updated_at": "2023-09-26T20:28:47Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\nFor our current out of core sort I made it do it was not stable, because I could not figure out a cheap way to have it be stable.  This is causing problems (https://github.com/NVIDIA/spark-rapids/issues/2884, https://github.com/NVIDIA/spark-rapids/issues/9243) and it would be better to just make it stable by default so it matches Spark, even though in 99% of the cases Spark does not need it to be stable because the shuffle order is not deterministic.\r\n\r\n**Describe the solution you'd like**\r\nThe simplest way to make this work is to add a row number to each row and sort on it as a secondary sort.  But that is far from ideal because it adds a lot of GPU memory.  Instead we really just need to maintain an insertion order of the rows for the batches that are used, and at the same time use stable sorts for all of the operations.\r\n\r\nRight now the out of core sort algorithm effectively will\r\n\r\n1. Take in a batch and sort it.\r\n2. Split it into smaller batches.\r\n3. Insert these smaller batches into a priority queue that is sorted by the lowest row in the sorted batch.\r\n4. Pop off enough smaller batches to hit the target batch size.\r\n5. Merge sort these smaller batches into a larger batch\r\n6. Get the lowest row that is still in the queue and slice the merged batch by this lowest row\r\n7. Put the sliced input back in the queue that is not fully sorted and put the rest in a queue that can be released.\r\n\r\nBecause the priority queue will not maintain the order of the inserted batches and once we merge batches we have no way to track the original order we cannot have a stable sort.  I propose that we change the algorithm so that each inserted batch includes an insertion order value, which will be used to maintain the order of the batches. Then the order of operations starting at step 5 will change.\r\n\r\n5. Get the lowest row that is still int he queue and slice each of the smaller batches by that.\r\n6. Put the sliced input batches back in the queue that are larger than the cutoff.\r\n7. If the fully sorted data is large enough to output, merge sort it and output the result\r\n8. If the fully sorted data is not large enough add them to a holding queue until they are large enough to sort.\r\n\r\nThe other key step here is to make sure that we use the stable sort API for CUDF and possibly work with CUDF to get a stable merge sort API too. If they cannot provide that to us, we can concat the batches in order and stable sort the resulting batch.\r\n\r\nWhen this is done we should do some performance measurements. Ideally we would keep the existing config and use it to configure if we want stable sort or not. We would have stable be the default assuming that the performance difference is not too horrible.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9275/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9275/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}