{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8846",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8846/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8846/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8846/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/8846",
    "id": 1825393019,
    "node_id": "I_kwDOD7z77c5szUl7",
    "number": 8846,
    "title": "[BUG] `EXPLODE()` on `FULL JOIN` output fails with `AssertionError` (SPARK-44251)",
    "user": {
        "login": "mythrocks",
        "id": 5607330,
        "node_id": "MDQ6VXNlcjU2MDczMzA=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5607330?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mythrocks",
        "html_url": "https://github.com/mythrocks",
        "followers_url": "https://api.github.com/users/mythrocks/followers",
        "following_url": "https://api.github.com/users/mythrocks/following{/other_user}",
        "gists_url": "https://api.github.com/users/mythrocks/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/mythrocks/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/mythrocks/subscriptions",
        "organizations_url": "https://api.github.com/users/mythrocks/orgs",
        "repos_url": "https://api.github.com/users/mythrocks/repos",
        "events_url": "https://api.github.com/users/mythrocks/events{/privacy}",
        "received_events_url": "https://api.github.com/users/mythrocks/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 5390613357,
            "node_id": "LA_kwDOD7z77c8AAAABQU47bQ",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/audit_3.4.1",
            "name": "audit_3.4.1",
            "color": "0052cc",
            "default": false,
            "description": "Audit related tasks for 3.4.1"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-07-27T23:50:23Z",
    "updated_at": "2023-08-08T20:25:23Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "Repro SQL:\r\n```sql\r\n-- First table.\r\nCREATE OR REPLACE TEMP VIEW t1 AS VALUES (1, 2), (null, 7) AS (c1, c2);\r\n-- Second table.\r\nCREATE OR REPLACE TEMP VIEW t1 AS VALUES (2, 3) AS (c1, c2);\r\n\r\n-- JOIN and EXPLODE.\r\nSELECT EXPLODE(ARRAY(C1)) FROM t1 FULL JOIN t2 USING (c1);\r\n```\r\n\r\nFailure trace:\r\n```\r\nDriver stacktrace:\r\n        at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\r\n        at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\r\n        at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\r\n        at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n        at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n        at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\r\n...\r\nCaused by: java.lang.AssertionError:  value at 0 is null\r\n        at ai.rapids.cudf.HostColumnVectorCore.assertsForGet(HostColumnVectorCore.java:230)\r\n        at ai.rapids.cudf.HostColumnVectorCore.getInt(HostColumnVectorCore.java:256)\r\n        at com.nvidia.spark.rapids.RapidsHostColumnVectorCore.getInt(RapidsHostColumnVectorCore.java:109)\r\n        at org.apache.spark.sql.vectorized.ColumnarBatchRow.getInt(ColumnarBatch.java:202)\r\n        at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\r\n```\r\n\r\nNote: Apache Spark versions < 3.4 do not crash on CPU, but they do return the wrong results. This was fixed in Apache Spark 3.4.\r\n\r\nAny tests added for this need to be skipped version < 3.4.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8846/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8846/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}