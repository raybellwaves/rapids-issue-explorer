{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8788",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8788/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8788/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8788/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/8788",
    "id": 1819353540,
    "node_id": "I_kwDOD7z77c5scSHE",
    "number": 8788,
    "title": "[BUG] Error reading a Parquet file with missing fields using schema evolution",
    "user": {
        "login": "razajafri",
        "id": 8813002,
        "node_id": "MDQ6VXNlcjg4MTMwMDI=",
        "avatar_url": "https://avatars.githubusercontent.com/u/8813002?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/razajafri",
        "html_url": "https://github.com/razajafri",
        "followers_url": "https://api.github.com/users/razajafri/followers",
        "following_url": "https://api.github.com/users/razajafri/following{/other_user}",
        "gists_url": "https://api.github.com/users/razajafri/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/razajafri/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/razajafri/subscriptions",
        "organizations_url": "https://api.github.com/users/razajafri/orgs",
        "repos_url": "https://api.github.com/users/razajafri/repos",
        "events_url": "https://api.github.com/users/razajafri/events{/privacy}",
        "received_events_url": "https://api.github.com/users/razajafri/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 4029093938,
            "node_id": "LA_kwDOD7z77c7wJxgy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/reliability",
            "name": "reliability",
            "color": "2654AF",
            "default": false,
            "description": "Features to improve reliability or bugs that severly impact the reliability of the plugin"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-07-25T00:53:13Z",
    "updated_at": "2023-07-25T20:44:35Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nReading a Parquet file with null values in a complex field results in an Exception\r\n\r\n**Steps/Code to reproduce bug**\r\nThe Parquet file attached has the following schema \r\n```\r\nroot\r\n |-- id: integer (nullable = true)\r\n |-- name: struct (nullable = true)\r\n |    |-- first: string (nullable = true)\r\n |    |-- last: string (nullable = true)\r\n |-- address: string (nullable = true)\r\n |-- p: integer (nullable = true)\r\n\r\n```\r\nIf we read this file with a custom schema (for schema evolution) using the following command \r\n\r\n```\r\nscala> val schema = \"`id` INT, `name` STRUCT<`first`: STRING, `middle`: STRING, `last`: STRING>, `address` STRING,`friends` ARRAY<STRUCT<`first`: STRING, `middle`: STRING, `last`: STRING>>,`p` INT\"\r\n\r\nscala> val df = spark.read.format(\"parquet\").schema(schema).load(<PATH_TO_PARQUET_FILE>)\r\n\r\nscala> df.printSchema\r\nroot\r\n |-- id: integer (nullable = true)\r\n |-- name: struct (nullable = true)\r\n |    |-- first: string (nullable = true)\r\n |    |-- middle: string (nullable = true)\r\n |    |-- last: string (nullable = true)\r\n |-- address: string (nullable = true)\r\n |-- friends: array (nullable = true)\r\n |    |-- element: struct (containsNull = true)\r\n |    |    |-- first: string (nullable = true)\r\n |    |    |-- middle: string (nullable = true)\r\n |    |    |-- last: string (nullable = true)\r\n |-- p: integer (nullable = true)\r\n```\r\nBut running the following command will result in an Exception\r\n\r\n```\r\nscala> spark.sql(\"select name.middle from contacts where p = 2\").show(false) \r\n23/07/25 00:41:10 WARN GpuOverrides: \r\n!Exec <CollectLimitExec> cannot run on GPU because the Exec CollectLimitExec has been disabled, and is disabled by default because Collect Limit replacement can be slower on the GPU, if huge number of rows in a batch it could help by limiting the number of rows transferred from GPU to CPU. Set spark.rapids.sql.exec.CollectLimitExec to true if you wish to enable it\r\n  @Partitioning <SinglePartition$> could run on GPU\r\n```\r\n<details>\r\n  <summary>Exception Details</summary>\r\n\r\n  23/07/25 00:41:10 ERROR Executor: Exception in task 0.0 in stage 19.0 (TID 19)\r\nai.rapids.cudf.CudfException: CUDF failure at: /home/jenkins/agent/workspace/jenkins-spark-rapids-jni_nightly-dev-471-cuda11/thirdparty/cudf/cpp/src/io/parquet/reader_impl_helpers.cpp:288: Found no metadata for schema index\r\n        at ai.rapids.cudf.ParquetChunkedReader.readChunk(Native Method)\r\n        at ai.rapids.cudf.ParquetChunkedReader.readChunk(ParquetChunkedReader.java:111)\r\n        at com.nvidia.spark.rapids.ParquetTableReader.$anonfun$next$1(GpuParquetScan.scala:2695)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.ParquetTableReader.next(GpuParquetScan.scala:2694)\r\n        at com.nvidia.spark.rapids.ParquetTableReader.next(GpuParquetScan.scala:2672)\r\n        at com.nvidia.spark.rapids.CachedGpuBatchIterator$.$anonfun$apply$1(GpuDataProducer.scala:159)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.CachedGpuBatchIterator$.apply(GpuDataProducer.scala:156)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.$anonfun$readBatch$5(GpuMultiFileReader.scala:1177)\r\n        at com.nvidia.spark.rapids.RmmRapidsRetryIterator$AutoCloseableAttemptSpliterator.next(RmmRapidsRetryIterator.scala:431)\r\n        at com.nvidia.spark.rapids.RmmRapidsRetryIterator$RmmRapidsRetryIterator.next(RmmRapidsRetryIterator.scala:542)\r\n        at com.nvidia.spark.rapids.RmmRapidsRetryIterator$RmmRapidsRetryAutoCloseableIterator.next(RmmRapidsRetryIterator.scala:468)\r\n        at scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\r\n        at scala.collection.TraversableOnce$FlattenOps$$anon$2.hasNext(TraversableOnce.scala:521)\r\n        at com.nvidia.spark.rapids.GpuColumnarBatchWithPartitionValuesIterator.hasNext(GpuColumnarBatchIterator.scala:107)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.next(GpuMultiFileReader.scala:1127)\r\n        at com.nvidia.spark.rapids.PartitionIterator.hasNext(dataSourceUtil.scala:29)\r\n        at com.nvidia.spark.rapids.MetricsBatchIterator.hasNext(dataSourceUtil.scala:46)\r\n        at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n        at org.apache.spark.sql.rapids.GpuFileSourceScanExec$$anon$1.hasNext(GpuFileSourceScanExec.scala:477)\r\n        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n        at com.nvidia.spark.rapids.CollectTimeIterator.$anonfun$hasNext$1(GpuExec.scala:177)\r\n        at com.nvidia.spark.rapids.CollectTimeIterator.$anonfun$hasNext$1$adapted(GpuExec.scala:176)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.CollectTimeIterator.hasNext(GpuExec.scala:176)\r\n        at com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.getHasOnDeck(GpuCoalesceBatches.scala:309)\r\n        at com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.hasNext(GpuCoalesceBatches.scala:326)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.$anonfun$fetchNextBatch$2(GpuColumnarToRowExec.scala:256)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.fetchNextBatch(GpuColumnarToRowExec.scala:255)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.loadNextBatch(GpuColumnarToRowExec.scala:228)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.hasNext(GpuColumnarToRowExec.scala:272)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:350)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\r\n        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n        at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n        at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:750)\r\n23/07/25 00:41:10 WARN TaskSetManager: Lost task 0.0 in stage 19.0 (TID 19) (10.110.46.120 executor driver): ai.rapids.cudf.CudfException: CUDF failure at: /home/jenkins/agent/workspace/jenkins-spark-rapids-jni_nightly-dev-471-cuda11/thirdparty/cudf/cpp/src/io/parquet/reader_impl_helpers.cpp:288: Found no metadata for schema index\r\n        at ai.rapids.cudf.ParquetChunkedReader.readChunk(Native Method)\r\n        at ai.rapids.cudf.ParquetChunkedReader.readChunk(ParquetChunkedReader.java:111)\r\n        at com.nvidia.spark.rapids.ParquetTableReader.$anonfun$next$1(GpuParquetScan.scala:2695)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.ParquetTableReader.next(GpuParquetScan.scala:2694)\r\n        at com.nvidia.spark.rapids.ParquetTableReader.next(GpuParquetScan.scala:2672)\r\n        at com.nvidia.spark.rapids.CachedGpuBatchIterator$.$anonfun$apply$1(GpuDataProducer.scala:159)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.CachedGpuBatchIterator$.apply(GpuDataProducer.scala:156)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.$anonfun$readBatch$5(GpuMultiFileReader.scala:1177)\r\n        at com.nvidia.spark.rapids.RmmRapidsRetryIterator$AutoCloseableAttemptSpliterator.next(RmmRapidsRetryIterator.scala:431)\r\n        at com.nvidia.spark.rapids.RmmRapidsRetryIterator$RmmRapidsRetryIterator.next(RmmRapidsRetryIterator.scala:542)\r\n        at com.nvidia.spark.rapids.RmmRapidsRetryIterator$RmmRapidsRetryAutoCloseableIterator.next(RmmRapidsRetryIterator.scala:468)\r\n        at scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\r\n        at scala.collection.TraversableOnce$FlattenOps$$anon$2.hasNext(TraversableOnce.scala:521)\r\n        at com.nvidia.spark.rapids.GpuColumnarBatchWithPartitionValuesIterator.hasNext(GpuColumnarBatchIterator.scala:107)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.next(GpuMultiFileReader.scala:1127)\r\n        at com.nvidia.spark.rapids.PartitionIterator.hasNext(dataSourceUtil.scala:29)\r\n        at com.nvidia.spark.rapids.MetricsBatchIterator.hasNext(dataSourceUtil.scala:46)\r\n        at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n        at org.apache.spark.sql.rapids.GpuFileSourceScanExec$$anon$1.hasNext(GpuFileSourceScanExec.scala:477)\r\n        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n        at com.nvidia.spark.rapids.CollectTimeIterator.$anonfun$hasNext$1(GpuExec.scala:177)\r\n        at com.nvidia.spark.rapids.CollectTimeIterator.$anonfun$hasNext$1$adapted(GpuExec.scala:176)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.CollectTimeIterator.hasNext(GpuExec.scala:176)\r\n        at com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.getHasOnDeck(GpuCoalesceBatches.scala:309)\r\n        at com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.hasNext(GpuCoalesceBatches.scala:326)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.$anonfun$fetchNextBatch$2(GpuColumnarToRowExec.scala:256)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.fetchNextBatch(GpuColumnarToRowExec.scala:255)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.loadNextBatch(GpuColumnarToRowExec.scala:228)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.hasNext(GpuColumnarToRowExec.scala:272)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:350)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\r\n        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n        at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n        at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:750)\r\n\r\n23/07/25 00:41:10 ERROR TaskSetManager: Task 0 in stage 19.0 failed 1 times; aborting job\r\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 19) (10.110.46.120 executor driver): ai.rapids.cudf.CudfException: CUDF failure at: /home/jenkins/agent/workspace/jenkins-spark-rapids-jni_nightly-dev-471-cuda11/thirdparty/cudf/cpp/src/io/parquet/reader_impl_helpers.cpp:288: Found no metadata for schema index\r\n        at ai.rapids.cudf.ParquetChunkedReader.readChunk(Native Method)\r\n        at ai.rapids.cudf.ParquetChunkedReader.readChunk(ParquetChunkedReader.java:111)\r\n        at com.nvidia.spark.rapids.ParquetTableReader.$anonfun$next$1(GpuParquetScan.scala:2695)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.ParquetTableReader.next(GpuParquetScan.scala:2694)\r\n        at com.nvidia.spark.rapids.ParquetTableReader.next(GpuParquetScan.scala:2672)\r\n        at com.nvidia.spark.rapids.CachedGpuBatchIterator$.$anonfun$apply$1(GpuDataProducer.scala:159)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.CachedGpuBatchIterator$.apply(GpuDataProducer.scala:156)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.$anonfun$readBatch$5(GpuMultiFileReader.scala:1177)\r\n        at com.nvidia.spark.rapids.RmmRapidsRetryIterator$AutoCloseableAttemptSpliterator.next(RmmRapidsRetryIterator.scala:431)\r\n        at com.nvidia.spark.rapids.RmmRapidsRetryIterator$RmmRapidsRetryIterator.next(RmmRapidsRetryIterator.scala:542)\r\n        at com.nvidia.spark.rapids.RmmRapidsRetryIterator$RmmRapidsRetryAutoCloseableIterator.next(RmmRapidsRetryIterator.scala:468)\r\n        at scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\r\n        at scala.collection.TraversableOnce$FlattenOps$$anon$2.hasNext(TraversableOnce.scala:521)\r\n        at com.nvidia.spark.rapids.GpuColumnarBatchWithPartitionValuesIterator.hasNext(GpuColumnarBatchIterator.scala:107)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.next(GpuMultiFileReader.scala:1127)\r\n        at com.nvidia.spark.rapids.PartitionIterator.hasNext(dataSourceUtil.scala:29)\r\n        at com.nvidia.spark.rapids.MetricsBatchIterator.hasNext(dataSourceUtil.scala:46)\r\n        at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n        at org.apache.spark.sql.rapids.GpuFileSourceScanExec$$anon$1.hasNext(GpuFileSourceScanExec.scala:477)\r\n        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n        at com.nvidia.spark.rapids.CollectTimeIterator.$anonfun$hasNext$1(GpuExec.scala:177)\r\n        at com.nvidia.spark.rapids.CollectTimeIterator.$anonfun$hasNext$1$adapted(GpuExec.scala:176)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.CollectTimeIterator.hasNext(GpuExec.scala:176)\r\n        at com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.getHasOnDeck(GpuCoalesceBatches.scala:309)\r\n        at com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.hasNext(GpuCoalesceBatches.scala:326)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.$anonfun$fetchNextBatch$2(GpuColumnarToRowExec.scala:256)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.fetchNextBatch(GpuColumnarToRowExec.scala:255)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.loadNextBatch(GpuColumnarToRowExec.scala:228)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.hasNext(GpuColumnarToRowExec.scala:272)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:350)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\r\n        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n        at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n        at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:750)\r\n\r\nDriver stacktrace:\r\n  at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\r\n  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\r\n  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\r\n  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\r\n  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\r\n  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\r\n  at scala.Option.foreach(Option.scala:407)\r\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\r\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\r\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\r\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\r\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\r\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\r\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\r\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\r\n  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:492)\r\n  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:445)\r\n  at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)\r\n  at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)\r\n  at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)\r\n  at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)\r\n  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\r\n  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\r\n  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\r\n  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)\r\n  at org.apache.spark.sql.Dataset.head(Dataset.scala:2728)\r\n  at org.apache.spark.sql.Dataset.take(Dataset.scala:2935)\r\n  at org.apache.spark.sql.Dataset.getRows(Dataset.scala:287)\r\n  at org.apache.spark.sql.Dataset.showString(Dataset.scala:326)\r\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:808)\r\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:785)\r\n  ... 47 elided\r\nCaused by: ai.rapids.cudf.CudfException: CUDF failure at: /home/jenkins/agent/workspace/jenkins-spark-rapids-jni_nightly-dev-471-cuda11/thirdparty/cudf/cpp/src/io/parquet/reader_impl_helpers.cpp:288: Found no metadata for schema index\r\n  at ai.rapids.cudf.ParquetChunkedReader.readChunk(Native Method)\r\n  at ai.rapids.cudf.ParquetChunkedReader.readChunk(ParquetChunkedReader.java:111)\r\n  at com.nvidia.spark.rapids.ParquetTableReader.$anonfun$next$1(GpuParquetScan.scala:2695)\r\n  at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n  at com.nvidia.spark.rapids.ParquetTableReader.next(GpuParquetScan.scala:2694)\r\n  at com.nvidia.spark.rapids.ParquetTableReader.next(GpuParquetScan.scala:2672)\r\n  at com.nvidia.spark.rapids.CachedGpuBatchIterator$.$anonfun$apply$1(GpuDataProducer.scala:159)\r\n  at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n  at com.nvidia.spark.rapids.CachedGpuBatchIterator$.apply(GpuDataProducer.scala:156)\r\n  at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.$anonfun$readBatch$5(GpuMultiFileReader.scala:1177)\r\n  at com.nvidia.spark.rapids.RmmRapidsRetryIterator$AutoCloseableAttemptSpliterator.next(RmmRapidsRetryIterator.scala:431)\r\n  at com.nvidia.spark.rapids.RmmRapidsRetryIterator$RmmRapidsRetryIterator.next(RmmRapidsRetryIterator.scala:542)\r\n  at com.nvidia.spark.rapids.RmmRapidsRetryIterator$RmmRapidsRetryAutoCloseableIterator.next(RmmRapidsRetryIterator.scala:468)\r\n  at scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\r\n  at scala.collection.TraversableOnce$FlattenOps$$anon$2.hasNext(TraversableOnce.scala:521)\r\n  at com.nvidia.spark.rapids.GpuColumnarBatchWithPartitionValuesIterator.hasNext(GpuColumnarBatchIterator.scala:107)\r\n  at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n  at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.next(GpuMultiFileReader.scala:1127)\r\n  at com.nvidia.spark.rapids.PartitionIterator.hasNext(dataSourceUtil.scala:29)\r\n  at com.nvidia.spark.rapids.MetricsBatchIterator.hasNext(dataSourceUtil.scala:46)\r\n  at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n  at org.apache.spark.sql.rapids.GpuFileSourceScanExec$$anon$1.hasNext(GpuFileSourceScanExec.scala:477)\r\n  at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n  at com.nvidia.spark.rapids.CollectTimeIterator.$anonfun$hasNext$1(GpuExec.scala:177)\r\n  at com.nvidia.spark.rapids.CollectTimeIterator.$anonfun$hasNext$1$adapted(GpuExec.scala:176)\r\n  at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n  at com.nvidia.spark.rapids.CollectTimeIterator.hasNext(GpuExec.scala:176)\r\n  at com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.getHasOnDeck(GpuCoalesceBatches.scala:309)\r\n  at com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.hasNext(GpuCoalesceBatches.scala:326)\r\n  at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n  at com.nvidia.spark.rapids.ColumnarToRowIterator.$anonfun$fetchNextBatch$2(GpuColumnarToRowExec.scala:256)\r\n  at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n  at com.nvidia.spark.rapids.ColumnarToRowIterator.fetchNextBatch(GpuColumnarToRowExec.scala:255)\r\n  at com.nvidia.spark.rapids.ColumnarToRowIterator.loadNextBatch(GpuColumnarToRowExec.scala:228)\r\n  at com.nvidia.spark.rapids.ColumnarToRowIterator.hasNext(GpuColumnarToRowExec.scala:272)\r\n  at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n  at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:350)\r\n  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\r\n  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\r\n  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n  at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n  at org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n  at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\r\n  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n  at java.lang.Thread.run(Thread.java:750)\r\n\r\n\r\n</details>\r\n\r\n\r\n\r\n**Expected behavior**\r\n```\r\nscala> spark.sql(\"select name.middle from contacts where p = 2\").show(false) \r\n+------+\r\n|middle|\r\n+------+\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n|null  |\r\n+------+\r\nonly showing top 20 rows\r\n\r\n```\r\n\r\n**Additional context**\r\n<details>\r\n<summary>\r\nRunning the query without any condition results in a different Exception </summary>\r\n\r\nscala> spark.sql(\"select name.middle from contacts\").show(false) \r\n23/07/25 00:28:17 WARN GpuOverrides: \r\n!Exec <CollectLimitExec> cannot run on GPU because the Exec CollectLimitExec has been disabled, and is disabled by default because Collect Limit replacement can be slower on the GPU, if huge number of rows in a batch it could help by limiting the number of rows transferred from GPU to CPU. Set spark.rapids.sql.exec.CollectLimitExec to true if you wish to enable it\r\n  @ Partitioning <SinglePartition$> could run on GPU\r\n\r\n23/07/25 00:28:17 ERROR Executor: Exception in task 0.0 in stage 12.0 (TID 12)\r\njava.lang.IndexOutOfBoundsException: Index: 0, Size: 0\r\n        at java.util.ArrayList.rangeCheck(ArrayList.java:659)\r\n        at java.util.ArrayList.get(ArrayList.java:435)\r\n        at java.util.Collections$UnmodifiableList.get(Collections.java:1311)\r\n        at org.apache.parquet.hadoop.metadata.BlockMetaData.getStartingPos(BlockMetaData.java:103)\r\n        at org.apache.parquet.format.converter.ParquetMetadataConverter.toParquetMetadata(ParquetMetadataConverter.java:209)\r\n        at org.apache.parquet.format.converter.ParquetMetadataConverter.toParquetMetadata(ParquetMetadataConverter.java:197)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.writeFooter(GpuParquetScan.scala:1476)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.writeFooter$(GpuParquetScan.scala:1468)\r\n        at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.writeFooter(GpuParquetScan.scala:1884)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetFooterSize(GpuParquetScan.scala:1423)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetFooterSize$(GpuParquetScan.scala:1416)\r\n        at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.calculateParquetFooterSize(GpuParquetScan.scala:1884)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetOutputSize(GpuParquetScan.scala:1457)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetOutputSize$(GpuParquetScan.scala:1445)\r\n        at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.calculateParquetOutputSize(GpuParquetScan.scala:1884)\r\n        at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.calculateEstimatedBlocksOutputSize(GpuParquetScan.scala:1968)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.$anonfun$readPartFiles$1(GpuMultiFileReader.scala:1214)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.readPartFiles(GpuMultiFileReader.scala:1203)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.$anonfun$readBatch$1(GpuMultiFileReader.scala:1164)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.readBatch(GpuMultiFileReader.scala:1143)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.next(GpuMultiFileReader.scala:1116)\r\n        at com.nvidia.spark.rapids.PartitionIterator.hasNext(dataSourceUtil.scala:29)\r\n        at com.nvidia.spark.rapids.MetricsBatchIterator.hasNext(dataSourceUtil.scala:46)\r\n        at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n        at org.apache.spark.sql.rapids.GpuFileSourceScanExec$$anon$1.hasNext(GpuFileSourceScanExec.scala:477)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.$anonfun$fetchNextBatch$2(GpuColumnarToRowExec.scala:256)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.fetchNextBatch(GpuColumnarToRowExec.scala:255)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.loadNextBatch(GpuColumnarToRowExec.scala:228)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.hasNext(GpuColumnarToRowExec.scala:272)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:350)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\r\n        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n        at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n        at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:750)\r\n23/07/25 00:28:17 WARN TaskSetManager: Lost task 0.0 in stage 12.0 (TID 12) (10.110.46.120 executor driver): java.lang.IndexOutOfBoundsException: Index: 0, Size: 0\r\n        at java.util.ArrayList.rangeCheck(ArrayList.java:659)\r\n        at java.util.ArrayList.get(ArrayList.java:435)\r\n        at java.util.Collections$UnmodifiableList.get(Collections.java:1311)\r\n        at org.apache.parquet.hadoop.metadata.BlockMetaData.getStartingPos(BlockMetaData.java:103)\r\n        at org.apache.parquet.format.converter.ParquetMetadataConverter.toParquetMetadata(ParquetMetadataConverter.java:209)\r\n        at org.apache.parquet.format.converter.ParquetMetadataConverter.toParquetMetadata(ParquetMetadataConverter.java:197)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.writeFooter(GpuParquetScan.scala:1476)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.writeFooter$(GpuParquetScan.scala:1468)\r\n        at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.writeFooter(GpuParquetScan.scala:1884)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetFooterSize(GpuParquetScan.scala:1423)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetFooterSize$(GpuParquetScan.scala:1416)\r\n        at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.calculateParquetFooterSize(GpuParquetScan.scala:1884)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetOutputSize(GpuParquetScan.scala:1457)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetOutputSize$(GpuParquetScan.scala:1445)\r\n        at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.calculateParquetOutputSize(GpuParquetScan.scala:1884)\r\n        at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.calculateEstimatedBlocksOutputSize(GpuParquetScan.scala:1968)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.$anonfun$readPartFiles$1(GpuMultiFileReader.scala:1214)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.readPartFiles(GpuMultiFileReader.scala:1203)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.$anonfun$readBatch$1(GpuMultiFileReader.scala:1164)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.readBatch(GpuMultiFileReader.scala:1143)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.next(GpuMultiFileReader.scala:1116)\r\n        at com.nvidia.spark.rapids.PartitionIterator.hasNext(dataSourceUtil.scala:29)\r\n        at com.nvidia.spark.rapids.MetricsBatchIterator.hasNext(dataSourceUtil.scala:46)\r\n        at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n        at org.apache.spark.sql.rapids.GpuFileSourceScanExec$$anon$1.hasNext(GpuFileSourceScanExec.scala:477)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.$anonfun$fetchNextBatch$2(GpuColumnarToRowExec.scala:256)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.fetchNextBatch(GpuColumnarToRowExec.scala:255)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.loadNextBatch(GpuColumnarToRowExec.scala:228)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.hasNext(GpuColumnarToRowExec.scala:272)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:350)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\r\n        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n        at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n        at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:750)\r\n\r\n23/07/25 00:28:17 ERROR TaskSetManager: Task 0 in stage 12.0 failed 1 times; aborting job\r\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 12) (10.110.46.120 executor driver): java.lang.IndexOutOfBoundsException: Index: 0, Size: 0\r\n        at java.util.ArrayList.rangeCheck(ArrayList.java:659)\r\n        at java.util.ArrayList.get(ArrayList.java:435)\r\n        at java.util.Collections$UnmodifiableList.get(Collections.java:1311)\r\n        at org.apache.parquet.hadoop.metadata.BlockMetaData.getStartingPos(BlockMetaData.java:103)\r\n        at org.apache.parquet.format.converter.ParquetMetadataConverter.toParquetMetadata(ParquetMetadataConverter.java:209)\r\n        at org.apache.parquet.format.converter.ParquetMetadataConverter.toParquetMetadata(ParquetMetadataConverter.java:197)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.writeFooter(GpuParquetScan.scala:1476)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.writeFooter$(GpuParquetScan.scala:1468)\r\n        at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.writeFooter(GpuParquetScan.scala:1884)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetFooterSize(GpuParquetScan.scala:1423)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetFooterSize$(GpuParquetScan.scala:1416)\r\n        at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.calculateParquetFooterSize(GpuParquetScan.scala:1884)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetOutputSize(GpuParquetScan.scala:1457)\r\n        at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetOutputSize$(GpuParquetScan.scala:1445)\r\n        at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.calculateParquetOutputSize(GpuParquetScan.scala:1884)\r\n        at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.calculateEstimatedBlocksOutputSize(GpuParquetScan.scala:1968)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.$anonfun$readPartFiles$1(GpuMultiFileReader.scala:1214)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.readPartFiles(GpuMultiFileReader.scala:1203)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.$anonfun$readBatch$1(GpuMultiFileReader.scala:1164)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.readBatch(GpuMultiFileReader.scala:1143)\r\n        at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.next(GpuMultiFileReader.scala:1116)\r\n        at com.nvidia.spark.rapids.PartitionIterator.hasNext(dataSourceUtil.scala:29)\r\n        at com.nvidia.spark.rapids.MetricsBatchIterator.hasNext(dataSourceUtil.scala:46)\r\n        at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n        at org.apache.spark.sql.rapids.GpuFileSourceScanExec$$anon$1.hasNext(GpuFileSourceScanExec.scala:477)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.$anonfun$fetchNextBatch$2(GpuColumnarToRowExec.scala:256)\r\n        at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.fetchNextBatch(GpuColumnarToRowExec.scala:255)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.loadNextBatch(GpuColumnarToRowExec.scala:228)\r\n        at com.nvidia.spark.rapids.ColumnarToRowIterator.hasNext(GpuColumnarToRowExec.scala:272)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:350)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\r\n        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n        at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n        at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:750)\r\n\r\nDriver stacktrace:\r\n  at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\r\n  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\r\n  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\r\n  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\r\n  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\r\n  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\r\n  at scala.Option.foreach(Option.scala:407)\r\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\r\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\r\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\r\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\r\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\r\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\r\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\r\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\r\n  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:492)\r\n  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:445)\r\n  at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)\r\n  at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)\r\n  at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)\r\n  at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)\r\n  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\r\n  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\r\n  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\r\n  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)\r\n  at org.apache.spark.sql.Dataset.head(Dataset.scala:2728)\r\n  at org.apache.spark.sql.Dataset.take(Dataset.scala:2935)\r\n  at org.apache.spark.sql.Dataset.getRows(Dataset.scala:287)\r\n  at org.apache.spark.sql.Dataset.showString(Dataset.scala:326)\r\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:808)\r\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:785)\r\n  ... 47 elided\r\nCaused by: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0\r\n  at java.util.ArrayList.rangeCheck(ArrayList.java:659)\r\n  at java.util.ArrayList.get(ArrayList.java:435)\r\n  at java.util.Collections$UnmodifiableList.get(Collections.java:1311)\r\n  at org.apache.parquet.hadoop.metadata.BlockMetaData.getStartingPos(BlockMetaData.java:103)\r\n  at org.apache.parquet.format.converter.ParquetMetadataConverter.toParquetMetadata(ParquetMetadataConverter.java:209)\r\n  at org.apache.parquet.format.converter.ParquetMetadataConverter.toParquetMetadata(ParquetMetadataConverter.java:197)\r\n  at com.nvidia.spark.rapids.ParquetPartitionReaderBase.writeFooter(GpuParquetScan.scala:1476)\r\n  at com.nvidia.spark.rapids.ParquetPartitionReaderBase.writeFooter$(GpuParquetScan.scala:1468)\r\n  at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.writeFooter(GpuParquetScan.scala:1884)\r\n  at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetFooterSize(GpuParquetScan.scala:1423)\r\n  at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetFooterSize$(GpuParquetScan.scala:1416)\r\n  at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.calculateParquetFooterSize(GpuParquetScan.scala:1884)\r\n  at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetOutputSize(GpuParquetScan.scala:1457)\r\n  at com.nvidia.spark.rapids.ParquetPartitionReaderBase.calculateParquetOutputSize$(GpuParquetScan.scala:1445)\r\n  at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.calculateParquetOutputSize(GpuParquetScan.scala:1884)\r\n  at com.nvidia.spark.rapids.MultiFileParquetPartitionReader.calculateEstimatedBlocksOutputSize(GpuParquetScan.scala:1968)\r\n  at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.$anonfun$readPartFiles$1(GpuMultiFileReader.scala:1214)\r\n  at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n  at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.readPartFiles(GpuMultiFileReader.scala:1203)\r\n  at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.$anonfun$readBatch$1(GpuMultiFileReader.scala:1164)\r\n  at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n  at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.readBatch(GpuMultiFileReader.scala:1143)\r\n  at com.nvidia.spark.rapids.MultiFileCoalescingPartitionReaderBase.next(GpuMultiFileReader.scala:1116)\r\n  at com.nvidia.spark.rapids.PartitionIterator.hasNext(dataSourceUtil.scala:29)\r\n  at com.nvidia.spark.rapids.MetricsBatchIterator.hasNext(dataSourceUtil.scala:46)\r\n  at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n  at org.apache.spark.sql.rapids.GpuFileSourceScanExec$$anon$1.hasNext(GpuFileSourceScanExec.scala:477)\r\n  at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n  at com.nvidia.spark.rapids.ColumnarToRowIterator.$anonfun$fetchNextBatch$2(GpuColumnarToRowExec.scala:256)\r\n  at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\n  at com.nvidia.spark.rapids.ColumnarToRowIterator.fetchNextBatch(GpuColumnarToRowExec.scala:255)\r\n  at com.nvidia.spark.rapids.ColumnarToRowIterator.loadNextBatch(GpuColumnarToRowExec.scala:228)\r\n  at com.nvidia.spark.rapids.ColumnarToRowIterator.hasNext(GpuColumnarToRowExec.scala:272)\r\n  at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n  at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:350)\r\n  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\r\n  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\r\n  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n  at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n  at org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n  at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\r\n  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n  at java.lang.Thread.run(Thread.java:750)\r\n</details>\r\n\r\n[part-00000-8630f7d1-71be-4e11-9691-9b2708f16d1f-c000.snappy.parquet.zip](https://github.com/NVIDIA/spark-rapids/files/12156117/part-00000-8630f7d1-71be-4e11-9691-9b2708f16d1f-c000.snappy.parquet.zip)\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8788/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8788/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}