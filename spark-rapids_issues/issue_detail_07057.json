{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7057",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7057/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7057/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7057/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7057",
    "id": 1448307911,
    "node_id": "I_kwDOD7z77c5WU2zH",
    "number": 7057,
    "title": "[FEA] Stop doing stupid things when moving project ops to the GPU",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735884,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODg0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        },
        {
            "id": 2094500742,
            "node_id": "MDU6TGFiZWwyMDk0NTAwNzQy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/performance",
            "name": "performance",
            "color": "d845b1",
            "default": false,
            "description": "A performance related task/issue"
        },
        {
            "id": 3002001655,
            "node_id": "MDU6TGFiZWwzMDAyMDAxNjU1",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/ease%20of%20use",
            "name": "ease of use",
            "color": "5500FD",
            "default": false,
            "description": "Makes the product simpler to use or configure"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2022-11-14T15:48:11Z",
    "updated_at": "2022-11-16T21:43:33Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\nThere are a lot of cases where we end up doing really dumb things on the GPU. Typically this involves moving data to the GPU to do an operation that is simple to do on the CPU and then moving the data back to the CPU again afterwards. We tried to do this with a [cost based optimizer CBO](https://github.com/NVIDIA/spark-rapids/issues/1633) in the past and even got [code for it](https://github.com/NVIDIA/spark-rapids/blob/branch-22.12/sql-plugin/src/main/scala/com/nvidia/spark/rapids/CostBasedOptimizer.scala) checked in. but it didn't really work out all that well and it is off by default.\r\n\r\nIn the mean time we have spent a lot of effort with delta lake log queries to make them always be on the CPU because we end up having really bad performance on the GPU with them.\r\n\r\n**Describe the solution you'd like**\r\n\r\nDevelop a number of test situations where we do something stupid today. At a minimum we need a test that starts out on the CPU tries to reorder or drop a column on the GPU (something that is almost free on the CPU) and then goes back to the CPU for more processing.  We should also look at the delta lake log processing for ideas and examples of things that are bad on the GPU. We should keep in mind that there are a lot of variables that impact performance. Things like the number of rows being processed and the schema of the columns can have a huge impact on performance and should be a part of the tests. We should also come up with a set of cases, if we can find any, where the GPU doing a project can pay the cost of doing the transitions.\r\n\r\nIf we cannot find any project operation where going to the GPU just for the project and back to the CPU is worth it, then things are simple we write a hand coded rule to never do this, just like we have for shuffle. We need to be careful here and might need to have a config to disable it for testing because we do this a lot in our integration tests because we are looking at functionality/correctness and not performance.\r\n\r\nIf there are cases where it is worth the transition to do it, then we need to test a few alternative.\r\n\r\n1. Hand coded rule where we always fall back to the CPU.\r\n2. Hand coded rule where we only fall back in very obviously bad cases (the CPU is doing no computation just dropping columns, re-ordering columns, adding scalars/etc).\r\n3. The current CBO code (we might have just not tested it properly enough)\r\n4. If we see some promise in the current CBO code, but it is not great, we might want to look to see if we can find some bugs in how it is implemented.\r\n\r\nIf CBO or a modified CBO does look like a good solution we need to discuss if it goes in as is, or if we have a way to restricting it to just looking at situations that this is covering, a ProjectExec that could be on the GPU, but is surrounded by CPU operations.\r\n\r\nIf we find a good solution for `ProjectExec`, then we should start to look at other operators too and expand the solution. `FilterExec` is a good example because it is very similar to `ProjectExec`.  After that we can start to look at other Exec operators that can pay for themselves or else we would never do anything on the GPU.\r\n\r\n\r\n**Describe alternatives you've considered**\r\nKeep what we are doing today.\r\n\r\n**Additional context**\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7057/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7057/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}