{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8059",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8059/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8059/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8059/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/8059",
    "id": 1659042606,
    "node_id": "I_kwDOD7z77c5i4vsu",
    "number": 8059,
    "title": "[FEA] Fully support `spark.sql.legacy.parquet.nanosAsLong` instead of falling back to CPU",
    "user": {
        "login": "andygrove",
        "id": 934084,
        "node_id": "MDQ6VXNlcjkzNDA4NA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/934084?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/andygrove",
        "html_url": "https://github.com/andygrove",
        "followers_url": "https://api.github.com/users/andygrove/followers",
        "following_url": "https://api.github.com/users/andygrove/following{/other_user}",
        "gists_url": "https://api.github.com/users/andygrove/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/andygrove/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/andygrove/subscriptions",
        "organizations_url": "https://api.github.com/users/andygrove/orgs",
        "repos_url": "https://api.github.com/users/andygrove/repos",
        "events_url": "https://api.github.com/users/andygrove/events{/privacy}",
        "received_events_url": "https://api.github.com/users/andygrove/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735884,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODg0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-04-07T17:50:07Z",
    "updated_at": "2023-04-12T20:18:14Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\nIn https://github.com/NVIDIA/spark-rapids/pull/8044 we fall back to CPU for Spark 3.2.4+, 3.3.2+, 3.4.0 if `spark.sql.legacy.parquet.nanosAsLong=true`.\r\n\r\nHowever, for Spark 3.1.x, the GPU correctly supports returning nanos as long (the default in 3.1.x). This suggest that perhaps we could support it in other versions as well.\r\n\r\n```\r\n     / __/__  ___ _____/ /__\r\n    _\\ \\/ _ \\/ _ `/ __/  '_/\r\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.1.1\r\n      /_/\r\n         \r\nUsing Scala version 2.12.10 (OpenJDK 64-Bit Server VM, Java 1.8.0_362)\r\nType in expressions to have them evaluated.\r\nType :help for more information.\r\n\r\nscala> spark.read.parquet(\"/home/andy/git/nvidia/spark-rapids/integration_tests/src/test/resources/timestamp-nanos.parquet\").show\r\n23/04/07 15:46:40 WARN GpuOverrides:                                            \r\n!Exec <CollectLimitExec> cannot run on GPU because the Exec CollectLimitExec has been disabled, and is disabled by default because Collect Limit replacement can be slower on the GPU, if huge number of rows in a batch it could help by limiting the number of rows transferred from GPU to CPU. Set spark.rapids.sql.exec.CollectLimitExec to true if you wish to enable it\r\n  @Partitioning <SinglePartition$> could run on GPU\r\n  *Exec <ProjectExec> will run on GPU\r\n    *Expression <Alias> cast(id#0L as string) AS id#9 will run on GPU\r\n      *Expression <Cast> cast(id#0L as string) will run on GPU\r\n    *Expression <Alias> cast(birthday#2L as string) AS birthday#11 will run on GPU\r\n      *Expression <Cast> cast(birthday#2L as string) will run on GPU\r\n    *Exec <FileSourceScanExec> will run on GPU\r\n\r\n+---+-------+-------------------+                                               \r\n| id|   name|           birthday|\r\n+---+-------+-------------------+\r\n|  1|  Alice|1668537129000000002|\r\n|  2|    Bob|1668537129000000003|\r\n|  3|Cecilia|1668537129123534758|\r\n+---+-------+-------------------+\r\n\r\n\r\nscala> spark.conf.set(\"spark.rapids.sql.enabled\", \"false\")\r\n\r\nscala> spark.read.parquet(\"/home/andy/git/nvidia/spark-rapids/integration_tests/src/test/resources/timestamp-nanos.parquet\").show\r\n+---+-------+-------------------+\r\n| id|   name|           birthday|\r\n+---+-------+-------------------+\r\n|  1|  Alice|1668537129000000002|\r\n|  2|    Bob|1668537129000000003|\r\n|  3|Cecilia|1668537129123534758|\r\n+---+-------+-------------------+\r\n```\r\n\r\n**Describe the solution you'd like**\r\nSupport this functionality so that we do not need to fall back to CPU.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n\r\n**Additional context**\r\n\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8059/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8059/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}