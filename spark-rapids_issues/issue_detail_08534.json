{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8534",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8534/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8534/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8534/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/8534",
    "id": 1748770225,
    "node_id": "I_kwDOD7z77c5oPB2x",
    "number": 8534,
    "title": "[DOC] Starting Kubernetes documentation can be more approachable",
    "user": {
        "login": "hyperbolic2346",
        "id": 3506308,
        "node_id": "MDQ6VXNlcjM1MDYzMDg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3506308?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/hyperbolic2346",
        "html_url": "https://github.com/hyperbolic2346",
        "followers_url": "https://api.github.com/users/hyperbolic2346/followers",
        "following_url": "https://api.github.com/users/hyperbolic2346/following{/other_user}",
        "gists_url": "https://api.github.com/users/hyperbolic2346/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/hyperbolic2346/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/hyperbolic2346/subscriptions",
        "organizations_url": "https://api.github.com/users/hyperbolic2346/orgs",
        "repos_url": "https://api.github.com/users/hyperbolic2346/repos",
        "events_url": "https://api.github.com/users/hyperbolic2346/events{/privacy}",
        "received_events_url": "https://api.github.com/users/hyperbolic2346/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735878,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc4",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/documentation",
            "name": "documentation",
            "color": "0075ca",
            "default": true,
            "description": "Improvements or additions to documentation"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-06-08T22:59:50Z",
    "updated_at": "2023-07-28T00:05:47Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "I am reading through the [Getting Started for Kubernetes](https://nvidia.github.io/spark-rapids/docs/get-started/getting-started-kubernetes.html) documentation with the lens of a Kubernetes user attempting to install the Spark-Rapids plugin. Here are my comments as I go through it:\r\n\r\n- [ ] The Kubernetes documentation doesn't read anything like a normal Kubernetes document. There is no helm chart and no deployment yaml here. It took me a while to realize that Spark is going to access the cluster and the user creates the things by running Spark itself. A typical Kubernetes deployment fills out some yaml/config and installs into the cluster and then things talk to the running application. This isn't a slight on the documentation, but an indication that the perspective is odd for a Kubernetes developer and documentation with a \"how does Spark work with Kubernetes\" overview would be nice, even if it is pointing to Spark documentation.\r\n- [ ] The startup could be so much more condensed and approachable if the user wasn't building their own docker images. I found a Databricks image being published, but couldn't find any docker image indicating it would work with Kubernetes. I found #4158 referencing this, but no real plans. This would be so much easier for people to kick the tires if they didn't have to build this image.\r\n- [ ] Layout seems odd. There is a [Running Spark Applications in the Kubernetes Cluster](https://nvidia.github.io/spark-rapids/docs/get-started/getting-started-kubernetes.html#running-spark-applications-in-the-kubernetes-cluster) header and it talks about a simple test job submission, then running and interactive shell, etc. Then the next major section is [Running Spark Applications using Spark Operator](https://nvidia.github.io/spark-rapids/docs/get-started/getting-started-kubernetes.html#running-spark-applications-using-spark-operator) which introduces a new way to talk to the cluster after the user has invested time into the original way. An introduction to the ways to run Spark on Kubernetes before these sections and then instructions on how to do the simple job, interactive shell, etc for both would be useful. Then the user can figure out the method that will work best for them and work through a simple example using that method.\r\n\r\nUltimately, I'd like to see a TLDR with a very simple get Spark running on Kubernetes at the top and then the added detail with two deployment methods and how it work after. I think a public docker image would make this very brief.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8534/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8534/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}