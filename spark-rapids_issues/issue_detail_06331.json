{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6331",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6331/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6331/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6331/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6331",
    "id": 1339749926,
    "node_id": "I_kwDOD7z77c5P2vYm",
    "number": 6331,
    "title": "[BUG] Executor JVM fails to shutdown after trapping cudaLaunchKernel_ptsz",
    "user": {
        "login": "gerashegalov",
        "id": 3187938,
        "node_id": "MDQ6VXNlcjMxODc5Mzg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3187938?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gerashegalov",
        "html_url": "https://github.com/gerashegalov",
        "followers_url": "https://api.github.com/users/gerashegalov/followers",
        "following_url": "https://api.github.com/users/gerashegalov/following{/other_user}",
        "gists_url": "https://api.github.com/users/gerashegalov/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/gerashegalov/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/gerashegalov/subscriptions",
        "organizations_url": "https://api.github.com/users/gerashegalov/orgs",
        "repos_url": "https://api.github.com/users/gerashegalov/repos",
        "events_url": "https://api.github.com/users/gerashegalov/events{/privacy}",
        "received_events_url": "https://api.github.com/users/gerashegalov/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 2223784776,
            "node_id": "MDU6TGFiZWwyMjIzNzg0Nzc2",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/P1",
            "name": "P1",
            "color": "fbca04",
            "default": false,
            "description": "Nice to have for release"
        },
        {
            "id": 4029093938,
            "node_id": "LA_kwDOD7z77c7wJxgy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/reliability",
            "name": "reliability",
            "color": "2654AF",
            "default": false,
            "description": "Features to improve reliability or bugs that severly impact the reliability of the plugin"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2022-08-16T03:09:19Z",
    "updated_at": "2022-08-16T20:19:21Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nExecutor JVM may fail to shutdown when a CudaFatalException is thrown.\r\n\r\n**Steps/Code to reproduce bug**\r\nRun integration tests with the following fault injector config boiling down to 1%  of kernel launches hitting an PTX trap instruction.\r\n\r\n```json\r\n{\r\n   \"logLevel\": 1,\r\n   \"cudaRuntimeFaults\": {\r\n       \"cudaLaunchKernel_ptsz\": {\r\n           \"percent\": 1,\r\n           \"injectionType\": 0,\r\n           \"interceptionCount\": 1\r\n       }\r\n   },\r\n}\r\n```\r\nYou may have to add \"seed\" 1660617617\r\n\r\n```bash\r\nSPARK_TASK_MAXFAILURES=20 \\\r\nCUDA_INJECTION64_PATH=~/gits/NVIDIA/spark-rapids-jni/target/cmake-build/faultinj/libcufaultinj.so \\\r\nFAULT_INJECTOR_CONFIG_PATH=~/gits/NVIDIA/spark-rapids-jni/src/test/cpp/faultinj/test_faultinj.json \\\r\nSPARK_HOME=~/dist/spark-3.2.2-bin-hadoop3.2 \\\r\n./integration_tests/run_pyspark_from_build.sh -k array_test\r\n\r\n[2022-08-15 19:40:17.488] [info] cuInit entry point for libcufaultinj InitializeInjection\r\n[2022-08-15 19:40:17.488] [debug] globalControlInit of fault injection\r\n[2022-08-15 19:40:17.488] [trace] checking environment FAULT_INJECTOR_CONFIG_PATH\r\n[2022-08-15 19:40:17.488] [debug] FAULT_INJECTOR_CONFIG_PATH is /home/gshegalov/gits/NVIDIA/spark-rapids-jni/src/test/cpp/faultinj/test_faultinj.json\r\n[2022-08-15 19:40:17.488] [debug] will init config from /home/gshegalov/gits/NVIDIA/spark-rapids-jni/src/test/cpp/faultinj/test_faultinj.json\r\n[2022-08-15 19:40:17.488] [info] Seeding std::srand with 1660617617\r\n[2022-08-15 19:40:17.488] [info] changed log level to 1\r\n[2022-08-15 19:40:17.488] [debug] readFaultInjectorConfig from /home/gshegalov/gits/NVIDIA/spark-rapids-jni/src/test/cpp/faultinj/test_faultinj.json DONE\r\n[2022-08-15 19:40:17.488] [debug] creating a thread to watch the fault injector config interactively\r\n[2022-08-15 19:40:17.488] [debug] config watcher thread: inotify_init()\r\n[2022-08-15 19:40:17.488] [debug] config watcher thread: inotify_add_watch /home/gshegalov/gits/NVIDIA/spark-rapids-jni/src/test/cpp/faultinj/test_faultinj.json\r\n```\r\n\r\n<details>\r\n<summary>rest of the console log</summary>\r\n<pre>\r\n22/08/16 02:40:22 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 4)\r\nai.rapids.cudf.CudaFatalException: Fatal CUDA error encountered at: /home/jenkins/agent/workspace/jenkins-spark-rapids-jni_nightly-dev-183-cuda11/thirdparty/cudf/cpp/include/cudf/detail/utilities/vector_factories.hpp:290: 719 cudaErrorLaunchFailure unspecified launch failure\r\n        at ai.rapids.cudf.ColumnView.extractListElement(Native Method)\r\n        at ai.rapids.cudf.ColumnView.extractListElement(ColumnView.java:2402)\r\n        at org.apache.spark.sql.rapids.GpuGetArrayItem.doColumnar(complexTypeExtractors.scala:179)\r\n        at com.nvidia.spark.rapids.GpuBinaryExpression.$anonfun$columnarEval$3(GpuExpressions.scala:260)\r\n        at com.nvidia.spark.rapids.Arm.withResourceIfAllowed(Arm.scala:73)\r\n        at com.nvidia.spark.rapids.Arm.withResourceIfAllowed$(Arm.scala:71)\r\n        at org.apache.spark.sql.rapids.GpuGetArrayItem.withResourceIfAllowed(complexTypeExtractors.scala:81)\r\n        at com.nvidia.spark.rapids.GpuBinaryExpression.$anonfun$columnarEval$2(GpuExpressions.scala:253)\r\n        at com.nvidia.spark.rapids.Arm.withResourceIfAllowed(Arm.scala:73)\r\n        at com.nvidia.spark.rapids.Arm.withResourceIfAllowed$(Arm.scala:71)\r\n        at org.apache.spark.sql.rapids.GpuGetArrayItem.withResourceIfAllowed(complexTypeExtractors.scala:81)\r\n        at com.nvidia.spark.rapids.GpuBinaryExpression.columnarEval(GpuExpressions.scala:252)\r\n        at com.nvidia.spark.rapids.GpuBinaryExpression.columnarEval$(GpuExpressions.scala:251)\r\n        at org.apache.spark.sql.rapids.GpuGetArrayItem.columnarEval(complexTypeExtractors.scala:81)\r\n        at com.nvidia.spark.rapids.RapidsPluginImplicits$ReallyAGpuExpression.columnarEval(implicits.scala:34)\r\n        at com.nvidia.spark.rapids.GpuAlias.columnarEval(namedExpressions.scala:109)\r\n        at com.nvidia.spark.rapids.RapidsPluginImplicits$ReallyAGpuExpression.columnarEval(implicits.scala:34)\r\n        at com.nvidia.spark.rapids.GpuExpressionsUtils$.columnarEvalToColumn(GpuExpressions.scala:93)\r\n        at com.nvidia.spark.rapids.GpuProjectExec$.projectSingle(basicPhysicalOperators.scala:102)\r\n        at com.nvidia.spark.rapids.GpuProjectExec$.$anonfun$project$1(basicPhysicalOperators.scala:109)\r\n        at com.nvidia.spark.rapids.RapidsPluginImplicits$MapsSafely.$anonfun$safeMap$1(implicits.scala:216)\r\n        at com.nvidia.spark.rapids.RapidsPluginImplicits$MapsSafely.$anonfun$safeMap$1$adapted(implicits.scala:213)\r\n        at scala.collection.immutable.List.foreach(List.scala:431)\r\n        at com.nvidia.spark.rapids.RapidsPluginImplicits$MapsSafely.safeMap(implicits.scala:213)\r\n        at com.nvidia.spark.rapids.RapidsPluginImplicits$AutoCloseableProducingSeq.safeMap(implicits.scala:248)\r\n        at com.nvidia.spark.rapids.GpuProjectExec$.project(basicPhysicalOperators.scala:109)\r\n        at com.nvidia.spark.rapids.GpuProjectExec$.projectAndClose(basicPhysicalOperators.scala:73)\r\n        at com.nvidia.spark.rapids.GpuProjectExec.$anonfun$doExecuteColumnar$1(basicPhysicalOperators.scala:149)\r\n        at scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\r\n        at com.nvidia.spark.rapids.AcceleratedColumnarToRowIterator.$anonfun$fetchNextBatch$1(GpuColumnarToRowExec.scala:144)\r\n        at com.nvidia.spark.rapids.Arm.withResource(Arm.scala:28)\r\n        at com.nvidia.spark.rapids.Arm.withResource$(Arm.scala:26)\r\n        at com.nvidia.spark.rapids.AcceleratedColumnarToRowIterator.withResource(GpuColumnarToRowExec.scala:38)\r\n        at com.nvidia.spark.rapids.AcceleratedColumnarToRowIterator.fetchNextBatch(GpuColumnarToRowExec.scala:142)\r\n        at com.nvidia.spark.rapids.AcceleratedColumnarToRowIterator.populateBatch(GpuColumnarToRowExec.scala:133)\r\n        at com.nvidia.spark.rapids.AcceleratedColumnarToRowIterator.loadNextBatch(GpuColumnarToRowExec.scala:125)\r\n        at com.nvidia.spark.rapids.AcceleratedColumnarToRowIterator.hasNext(GpuColumnarToRowExec.scala:154)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:350)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\r\n        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n        at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n        at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:750)\r\n22/08/16 02:40:22 ERROR RapidsExecutorPlugin: Stopping the Executor based on exception being a fatal CUDA error: ai.rapids.cudf.CudaFatalException: Fatal CUDA error encountered at: /home/jenkins/agent/workspace/jenkins-spark-rapids-jni_nightly-dev-183-cuda11/thirdparty/cudf/cpp/include/cudf/detail/utilities/vector_factories.hpp:290: 719 cudaErrorLaunchFailure unspecified launch failure\r\n        at ai.rapids.cudf.ColumnView.extractListElement(Native Method)\r\n        at ai.rapids.cudf.ColumnView.extractListElement(ColumnView.java:2402)\r\n        at org.apache.spark.sql.rapids.GpuGetArrayItem.doColumnar(complexTypeExtractors.scala:179)\r\n        at com.nvidia.spark.rapids.GpuBinaryExpression.$anonfun$columnarEval$3(GpuExpressions.scala:260)\r\n        at com.nvidia.spark.rapids.Arm.withResourceIfAllowed(Arm.scala:73)\r\n        at com.nvidia.spark.rapids.Arm.withResourceIfAllowed$(Arm.scala:71)\r\n        at org.apache.spark.sql.rapids.GpuGetArrayItem.withResourceIfAllowed(complexTypeExtractors.scala:81)\r\n        at com.nvidia.spark.rapids.GpuBinaryExpression.$anonfun$columnarEval$2(GpuExpressions.scala:253)\r\n        at com.nvidia.spark.rapids.Arm.withResourceIfAllowed(Arm.scala:73)\r\n        at com.nvidia.spark.rapids.Arm.withResourceIfAllowed$(Arm.scala:71)\r\n        at org.apache.spark.sql.rapids.GpuGetArrayItem.withResourceIfAllowed(complexTypeExtractors.scala:81)\r\n        at com.nvidia.spark.rapids.GpuBinaryExpression.columnarEval(GpuExpressions.scala:252)\r\n        at com.nvidia.spark.rapids.GpuBinaryExpression.columnarEval$(GpuExpressions.scala:251)\r\n        at org.apache.spark.sql.rapids.GpuGetArrayItem.columnarEval(complexTypeExtractors.scala:81)\r\n        at com.nvidia.spark.rapids.RapidsPluginImplicits$ReallyAGpuExpression.columnarEval(implicits.scala:34)\r\n        at com.nvidia.spark.rapids.GpuAlias.columnarEval(namedExpressions.scala:109)\r\n        at com.nvidia.spark.rapids.RapidsPluginImplicits$ReallyAGpuExpression.columnarEval(implicits.scala:34)\r\n        at com.nvidia.spark.rapids.GpuExpressionsUtils$.columnarEvalToColumn(GpuExpressions.scala:93)\r\n        at com.nvidia.spark.rapids.GpuProjectExec$.projectSingle(basicPhysicalOperators.scala:102)\r\n        at com.nvidia.spark.rapids.GpuProjectExec$.$anonfun$project$1(basicPhysicalOperators.scala:109)\r\n        at com.nvidia.spark.rapids.RapidsPluginImplicits$MapsSafely.$anonfun$safeMap$1(implicits.scala:216)\r\n        at com.nvidia.spark.rapids.RapidsPluginImplicits$MapsSafely.$anonfun$safeMap$1$adapted(implicits.scala:213)\r\n        at scala.collection.immutable.List.foreach(List.scala:431)\r\n        at com.nvidia.spark.rapids.RapidsPluginImplicits$MapsSafely.safeMap(implicits.scala:213)\r\n        at com.nvidia.spark.rapids.RapidsPluginImplicits$AutoCloseableProducingSeq.safeMap(implicits.scala:248)\r\n        at com.nvidia.spark.rapids.GpuProjectExec$.project(basicPhysicalOperators.scala:109)\r\n        at com.nvidia.spark.rapids.GpuProjectExec$.projectAndClose(basicPhysicalOperators.scala:73)\r\n        at com.nvidia.spark.rapids.GpuProjectExec.$anonfun$doExecuteColumnar$1(basicPhysicalOperators.scala:149)\r\n        at scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\r\n        at com.nvidia.spark.rapids.AcceleratedColumnarToRowIterator.$anonfun$fetchNextBatch$1(GpuColumnarToRowExec.scala:144)\r\n        at com.nvidia.spark.rapids.Arm.withResource(Arm.scala:28)\r\n        at com.nvidia.spark.rapids.Arm.withResource$(Arm.scala:26)\r\n        at com.nvidia.spark.rapids.AcceleratedColumnarToRowIterator.withResource(GpuColumnarToRowExec.scala:38)\r\n        at com.nvidia.spark.rapids.AcceleratedColumnarToRowIterator.fetchNextBatch(GpuColumnarToRowExec.scala:142)\r\n        at com.nvidia.spark.rapids.AcceleratedColumnarToRowIterator.populateBatch(GpuColumnarToRowExec.scala:133)\r\n        at com.nvidia.spark.rapids.AcceleratedColumnarToRowIterator.loadNextBatch(GpuColumnarToRowExec.scala:125)\r\n        at com.nvidia.spark.rapids.AcceleratedColumnarToRowIterator.hasNext(GpuColumnarToRowExec.scala:154)\r\n        at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n        at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:350)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\r\n        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n        at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n        at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:750)\r\n\r\n22/08/16 02:40:52 WARN ShutdownHookManager: ShutdownHook '$anon$2' timeout, java.util.concurrent.TimeoutException\r\njava.util.concurrent.TimeoutException\r\n        at java.util.concurrent.FutureTask.get(FutureTask.java:205)\r\n        at org.apache.hadoop.util.ShutdownHookManager.executeShutdown(ShutdownHookManager.java:124)\r\n        at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:95)\r\n22/08/16 02:41:22 WARN ShutdownHookManager: ShutdownHook 'ClientFinalizer' timeout, java.util.concurrent.TimeoutException\r\njava.util.concurrent.TimeoutException\r\n        at java.util.concurrent.FutureTask.get(FutureTask.java:205)\r\n        at org.apache.hadoop.util.ShutdownHookManager.executeShutdown(ShutdownHookManager.java:124)\r\n        at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:95)\r\n22/08/16 02:41:52 ERROR ShutdownHookManager: ShutdownHookManager shutdown forcefully after 30 seconds.\r\n[2022-08-15 19:41:57.571] [debug] config watcher thread: inotify_rm_watch 349 1\r\n[2022-08-15 19:41:57.571] [debug] config watcher thread: close 349\r\n[2022-08-15 19:41:57.585] [info] exiting dynamic reconfig thread: terminateThread=1\r\n[2022-08-15 19:41:57.585] [info] reconfig thread shut down ... exiting\r\n[2022-08-15 19:41:57.585] [debug] atExitHandler: cuptiFinalize\r\n</pre>\r\n</details>\r\n\r\nJVM is almost destroyed and no longer responds to jstack or kill -3 (SIGQUIT). However,  observe a shutdown hook thread and maybe (Java thread names are truncated by Linux) [task launch workers]( https://github.com/apache/spark/blob/bb5092b9af60afdceeccb239d14be660f77ae0ea/core/src/main/scala/org/apache/spark/executor/Executor.scala#L403) spinning\r\n \r\n```bash\r\n$ top -H -p 962802\r\n    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                                                                                                     \r\n 963186 user1  20   0   27.9g   2.0g 307368 R  99.9   6.6   7:25.43 shutdown-hook-0                                                                                             \r\n 963187 user1  20   0   27.9g   2.0g 307368 R  99.9   6.6   7:25.42 Executor task l                                                                                             \r\n 963106 user1  20   0   27.9g   2.0g 307368 R  99.9   6.6   7:25.69 Executor task l                                                                                             \r\n 963108 user1  20   0   27.9g   2.0g 307368 R  99.9   6.6   7:25.69 Executor task l \r\n```\r\n**Expected behavior**\r\nA  graceful executor shutdown\r\n\r\n**Environment details (please complete the following information)**\r\n - Environment location: local bare-metal\r\n - Spark configuration settings related to the issue: fault injector \r\n\r\n**Additional context**\r\nhttps://github.com/NVIDIA/spark-rapids-jni/tree/branch-22.10/src/main/cpp/faultinj",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6331/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6331/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}