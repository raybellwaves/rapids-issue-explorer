{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7745",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7745/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7745/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7745/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7745",
    "id": 1582526513,
    "node_id": "I_kwDOD7z77c5eU3Ax",
    "number": 7745,
    "title": "[BUG] The catalogs should reject requests for buffer if they are shutting down",
    "user": {
        "login": "abellina",
        "id": 1901059,
        "node_id": "MDQ6VXNlcjE5MDEwNTk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1901059?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/abellina",
        "html_url": "https://github.com/abellina",
        "followers_url": "https://api.github.com/users/abellina/followers",
        "following_url": "https://api.github.com/users/abellina/following{/other_user}",
        "gists_url": "https://api.github.com/users/abellina/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/abellina/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/abellina/subscriptions",
        "organizations_url": "https://api.github.com/users/abellina/orgs",
        "repos_url": "https://api.github.com/users/abellina/repos",
        "events_url": "https://api.github.com/users/abellina/events{/privacy}",
        "received_events_url": "https://api.github.com/users/abellina/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 4029093938,
            "node_id": "LA_kwDOD7z77c7wJxgy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/reliability",
            "name": "reliability",
            "color": "2654AF",
            "default": false,
            "description": "Features to improve reliability or bugs that severly impact the reliability of the plugin"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-02-13T15:08:21Z",
    "updated_at": "2023-02-14T21:41:43Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "We have seen errors like this from either the shuffle catalog or the regular spillable catalog (e.g. https://github.com/NVIDIA/spark-rapids/issues/7744), where it is not clear if we have been shut down or there is an actual block missing that should be in the catalog. We need to make a distinction as it would help with debugging other issues.\r\n\r\n```\r\n23/02/10 20:35:05 WARN TaskSetManager: Lost task 88.1 in stage 350.0 (TID 28288) (spark-egx-02.nvidia.com executor 2): java.util.NoSuchElementException: Cannot locate buffers associated with ID: ShuffleBufferId(shuffle_130_27962_88,1947246)\r\n\tat com.nvidia.spark.rapids.RapidsBufferCatalog.$anonfun$acquireBuffer$1(RapidsBufferCatalog.scala:232)\r\n\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\r\n\tat com.nvidia.spark.rapids.RapidsBufferCatalog.acquireBuffer(RapidsBufferCatalog.scala:229)\r\n\tat com.nvidia.spark.rapids.RapidsBufferCatalog.com$nvidia$spark$rapids$RapidsBufferCatalog$$updateUnderlyingRapidsBuffer(RapidsBufferCatalog.scala:210)\r\n\tat com.nvidia.spark.rapids.RapidsBufferCatalog$RapidsBufferHandleImpl.setSpillPriority(RapidsBufferCatalog.scala:77)\r\n\tat com.nvidia.spark.rapids.ShuffleBufferCatalog.updateSpillPriorityForLocalRead(ShuffleBufferCatalog.scala:289)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.$anonfun$read$5(RapidsCachingReader.scala:96)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.$anonfun$read$5$adapted(RapidsCachingReader.scala:96)\r\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\r\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\r\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.$anonfun$read$3(RapidsCachingReader.scala:96)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.$anonfun$read$3$adapted(RapidsCachingReader.scala:76)\r\n\tat scala.collection.immutable.List.foreach(List.scala:392)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.$anonfun$read$1(RapidsCachingReader.scala:76)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.$anonfun$read$1$adapted(RapidsCachingReader.scala:68)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\r\n\tat scala.collection.MapLike$DefaultKeySet.foreach(MapLike.scala:181)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.read(RapidsCachingReader.scala:68)\r\n\tat org.apache.spark.sql.rapids.execution.ShuffledBatchRDD.compute(ShuffledBatchRDD.scala:152)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7745/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7745/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}