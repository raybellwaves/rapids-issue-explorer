{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7827",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7827/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7827/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7827/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7827",
    "id": 1603535606,
    "node_id": "I_kwDOD7z77c5flAL2",
    "number": 7827,
    "title": "[BUG] decompressed batches corrupt if they are made spillable",
    "user": {
        "login": "abellina",
        "id": 1901059,
        "node_id": "MDQ6VXNlcjE5MDEwNTk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1901059?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/abellina",
        "html_url": "https://github.com/abellina",
        "followers_url": "https://api.github.com/users/abellina/followers",
        "following_url": "https://api.github.com/users/abellina/following{/other_user}",
        "gists_url": "https://api.github.com/users/abellina/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/abellina/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/abellina/subscriptions",
        "organizations_url": "https://api.github.com/users/abellina/orgs",
        "repos_url": "https://api.github.com/users/abellina/repos",
        "events_url": "https://api.github.com/users/abellina/events{/privacy}",
        "received_events_url": "https://api.github.com/users/abellina/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 2096543664,
            "node_id": "MDU6TGFiZWwyMDk2NTQzNjY0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/shuffle",
            "name": "shuffle",
            "color": "67fc73",
            "default": false,
            "description": "things that impact the shuffle plugin"
        },
        {
            "id": 4029093938,
            "node_id": "LA_kwDOD7z77c7wJxgy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/reliability",
            "name": "reliability",
            "color": "2654AF",
            "default": false,
            "description": "Features to improve reliability or bugs that severly impact the reliability of the plugin"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-02-28T17:52:02Z",
    "updated_at": "2023-03-06T22:55:09Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "While working on https://github.com/NVIDIA/spark-rapids/issues/7777 I ran into an issue where a decompressed batch (via nvcomp/UCX) was made spillable, but then I got a corrupted batch out when calling `getColumnarBatch`. This is likely an issue of 23.04.\r\n\r\nSo far, when we decompress batches in `GpuCoalesceBatches` https://github.com/NVIDIA/spark-rapids/blob/branch-23.02/sql-plugin/src/main/scala/com/nvidia/spark/rapids/GpuCoalesceBatches.scala#L645, we are taking the `TableMeta` directly from the compressed vector, instead of building a new one without compression info.\r\n\r\nCode that uses the metadata to rebuild the ColumnarBatch would produce an invalid batch, because we do different things when the batch has codecs defined: https://github.com/NVIDIA/spark-rapids/blob/branch-23.02/sql-plugin/src/main/scala/com/nvidia/spark/rapids/RapidsDeviceMemoryStore.scala#L282, and https://github.com/NVIDIA/spark-rapids/blob/96ed06b338aaff35ede7a23634a5c567b48df67d/sql-plugin/src/main/scala/com/nvidia/spark/rapids/RapidsBufferStore.scala#L309\r\n\r\nI think I can fix this with #7777, but adding an issue since it's a bug, and I am not sure if it was made worse in 23.04 because of https://github.com/NVIDIA/spark-rapids/pull/7572, since we now rely on `TableMeta` on the first creation of a batch from a RapidsBuffer.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7827/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7827/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}