{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/2063",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/2063/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/2063/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/2063/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/2063",
    "id": 848448963,
    "node_id": "MDU6SXNzdWU4NDg0NDg5NjM=",
    "number": 2063,
    "title": "[BUG] Fix CSV Parsing",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 2589743725,
            "node_id": "MDU6TGFiZWwyNTg5NzQzNzI1",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/epic",
            "name": "epic",
            "color": "0E8A16",
            "default": false,
            "description": "Issue that encompasses a significant feature or body of work"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2021-04-01T13:02:44Z",
    "updated_at": "2023-12-12T21:07:45Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nI am not totally sure if this is a bug or an epic, but I have marked it as both. CSV parsing has been on by default, but it has a lot of inconsistencies with what spark does and this can cause problems.  The current plan is to mitigate this by disabling CSV by default and then working through issues until we can enable it again everywhere.\r\n\r\nImportant Issues:\r\n\r\n- [ ] #6435\r\n- [ ] #129 escape quote parsing\r\n- [ ] #6917\r\n- [ ] #6926\r\n- [ ] #2069 A quoted value with training white space, has the white space ignored by spark, but not cudf when interpreted as a string.\r\n- [ ] #2065 Fall back to CPU if schema includes `columnNameofCorruptRecord`\r\n- [ ] #6927\r\n- [ ] #2068 cudf interprets missing values at the end of the line as empty strings. Spark interprets them a null values.  This is fine when the null value is the default (an empty string), but is a problem if you set it to anything else.\r\n- [ ] #125 float parsing for infinity, negative infinity, and nan\r\n- [ ] #2066 bug when parsing comments.\r\n- [ ] #4969 (Hopefully we can use this to fix some issues with #1091)\r\n- [x] #1322\r\n- [ ] #1091 Dates don't parse extra timestamps correctly\r\n- [x] #4940\r\n- [ ] #2931\r\n- [ ] #6814 CollectLimitExec when using header row\r\n- [ ] #958 \r\n- [ ] #136 special case date/timestamp strings.\r\n- [ ] #951 have null character disable comment parsing.\r\n- [x] #126 parsing int/float values overflows\r\n- [x] #124 float values on the edge parse incorrectly\r\n- [x] #2071 boolean parsing of invalid values is wrong\r\n- [x] #1111 Dates and timestamps need to deal with `spark.sql.legacy.timeParserPolicy`\r\n\r\nInvestigate:\r\n- [ ]  #1524 More control in newer versions of spark to handle how badly formed CSV is parsed. In this case around unescaped quotes.\r\n\r\nLow Priority Issues:\r\n- [ ] Header with lots of comments at the beginning. We currently play games with turning off header checking in all but the first partition for a file. This is fine, so long as the first partition is more than just comments.  This is minor, and possibly a bug in Spark as well.\r\n- [ ] #2862\r\n- [ ] Support alternate character sets (\"encoding\" option).\r\n- [ ] Support `FAILFAST` mode. By default when Spark sees malformed data it converts it into a null `PERMISSIVE` mode. In `FAILFAST` mode it throws an exception.  There is also `DROPMALFORMED` mode that is supposed to drop bad data, but it looks like CSV does not support this.\r\n- [ ] #6846\r\n- [x] #6814\r\n- [ ] #5115\r\n- [ ] #4654\r\n- [ ] #4644\r\n- [ ] #4146\r\n- [ ] #6\r\n- [ ] #130 `multiline` support\r\n\r\nTests:\r\n- [ ] Add tests for `enforceSchema` set to false. TODO file issues Oddly for Spark when you set this to false it does more schema enforcement.  The enforce here really means force the set schema on the files. It looks like it works for our plugin, but we want to have tests to verify this\r\n- [ ] https://github.com/NVIDIA/spark-rapids/issues/9990",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/2063/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/2063/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}