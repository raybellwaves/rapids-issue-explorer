{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10498",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10498/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10498/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10498/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10498",
    "id": 2152782008,
    "node_id": "I_kwDOD7z77c6AUNi4",
    "number": 10498,
    "title": "[BUG] Unit tests failed: [INTERVAL_ARITHMETIC_OVERFLOW] integer overflow. Use 'try_add' to tolerate overflow and return NULL instead",
    "user": {
        "login": "NvTimLiu",
        "id": 50287591,
        "node_id": "MDQ6VXNlcjUwMjg3NTkx",
        "avatar_url": "https://avatars.githubusercontent.com/u/50287591?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/NvTimLiu",
        "html_url": "https://github.com/NvTimLiu",
        "followers_url": "https://api.github.com/users/NvTimLiu/followers",
        "following_url": "https://api.github.com/users/NvTimLiu/following{/other_user}",
        "gists_url": "https://api.github.com/users/NvTimLiu/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/NvTimLiu/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/NvTimLiu/subscriptions",
        "organizations_url": "https://api.github.com/users/NvTimLiu/orgs",
        "repos_url": "https://api.github.com/users/NvTimLiu/repos",
        "events_url": "https://api.github.com/users/NvTimLiu/events{/privacy}",
        "received_events_url": "https://api.github.com/users/NvTimLiu/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-02-25T14:07:07Z",
    "updated_at": "2024-02-27T21:47:34Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\n\r\nUnit tests failed: [INTERVAL_ARITHMETIC_OVERFLOW] integer overflow. Use 'try_add' to tolerate overflow and return NULL instead, details as below:\r\n\r\n```\r\nIntervalArithmeticSuite:\r\n  - test year month interval arithmetic: Add\r\n 24/02/24 13:04:17.049 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 5)\r\n org.apache.spark.SparkArithmeticException: [INTERVAL_ARITHMETIC_OVERFLOW] integer overflow. Use 'try_add' to tolerate overflow and return NULL \r\n \tat org.apache.spark.sql.errors.QueryExecutionErrors$.intervalArithmeticOverflowError(QueryExecutionErrors.scala:679) ~[spark-r:3.4.1]\r\n \tat org.apache.spark.sql.catalyst.util.IntervalMathUtils$.withOverflow(IntervalMathUtils.scala:43) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.sql.catalyst.util.IntervalMathUtils$.addExact(IntervalMathUtils.scala:26) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.sql.catalyst.util.IntervalMathUtils.addExact(IntervalMathUtils.scala) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) ~[?:?] - test year month interval arithmetic: Add overflow ,cpu\r\n \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) ~[spark-sql_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760) ~[spark-sql_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388) ~[spark-sql_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888) ~[spark-core_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888) ~[spark-core_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) ~[spark-core_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364) ~[spark-core_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328) ~[spark-core_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92) ~[spark-core_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.scheduler.Task.run(Task.scala:139) ~[spark-core_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554) ~[spark-core_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529) ~[spark-core_2.12-3.4.1.jar:3.4.1]\r\n \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557) ~[spark-core_2.12-3.4.1.jar:3.4.1]\r\n \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_392]\r\n \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_392]\r\n \tat java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_392] \r\n```",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10498/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10498/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}