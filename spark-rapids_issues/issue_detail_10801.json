{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10801",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10801/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10801/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10801/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10801",
    "id": 2292268691,
    "node_id": "I_kwDOD7z77c6IoT6T",
    "number": 10801,
    "title": "[BUG] JDK17 nightly build after Spark UT Framework is merged",
    "user": {
        "login": "NvTimLiu",
        "id": 50287591,
        "node_id": "MDQ6VXNlcjUwMjg3NTkx",
        "avatar_url": "https://avatars.githubusercontent.com/u/50287591?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/NvTimLiu",
        "html_url": "https://github.com/NvTimLiu",
        "followers_url": "https://api.github.com/users/NvTimLiu/followers",
        "following_url": "https://api.github.com/users/NvTimLiu/following{/other_user}",
        "gists_url": "https://api.github.com/users/NvTimLiu/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/NvTimLiu/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/NvTimLiu/subscriptions",
        "organizations_url": "https://api.github.com/users/NvTimLiu/orgs",
        "repos_url": "https://api.github.com/users/NvTimLiu/repos",
        "events_url": "https://api.github.com/users/NvTimLiu/events{/privacy}",
        "received_events_url": "https://api.github.com/users/NvTimLiu/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": {
        "login": "binmahone",
        "id": 6416599,
        "node_id": "MDQ6VXNlcjY0MTY1OTk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6416599?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/binmahone",
        "html_url": "https://github.com/binmahone",
        "followers_url": "https://api.github.com/users/binmahone/followers",
        "following_url": "https://api.github.com/users/binmahone/following{/other_user}",
        "gists_url": "https://api.github.com/users/binmahone/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/binmahone/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/binmahone/subscriptions",
        "organizations_url": "https://api.github.com/users/binmahone/orgs",
        "repos_url": "https://api.github.com/users/binmahone/repos",
        "events_url": "https://api.github.com/users/binmahone/events{/privacy}",
        "received_events_url": "https://api.github.com/users/binmahone/received_events",
        "type": "User",
        "site_admin": false
    },
    "assignees": [
        {
            "login": "binmahone",
            "id": 6416599,
            "node_id": "MDQ6VXNlcjY0MTY1OTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6416599?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/binmahone",
            "html_url": "https://github.com/binmahone",
            "followers_url": "https://api.github.com/users/binmahone/followers",
            "following_url": "https://api.github.com/users/binmahone/following{/other_user}",
            "gists_url": "https://api.github.com/users/binmahone/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/binmahone/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/binmahone/subscriptions",
            "organizations_url": "https://api.github.com/users/binmahone/orgs",
            "repos_url": "https://api.github.com/users/binmahone/repos",
            "events_url": "https://api.github.com/users/binmahone/events{/privacy}",
            "received_events_url": "https://api.github.com/users/binmahone/received_events",
            "type": "User",
            "site_admin": false
        }
    ],
    "milestone": null,
    "comments": 15,
    "created_at": "2024-05-13T09:18:31Z",
    "updated_at": "2024-05-24T06:44:15Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\n\r\nUT tests failed on : The value '**' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed.\r\n\r\nNote: **Currently this issue only appeared on spark-rapids nightly build against `JDK17`;** \r\n\r\nNightly build UT against `JDK11` and `JDK8` have not reported these failures\r\n\r\n\r\n\r\n\r\n```\r\n- Cast from string to int using hand-picked values\r\n 24/05/12 01:41:36.590 Executor task launch worker for task 0.0 in stage 33.0 (TID 49) ERROR Executor: Exception in task 0.0 in stage 33.0 (TID 49)\r\n org.apache.spark.SparkNumberFormatException: The value '-.2' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. If necessary set \"spark.sql.ansi.enabled\" to \"false\" to bypass this error.\r\n        at org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:150) ~[spark-catalyst_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:46) ~[spark-catalyst_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toIntExact(UTF8StringUtils.scala:33) ~[spark-catalyst_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.sql.catalyst.util.UTF8StringUtils.toIntExact(UTF8StringUtils.scala) ~[spark-catalyst_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) ~[?:?]\r\n        at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) ~[spark-sql_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760) ~[spark-sql_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364) ~[spark-sql_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.rdd.RDD.iterator(RDD.scala:329) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:136) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]\r\n        at java.lang.Thread.run(Thread.java:840) ~[?:?]\r\n 24/05/12 01:41:36.607 task-result-getter-1 ERROR TaskSetManager: Task 0 in stage 33.0 failed 1 times; aborting job\r\n 24/05/12 01:41:36.608 Executor task launch worker for task 1.0 in stage 33.0 (TID 50) ERROR Executor: Exception in task 1.0 in stage 33.0 (TID 50)\r\n org.apache.spark.SparkNumberFormatException: The value '+1.2' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. If necessary set \"spark.sql.ansi.enabled\" to \"false\" to bypass this error.\r\n        at org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:150) ~[spark-catalyst_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:46) ~[spark-catalyst_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toIntExact(UTF8StringUtils.scala:33) ~[spark-catalyst_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.sql.catalyst.util.UTF8StringUtils.toIntExact(UTF8StringUtils.scala) ~[spark-catalyst_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) ~[?:?]\r\n        at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) ~[spark-sql_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760) ~[spark-sql_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364) ~[spark-sql_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.rdd.RDD.iterator(RDD.scala:329) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:136) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551) ~[spark-core_2.12-3.3.0.jar:3.3.0]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]\r\n        at java.lang.Thread.run(Thread.java:840) ~[?:?]\r\n\r\n```\r\n\r\n",
    "closed_by": {
        "login": "NvTimLiu",
        "id": 50287591,
        "node_id": "MDQ6VXNlcjUwMjg3NTkx",
        "avatar_url": "https://avatars.githubusercontent.com/u/50287591?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/NvTimLiu",
        "html_url": "https://github.com/NvTimLiu",
        "followers_url": "https://api.github.com/users/NvTimLiu/followers",
        "following_url": "https://api.github.com/users/NvTimLiu/following{/other_user}",
        "gists_url": "https://api.github.com/users/NvTimLiu/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/NvTimLiu/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/NvTimLiu/subscriptions",
        "organizations_url": "https://api.github.com/users/NvTimLiu/orgs",
        "repos_url": "https://api.github.com/users/NvTimLiu/repos",
        "events_url": "https://api.github.com/users/NvTimLiu/events{/privacy}",
        "received_events_url": "https://api.github.com/users/NvTimLiu/received_events",
        "type": "User",
        "site_admin": false
    },
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10801/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10801/timeline",
    "performed_via_github_app": null,
    "state_reason": "reopened"
}