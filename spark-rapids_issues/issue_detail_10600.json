{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10600",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10600/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10600/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10600/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10600",
    "id": 2188663580,
    "node_id": "I_kwDOD7z77c6CdFsc",
    "number": 10600,
    "title": "[FEA] Find ways to convert regular expressions into faster operations",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735884,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODg0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        },
        {
            "id": 2094500742,
            "node_id": "MDU6TGFiZWwyMDk0NTAwNzQy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/performance",
            "name": "performance",
            "color": "d845b1",
            "default": false,
            "description": "A performance related task/issue"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-03-15T14:32:04Z",
    "updated_at": "2024-04-25T19:01:32Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\nProcessing regular expressions on the GPU is really expensive compared to purpose built kernels. We already have done some work to avoid running a regular expression in some cases with StringSplit when the result would just be a regular string.\r\n\r\nhttps://github.com/NVIDIA/spark-rapids/pull/4854\r\n\r\nAnd similarly for RegexpReplace when it would just be a list of choices for replacement\r\n\r\nhttps://github.com/NVIDIA/spark-rapids/pull/7967\r\n\r\nI would like to see us do similar things for RLike.  Spark already optimizes LIKE so that if it sees `%FOO`, it is translated to an `ends_with`, `FOO%` to a `starts_with`, and `%FOO%` to a `contains`.\r\n\r\nI want to do the same kind of thing but using our regexp transpiler.\r\n\r\nWe might also want to have some simplification rules for RLIKE in the transpile to make it easier to find these situations instead of hard coding a list of them.\r\n\r\n * `FOO`, `.*FOO`, `FOO.*`, `^.*FOO`, `\\A.*FOO`, `^.*FOO.*$`, `\\A.*FOO.*\\Z` can be converted into `contains`\r\n * `^FOO`, `^FOO.*`, `\\AFOO`, `\\AFOO.*` can be be converted into `starts_with`\r\n * `FOO$`, `.*FOO$`, `FOO\\Z`, `.*FOO\\Z` can be be converted into `ends_with`\r\n\r\nNote that these are after capture groups have been removed/ignored, and `FOO` represents any pattern that can be converted into a static string, similar to what we do for `StringSplit` and `RegexpReplace`.  In fact the multi-match that regexp replace does should work for contains because we could use `find_multiple` and then check for any of the values in the array being >= 0 \r\n\r\nhttps://github.com/rapidsai/cudf/blob/610c022164b71614fb92366b3694df6d700283c8/cpp/include/cudf/strings/find_multiple.hpp#L57\r\n\r\nWe could also do a custom kernel if we see a need for it and want more speed.\r\n\r\nThere might be more, but a few of these we have see in real world queries and it would be good to try and speed these up. As in all things we should run some benchmarks to really see how much better the speedup is, and if it is worth the added complexity.  My guess is that it will always be a win, and for long strings it can be a huge win.\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10600/reactions",
        "total_count": 1,
        "+1": 1,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10600/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}