{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7744",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7744/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7744/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7744/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7744",
    "id": 1582521754,
    "node_id": "I_kwDOD7z77c5eU12a",
    "number": 7744,
    "title": "[BUG] UCX-EGX-Yarn test failed over too much host memory usage",
    "user": {
        "login": "abellina",
        "id": 1901059,
        "node_id": "MDQ6VXNlcjE5MDEwNTk=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1901059?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/abellina",
        "html_url": "https://github.com/abellina",
        "followers_url": "https://api.github.com/users/abellina/followers",
        "following_url": "https://api.github.com/users/abellina/following{/other_user}",
        "gists_url": "https://api.github.com/users/abellina/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/abellina/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/abellina/subscriptions",
        "organizations_url": "https://api.github.com/users/abellina/orgs",
        "repos_url": "https://api.github.com/users/abellina/repos",
        "events_url": "https://api.github.com/users/abellina/events{/privacy}",
        "received_events_url": "https://api.github.com/users/abellina/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 4029093938,
            "node_id": "LA_kwDOD7z77c7wJxgy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/reliability",
            "name": "reliability",
            "color": "2654AF",
            "default": false,
            "description": "Features to improve reliability or bugs that severly impact the reliability of the plugin"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2023-02-13T15:06:10Z",
    "updated_at": "2023-02-14T21:40:15Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "We have a test that runs under Yarn with UCX (UCX-EGX-Yarn) where we run ~100 tests from our CI. The following test failed once, and then succeeded the next two attempts. It hasn't failed before, not according to the history. This is with 23.02\r\n\r\n```\r\nFAILED integration_tests/src/main/python/udf_test.py::test_window_aggregate_udf[Lower_Upper-Integer][IGNORE_ORDER]\r\n```\r\n\r\nThis seems to indicate that either we are likely close to the overhead limit of 22GB. We set aside: 4GB for pinned memory, 1GB for the pageable pool (and didn't set `spark.rapids.memory.host.spillStorageSize` so our max on the host should be 5GB).\r\n\r\nNonetheless we are using more host memory than I anticipated here. I think it would be worth using this test to figure out what is all this host memory.\r\n\r\n```\r\n23/02/10 20:35:04 ERROR YarnClusterScheduler: Lost executor 1 on spark-egx-10.nvidia.com: Container killed by YARN for exceeding physical memory limits. 22.3 GB of 22 GB physical memory used. Consider boosting spark.executor.memoryOverhead.\r\n```\r\n\r\n\r\nThe error above causes fetch failures:\r\n\r\n```\r\n23/02/10 20:35:04 WARN TaskSetManager: Lost task 104.0 in stage 350.0 (TID 28281) (spark-egx-02.nvidia.com executor 2): FetchFailed(BlockManagerId(1, spark-egx-10.nvidia.com, 38899, Some(rapids=62688)), shuffleId=130, mapIndex=2, mapId=27963, reduceId=104, message=\r\norg.apache.spark.shuffle.rapids.RapidsShuffleFetchFailedException: Transfer error detected by shuffle iterator, failing task. Connection to 1 closed\r\n\tat com.nvidia.spark.rapids.shuffle.RapidsShuffleIterator.next(RapidsShuffleIterator.scala:378)\r\n\tat com.nvidia.spark.rapids.shuffle.RapidsShuffleIterator.next(RapidsShuffleIterator.scala:49)\r\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\r\n\tat scala.collection.Iterator$ConcatIterator.next(Iterator.scala:230)\r\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\r\n\tat org.apache.spark.InterruptibleIterator.next(InterruptibleIterator.scala:40)\r\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\r\n\tat com.nvidia.spark.rapids.CollectTimeIterator.$anonfun$next$1(GpuExec.scala:199)\r\n\tat com.nvidia.spark.rapids.Arm.withResource(Arm.scala:28)\r\n\tat com.nvidia.spark.rapids.Arm.withResource$(Arm.scala:26)\r\n\tat com.nvidia.spark.RebaseHelper$.withResource(RebaseHelper.scala:26)\r\n\tat com.nvidia.spark.rapids.CollectTimeIterator.next(GpuExec.scala:198)\r\n\tat com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.$anonfun$next$1(GpuCoalesceBatches.scala:385)\r\n\tat com.nvidia.spark.rapids.Arm.withResource(Arm.scala:28)\r\n\tat com.nvidia.spark.rapids.Arm.withResource$(Arm.scala:26)\r\n\tat com.nvidia.spark.rapids.AbstractGpuCoalesceIterator.withResource(GpuCoalesceBatches.scala:237)\r\n```\r\n\r\nWe also see this, but executor 2 didn't seem to get shot, so either that didn't get logged or it was coming, or something really bad happened. I am thinking that what we really want is a flag in the shuffle catalog that says \"we have been told to shutdown, so no buffers can be accessed\". This is going to be filed separately.\r\n\r\n```\r\n23/02/10 20:35:05 WARN TaskSetManager: Lost task 88.1 in stage 350.0 (TID 28288) (spark-egx-02.nvidia.com executor 2): java.util.NoSuchElementException: Cannot locate buffers associated with ID: ShuffleBufferId(shuffle_130_27962_88,1947246)\r\n\tat com.nvidia.spark.rapids.RapidsBufferCatalog.$anonfun$acquireBuffer$1(RapidsBufferCatalog.scala:232)\r\n\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\r\n\tat com.nvidia.spark.rapids.RapidsBufferCatalog.acquireBuffer(RapidsBufferCatalog.scala:229)\r\n\tat com.nvidia.spark.rapids.RapidsBufferCatalog.com$nvidia$spark$rapids$RapidsBufferCatalog$$updateUnderlyingRapidsBuffer(RapidsBufferCatalog.scala:210)\r\n\tat com.nvidia.spark.rapids.RapidsBufferCatalog$RapidsBufferHandleImpl.setSpillPriority(RapidsBufferCatalog.scala:77)\r\n\tat com.nvidia.spark.rapids.ShuffleBufferCatalog.updateSpillPriorityForLocalRead(ShuffleBufferCatalog.scala:289)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.$anonfun$read$5(RapidsCachingReader.scala:96)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.$anonfun$read$5$adapted(RapidsCachingReader.scala:96)\r\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\r\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\r\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.$anonfun$read$3(RapidsCachingReader.scala:96)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.$anonfun$read$3$adapted(RapidsCachingReader.scala:76)\r\n\tat scala.collection.immutable.List.foreach(List.scala:392)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.$anonfun$read$1(RapidsCachingReader.scala:76)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.$anonfun$read$1$adapted(RapidsCachingReader.scala:68)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\r\n\tat scala.collection.MapLike$DefaultKeySet.foreach(MapLike.scala:181)\r\n\tat org.apache.spark.sql.rapids.RapidsCachingReader.read(RapidsCachingReader.scala:68)\r\n\tat org.apache.spark.sql.rapids.execution.ShuffledBatchRDD.compute(ShuffledBatchRDD.scala:152)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7744/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7744/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}