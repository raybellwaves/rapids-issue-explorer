{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8878",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8878/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8878/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8878/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/8878",
    "id": 1829733883,
    "node_id": "I_kwDOD7z77c5tD4X7",
    "number": 8878,
    "title": "[FEA] clean up host memory limit configs",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2586576266,
            "node_id": "MDU6TGFiZWwyNTg2NTc2MjY2",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/task",
            "name": "task",
            "color": "65abf7",
            "default": false,
            "description": "Work required that improves the product but is not user facing"
        },
        {
            "id": 4029093938,
            "node_id": "LA_kwDOD7z77c7wJxgy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/reliability",
            "name": "reliability",
            "color": "2654AF",
            "default": false,
            "description": "Features to improve reliability or bugs that severly impact the reliability of the plugin"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-07-31T17:46:10Z",
    "updated_at": "2023-08-08T20:35:52Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nOnce the changes to the plugin are enough done that we feel that it should be turned on by default. \r\n   * We will set `spark.rapids.memory.hostOffHeapLimit.enabled` to true by default, and deprecate it. We will have a follow on issue to remove it once we have confidence that customers can move to this without a lot of problems. \r\n   * We will deprecate `spark.rapids.memory.host.spillStorageSize` and point people to `spark.rapids.memory.hostOffHeapLimit.size` instead. \r\n   * We will move `spark.rapids.memory.hostPageable.taskOverhead.size` from being an internal config to being an advanced config. \r\n   * We will write user facing docs about the remaining non-hidden configs\r\n   * We will add in a warning to the user if the configs appear to be set in a way that would make it very hard to run well. This would be something like if `spark.rapids.memory.hostOffHeapLimit.size` < 2 * `spark.rapids.memory.hostPageable.taskOverhead.size` * `numberOfTasks` OR `spark.rapids.memory.hostOffHeapLimit.size` < `spark.rapids.sql.batchSizeBytes` + `spark.sql.files.maxPartitionBytes` * some factor (but we can adjust this based off of testing we do).  The warning should be there to let them know that we are adjusting it to the new minimum value to avoid problems. We should also warn it the pinned pool is larger than the offHealLimit. For now we will adjust the pinned pool down to fit in the off heap limit. All of these should be documented.\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8878/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8878/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}