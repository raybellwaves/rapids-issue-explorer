{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/3114",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/3114/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/3114/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/3114/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/3114",
    "id": 958665137,
    "node_id": "MDU6SXNzdWU5NTg2NjUxMzc=",
    "number": 3114,
    "title": "[BUG] integration tests pyspark log4j logging is not configured properly",
    "user": {
        "login": "gerashegalov",
        "id": 3187938,
        "node_id": "MDQ6VXNlcjMxODc5Mzg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3187938?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gerashegalov",
        "html_url": "https://github.com/gerashegalov",
        "followers_url": "https://api.github.com/users/gerashegalov/followers",
        "following_url": "https://api.github.com/users/gerashegalov/following{/other_user}",
        "gists_url": "https://api.github.com/users/gerashegalov/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/gerashegalov/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/gerashegalov/subscriptions",
        "organizations_url": "https://api.github.com/users/gerashegalov/orgs",
        "repos_url": "https://api.github.com/users/gerashegalov/repos",
        "events_url": "https://api.github.com/users/gerashegalov/events{/privacy}",
        "received_events_url": "https://api.github.com/users/gerashegalov/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 2094874947,
            "node_id": "MDU6TGFiZWwyMDk0ODc0OTQ3",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/test",
            "name": "test",
            "color": "60d6d4",
            "default": false,
            "description": "Only impacts tests"
        },
        {
            "id": 2223784776,
            "node_id": "MDU6TGFiZWwyMjIzNzg0Nzc2",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/P1",
            "name": "P1",
            "color": "fbca04",
            "default": false,
            "description": "Nice to have for release"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2021-08-03T02:46:36Z",
    "updated_at": "2021-08-03T20:22:42Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\n1. In the non-xdist mode (`TEST_PARALLEL < 3`)  the test jar with [log4j.properties](https://github.com/NVIDIA/spark-rapids/blob/e303d2d7dc0b371a6c5525b555e91ac22325adb8/integration_tests/src/test/resources/log4j.properties) is added to the client mode driver via `--jars` which is too late for log4j configuration to happen. Therefore we need `--driver-class-path \"$PYSP_TEST_spark_driver_extraClassPath\"` at \r\nhttps://github.com/NVIDIA/spark-rapids/blob/e303d2d7dc0b371a6c5525b555e91ac22325adb8/integration_tests/run_pyspark_from_build.sh#L169  or   `-Dlog4j.configuration` in `--driver-java-options`. Currently there is no driver JVM output \r\n\r\n1.  in the xdist mode, we need to generate log4j properties for each worker with distinct log filenames containing worker id to avoid the log being overwritten, since no variable substitution is available in log4j 1. 2 Spark is using.\r\n\r\n1. when run in the psuedo-distributed `local-cluster` (NUM_LOCAL_EXECS > 0) mode, Executors end up creating unnecessary intermediate directories `target/surefire-reports/` under the executor log directory",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/3114/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/3114/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}