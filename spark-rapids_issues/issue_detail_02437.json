{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/2437",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/2437/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/2437/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/2437/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/2437",
    "id": 894526346,
    "node_id": "MDU6SXNzdWU4OTQ1MjYzNDY=",
    "number": 2437,
    "title": "[FEA] CBO cost models should be more accurate for columnar file scans",
    "user": {
        "login": "andygrove",
        "id": 934084,
        "node_id": "MDQ6VXNlcjkzNDA4NA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/934084?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/andygrove",
        "html_url": "https://github.com/andygrove",
        "followers_url": "https://api.github.com/users/andygrove/followers",
        "following_url": "https://api.github.com/users/andygrove/following{/other_user}",
        "gists_url": "https://api.github.com/users/andygrove/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/andygrove/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/andygrove/subscriptions",
        "organizations_url": "https://api.github.com/users/andygrove/orgs",
        "repos_url": "https://api.github.com/users/andygrove/repos",
        "events_url": "https://api.github.com/users/andygrove/events{/privacy}",
        "received_events_url": "https://api.github.com/users/andygrove/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735884,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODg0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        },
        {
            "id": 2094500742,
            "node_id": "MDU6TGFiZWwyMDk0NTAwNzQy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/performance",
            "name": "performance",
            "color": "d845b1",
            "default": false,
            "description": "A performance related task/issue"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2021-05-18T15:49:24Z",
    "updated_at": "2021-05-19T21:47:22Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\nPR https://github.com/NVIDIA/spark-rapids/pull/2397 introduces memory access costs for evaluating expressions and for performing transitions between CPU and GPU. However, this does not take into account the cost of converting CPU columnar batches to GPU when scanning columnar files (Parquet and Orc).\r\n\r\n**Describe the solution you'd like**\r\nThe CPU and GPU cost models should include costs based on the file schema and columns being read. We should also include the cost of reading the data from disk.\r\n\r\n**Describe alternatives you've considered**\r\nNone\r\n\r\n**Additional context**\r\nNone\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/2437/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/2437/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}