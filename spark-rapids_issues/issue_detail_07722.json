{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7722",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7722/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7722/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7722/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7722",
    "id": 1578433715,
    "node_id": "I_kwDOD7z77c5eFPyz",
    "number": 7722,
    "title": "[BUG] Databricks 11.3 Executor Broadcast throws exception when UCX shuffle is enabled",
    "user": {
        "login": "NVnavkumar",
        "id": 97137715,
        "node_id": "U_kgDOBco0Mw",
        "avatar_url": "https://avatars.githubusercontent.com/u/97137715?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/NVnavkumar",
        "html_url": "https://github.com/NVnavkumar",
        "followers_url": "https://api.github.com/users/NVnavkumar/followers",
        "following_url": "https://api.github.com/users/NVnavkumar/following{/other_user}",
        "gists_url": "https://api.github.com/users/NVnavkumar/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/NVnavkumar/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/NVnavkumar/subscriptions",
        "organizations_url": "https://api.github.com/users/NVnavkumar/orgs",
        "repos_url": "https://api.github.com/users/NVnavkumar/repos",
        "events_url": "https://api.github.com/users/NVnavkumar/events{/privacy}",
        "received_events_url": "https://api.github.com/users/NVnavkumar/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-02-09T19:01:08Z",
    "updated_at": "2023-02-14T21:18:30Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nWhen enabling the RAPIDS Shuffle Manager with UCX mode, we get a ClassCastException:\r\n\r\n```\r\n...\r\nCaused by: java.lang.ClassCastException: com.nvidia.spark.rapids.GpuColumnVectorFromBuffer cannot be cast to com.nvidia.spark.rapids.SerializedTableColumn\r\n\tat com.nvidia.spark.rapids.HostShuffleCoalesceIterator.$anonfun$bufferNextBatch$1(GpuShuffleCoalesceExec.scala:145)\r\n\tat com.nvidia.spark.rapids.HostShuffleCoalesceIterator.$anonfun$bufferNextBatch$1$adapted(GpuShuffleCoalesceExec.scala:140)\r\n\tat com.nvidia.spark.rapids.Arm.closeOnExcept(Arm.scala:87)\r\n\tat com.nvidia.spark.rapids.Arm.closeOnExcept$(Arm.scala:85)\r\n\tat com.nvidia.spark.rapids.HostShuffleCoalesceIterator.closeOnExcept(GpuShuffleCoalesceExec.scala:80)\r\n\tat com.nvidia.spark.rapids.HostShuffleCoalesceIterator.bufferNextBatch(GpuShuffleCoalesceExec.scala:140)\r\n\tat com.nvidia.spark.rapids.HostShuffleCoalesceIterator.hasNext(GpuShuffleCoalesceExec.scala:163)\r\n\tat com.nvidia.spark.rapids.GpuShuffleCoalesceIterator.hasNext(GpuShuffleCoalesceExec.scala:200)\r\n\tat com.nvidia.spark.rapids.ConcatAndConsumeAll$.getSingleBatchWithVerification(GpuCoalesceBatches.scala:93)\r\n\tat org.apache.spark.sql.rapids.execution.GpuExecutorBroadcastHelper$.getExecutorBroadcastBatch(GpuExecutorBroadcastHelper.scala:94)\r\n\tat org.apache.spark.sql.rapids.execution.GpuBroadcastHashJoinExec.$anonfun$getExecutorBuiltBatchAndStreamIter$1(GpuBroadcastHashJoinExec.scala:143)\r\n...\r\n```\r\n\r\n**Steps/Code to reproduce bug**\r\n\r\nReproduce case using Scala Notebook:\r\n\r\n```\r\nspark.conf.set(\"spark.rapids.sql.enabled\", true)\r\nspark.conf.set(\"spark.sql.adaptive.enabled\", true)\r\nspark.conf.set(\"spark.sql.optimizer.dynamicPartitionPruning.enabled\", true)\r\nspark.conf.set(\"spark.databricks.delta.optimizeWrite.enabled\", false)\r\n\r\n\r\n\r\nimport org.apache.spark.sql.functions.col\r\n\r\n\r\nspark.range(1000).select(col(\"id\"), col(\"id\").as(\"k\")).write.partitionBy(\"k\").format(\"parquet\").mode(\"overwrite\").save(\"/navink/tmp/myfact\")\r\nspark.range(100).select(col(\"id\"), col(\"id\").as(\"k\")).write.format(\"parquet\").mode(\"overwrite\").save(\"/navink/tmp/mydim\")\r\nspark.read.parquet(\"/navink/tmp/myfact\").createOrReplaceTempView(\"fact\")\r\nspark.read.parquet(\"/navink/tmp/mydim\").createOrReplaceTempView(\"dim\")\r\nval df = spark.sql(\"SELECT fact.id, fact.k FROM fact JOIN dim ON fact.k = dim.k AND dim.id < 2\")\r\ndf.collect()\r\n\r\n```\r\n\r\n**Expected behavior**\r\nThe query should execute normally.\r\n\r\n\r\n**Environment details (please complete the following information)**\r\n - Environment location: Databricks 11.3\r\n\r\n**Additional context**\r\n- See https://github.com/NVIDIA/spark-rapids/issues/7599 for cleanup related task for handling executor broadcast columnar batch\r\n- Note the AQE edge case where an non-replaced CPU join must consume a reused GPU exchange. In that case, an extra CPU ShuffleExchangeExec is inserted for the Databricks join code to consume what it expects as an executor broadcast.\r\n   - See https://github.com/NVIDIA/spark-rapids/blob/f1829eb327a5cf4afcaaf5609837ac05f655c4d6/sql-plugin/src/main/330db/scala/com/nvidia/spark/rapids/shims/SparkShims.scala#L89 and https://github.com/NVIDIA/spark-rapids/blob/f1829eb327a5cf4afcaaf5609837ac05f655c4d6/sql-plugin/src/main/scala/com/nvidia/spark/rapids/GpuTransitionOverrides.scala#L172\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7722/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7722/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}