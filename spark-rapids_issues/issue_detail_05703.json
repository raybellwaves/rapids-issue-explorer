{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5703",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5703/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5703/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5703/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/5703",
    "id": 1254589801,
    "node_id": "I_kwDOD7z77c5Kx4Vp",
    "number": 5703,
    "title": "[BUG] Create a nightly CI test pipeline for force.caller.classloader=false",
    "user": {
        "login": "gerashegalov",
        "id": 3187938,
        "node_id": "MDQ6VXNlcjMxODc5Mzg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3187938?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gerashegalov",
        "html_url": "https://github.com/gerashegalov",
        "followers_url": "https://api.github.com/users/gerashegalov/followers",
        "following_url": "https://api.github.com/users/gerashegalov/following{/other_user}",
        "gists_url": "https://api.github.com/users/gerashegalov/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/gerashegalov/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/gerashegalov/subscriptions",
        "organizations_url": "https://api.github.com/users/gerashegalov/orgs",
        "repos_url": "https://api.github.com/users/gerashegalov/repos",
        "events_url": "https://api.github.com/users/gerashegalov/events{/privacy}",
        "received_events_url": "https://api.github.com/users/gerashegalov/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 4029093938,
            "node_id": "LA_kwDOD7z77c7wJxgy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/reliability",
            "name": "reliability",
            "color": "2654AF",
            "default": false,
            "description": "Features to improve reliability or bugs that severly impact the reliability of the plugin"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 4,
    "created_at": "2022-06-01T00:59:45Z",
    "updated_at": "2022-06-17T19:20:22Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nAt a handful occasions we needed to resort to setting `spark.rapids.force.caller.classloader` to the non-default value `false` as a workaround for bugs. However, we only have a smoke test enabled for this configuration. Without a full test pipeline run against this config we ended up incurring a few regressions over time.\r\n\r\n**Steps/Code to reproduce bug**\r\nManually run pytest-xdist with pseudo-distributed standalone local-cluster via:\r\n```bash\r\nTEST_PARALLEL=2 \\\r\n  PYSP_TEST_spark_rapids_force_caller_classloader=false \\\r\n  NUM_LOCAL_EXECS=2 \\\r\n  ./integration_tests/run_pyspark_from_build.sh -k test_explain_set_config\r\n```\r\nand observe failures like:\r\n```\r\npy4j.protocol.Py4JJavaError: An error occurred while calling z:com.nvidia.spark.rapids.ExplainPlan.explainPotentialGpuPlan.\r\n  : java.lang.NoClassDefFoundError: com/nvidia/spark/rapids/GpuOverrides$\r\n```\r\n<details><description>full stacktrace</description>\r\n<pre>\r\nE                       at com.nvidia.spark.rapids.ExplainPlanImpl.explainPotentialGpuPlan(GpuOverrides.scala:4196)\r\nE                       at com.nvidia.spark.rapids.ExplainPlan$.explainPotentialGpuPlan(ExplainPlan.scala:65)\r\nE                       at com.nvidia.spark.rapids.ExplainPlan.explainPotentialGpuPlan(ExplainPlan.scala)\r\nE                       at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\nE                       at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\nE                       at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\nE                       at java.lang.reflect.Method.invoke(Method.java:498)\r\nE                       at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\nE                       at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\nE                       at py4j.Gateway.invoke(Gateway.java:282)\r\nE                       at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\nE                       at py4j.commands.CallCommand.execute(CallCommand.java:79)\r\nE                       at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\nE                       at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\nE                       at java.lang.Thread.run(Thread.java:748)\r\nE                   Caused by: java.lang.ClassNotFoundException: com.nvidia.spark.rapids.GpuOverrides$\r\nE                       at java.net.URLClassLoader.findClass(URLClassLoader.java:387)\r\nE                       at java.lang.ClassLoader.loadClass(ClassLoader.java:418)\r\nE                       at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)\r\nE                       at java.lang.ClassLoader.loadClass(ClassLoader.java:351)\r\nE                       ... 15 more\r\n</pre>\r\n</details>\r\n\r\n**Expected behavior**\r\nWe should not have exceptions with supported options. Unfortunately, this is one of the options that can't be solved via test parametrization because this needs to be applied before pytest Spark app is launched. More generally it may be an epic to identify more pre-pytest-launch settings like this. \r\n\r\n**Environment details (please complete the following information)**\r\nlocal-cluster, Standalone cluster anywhere\r\n\r\n**Additional context**\r\n#5646 \r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5703/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5703/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}