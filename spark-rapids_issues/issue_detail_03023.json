{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/3023",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/3023/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/3023/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/3023/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/3023",
    "id": 953239275,
    "node_id": "MDU6SXNzdWU5NTMyMzkyNzU=",
    "number": 3023,
    "title": "[FEA] Special case window optimizations",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735884,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODg0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        },
        {
            "id": 2094500742,
            "node_id": "MDU6TGFiZWwyMDk0NTAwNzQy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/performance",
            "name": "performance",
            "color": "d845b1",
            "default": false,
            "description": "A performance related task/issue"
        },
        {
            "id": 2223784867,
            "node_id": "MDU6TGFiZWwyMjIzNzg0ODY3",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/P2",
            "name": "P2",
            "color": "8ff7b9",
            "default": false,
            "description": "Not required for release"
        },
        {
            "id": 2710265788,
            "node_id": "MDU6TGFiZWwyNzEwMjY1Nzg4",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/cudf_dependency",
            "name": "cudf_dependency",
            "color": "7400FF",
            "default": false,
            "description": "An issue or PR with this label depends on a new feature in cudf"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2021-07-26T20:00:10Z",
    "updated_at": "2022-09-13T18:10:07Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "Spark supports a number of window performance optimizations as described in https://github.com/NVIDIA/spark-rapids/pull/3022. It would be good for us to try and figure out how to do these same types of optimizations.\r\n\r\n   \r\n\r\n- [ ] https://github.com/NVIDIA/spark-rapids/issues/ Unbounded Preceding to Unbounded Following. For this case we could do a sorted group by aggregation along with a count and then call `repeat` to produce the final result. (not sure how often this actually shows up in practice outside of percent rank)\r\n- [ ] Unbounded Preceding to Specific bound.  \r\n  - [ ] Row based windows: For running windows cudf asked us to use scan and group by scan. I think we can make this work by doing a scan followed by a lag. I am not sure what kind of performance hit we might get from doing this. \r\n  - [ ] For range based queries we are going to need changes to cudf.\r\n- [ ] Specific bound to Unbounded following.  Would it be better to reverse the sort order and switch following and preceding? Possibly? It would potentially insert in more sorts, but if all of the aggregations follow this pattern we could get away with a no extra sorting and reduced total memory usage.  Otherwise there really is no extra performance improvement to be made for this.\r\n\r\nIt would also be good to spend some time profiling to see if there are other optimizations that can be made to the internal code.\r\n\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/3023/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/3023/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}