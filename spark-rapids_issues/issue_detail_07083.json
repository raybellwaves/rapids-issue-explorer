{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7083",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7083/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7083/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7083/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7083",
    "id": 1451893276,
    "node_id": "I_kwDOD7z77c5WiiIc",
    "number": 7083,
    "title": "[FEA] Explore COMPLETE hash aggregations",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735884,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODg0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        },
        {
            "id": 2094500742,
            "node_id": "MDU6TGFiZWwyMDk0NTAwNzQy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/performance",
            "name": "performance",
            "color": "d845b1",
            "default": false,
            "description": "A performance related task/issue"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2022-11-16T16:20:14Z",
    "updated_at": "2022-11-16T22:12:19Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\nOpen source spark has 4 different modes for hash aggregates.  `Partial`, `PartialMerge`, `Final`, and `Complete`. Each of these has different meanings. In general what we see is an aggregation with a `Partial` mode followed by a shuffle and then an aggregation with a `Final` mode. to complete a fully distributed hash aggregation.  `Complete` is intended to mean do the entire aggregation in one go. There is no shuffle in between.  But in most versions of Spark if you try to do a hash aggregate the rules will split that hash aggregate into a `Partial` and a `Final` stage, and then rely on other plan optimization rules to insert in the shuffle as needed.  In a few rare cases that shuffle is not needed, because the data is already partitioned correctly and there is no need for a shuffle.  When this happens we still end up doing two hash aggregates. It is never optimized back to a single `Complete` aggregation, which could save on a lot of computation.  Databricks already does this and because of it we have to support `Complete` mode in our hash aggregate. I would really like to see if we can implement a simple rule that would let also support this same thing.\r\n\r\nFor example.\r\n\r\n```\r\ndf.groupBy(\"day\", \"hour\").agg(sum(\"money\")).groupBy(\"day\").agg(average(\"money\").alias(\"average_hourly_revenue\"))\r\n``` \r\n\r\nis one case where this type of thing would happen.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7083/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7083/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}