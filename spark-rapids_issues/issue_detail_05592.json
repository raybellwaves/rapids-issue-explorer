{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5592",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5592/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5592/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5592/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/5592",
    "id": 1245465527,
    "node_id": "I_kwDOD7z77c5KPEu3",
    "number": 5592,
    "title": "[FEA] Refactor Input Format Reading for Coalesing, PerFile, and Multithreaded",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2586576266,
            "node_id": "MDU6TGFiZWwyNTg2NTc2MjY2",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/task",
            "name": "task",
            "color": "65abf7",
            "default": false,
            "description": "Work required that improves the product but is not user facing"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2022-05-23T17:02:39Z",
    "updated_at": "2022-05-24T20:49:21Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "After looking at the Parquet code in particular it is clear that we can and should refactor how this code works to make it smaller, more common, and cleaner.  This should help with future work to support things like iceburg. I don't have all of the details about this but generally for Parquet, ORC and avro there are a few steps that happen. The difference between per file, Multithreaded, and coalescing is what thread these things take place on, and in a few cases if a step happens.  The general outline of these steps is below. \r\n\r\n1. Read footer/metadata and determine what parts should be read.  For Parquet and Orc this is filtering the RowGroup(s)/Stripe(s) from the partition, column pruning and predicate push down. For Avro it is really just determining the range of data to read and getting the read schema for the file.\r\n2. Coalesce/Split data into appropriately sized buffers for reading. This essentially boils down into taking the output of the first step and trying to combine independent RowGroups, Stripes, or Avro buffers together so that can be read on the GPU without crashing and as efficiently as possible. Combining between files may be disabled for a number of reasons.\r\n3. Take the output of the second step and read the actual data into a host memory buffer. To make CUDF happy we often need to turn this into an actual file including serialized footers and headers too.\r\n4. Take the host memory buffer from the third step and have the GPU convert it into a Table to be processed.\r\n5. Check/fix up the table returned by Step 4 to do schema evolution on it or what ever else we need to do to make it match what Spark expects.\r\n\r\nFor PerFile all of the steps happen in the main task thread for one file at a time, no coalescing, but the files may be split to be smaller.\r\nFor  MultiThreaded steps 1 to 3 happen on a background thread pool. There is no coalescing, but the files may be split to be smaller. This is just like PerFile. Steps 4 and 5 happen on the main task thread. They are connected by a queue of `Future`s to keep the order of the rows the same.\r\nFor Coalescing Steps 1 and 2 happen on the main task thread at the beginning of execution to build up a list of operations to do. Step 3 happens on a background thread pool, and steps 4 and 5 happen on the main task thread again.\r\n\r\nAt a minimum we should have the core parts of all of the steps made into static functions that can be shared between each of the different implementations that control where each step executes. Ideally it would be nice to combine as much of the control/glue code as well so we can just pick which steps execute on a background thread pool, and which ones do not, but that may get to be rather complicated.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5592/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5592/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}