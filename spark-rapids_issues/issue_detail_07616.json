{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7616",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7616/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7616/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7616/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7616",
    "id": 1561646145,
    "node_id": "I_kwDOD7z77c5dFNRB",
    "number": 7616,
    "title": "[BUG] GPU JSON reader fails to read the JSON string of an empty body ",
    "user": {
        "login": "firestarman",
        "id": 7280411,
        "node_id": "MDQ6VXNlcjcyODA0MTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7280411?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/firestarman",
        "html_url": "https://github.com/firestarman",
        "followers_url": "https://api.github.com/users/firestarman/followers",
        "following_url": "https://api.github.com/users/firestarman/following{/other_user}",
        "gists_url": "https://api.github.com/users/firestarman/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/firestarman/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/firestarman/subscriptions",
        "organizations_url": "https://api.github.com/users/firestarman/orgs",
        "repos_url": "https://api.github.com/users/firestarman/repos",
        "events_url": "https://api.github.com/users/firestarman/events{/privacy}",
        "received_events_url": "https://api.github.com/users/firestarman/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 5,
    "created_at": "2023-01-30T02:51:26Z",
    "updated_at": "2024-03-15T01:25:01Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nGPU JSON reader can not read the JSON string of an empty body `{}`. But Spark can read it successfully.\r\n\r\n**Steps/Code to reproduce bug**\r\nThere are two sub cases, and GPU read will fail due to different errors.\r\n\r\n```\r\n$ cat no-body.json \r\n{}\r\n```\r\n1) Read without specifying a schema.\r\n\r\n```\r\nscala> spark.read.json(\"/data/tmp/no-body.json\").show\r\n++\r\n||\r\n++\r\n||\r\n++\r\n\r\nscala> spark.read.json(\"/data/tmp/no-body.json\").show\r\n\r\n23/01/30 02:37:39 WARN GpuOverrides: \r\n!Exec <CollectLimitExec> cannot run on GPU because the Exec CollectLimitExec has been disabled, and is disabled by default because Collect Limit replacement can be slower on the GPU, if huge number of rows in a batch it could help by limiting the number of rows transferred from GPU to CPU. Set spark.rapids.sql.exec.CollectLimitExec to true if you wish to enable it\r\n  @Partitioning <SinglePartition$> could run on GPU\r\n  *Exec <FileSourceScanExec> will run on GPU\r\n\r\n23/01/30 02:37:39 ERROR Executor: Exception in task 0.0 in stage 9.0 (TID 9)\r\njava.lang.UnsupportedOperationException: empty.min\r\n\tat scala.collection.TraversableOnce.min(TraversableOnce.scala:227)\r\n\tat scala.collection.TraversableOnce.min$(TraversableOnce.scala:225)\r\n\tat org.apache.spark.sql.types.StructType.min(StructType.scala:102)\r\n\tat com.nvidia.spark.rapids.GpuTextBasedPartitionReader.readToTable(GpuTextBasedPartitionReader.scala:299)\r\n......\r\n```\r\n2) Read with a specified schema\r\n```\r\nscala> spark.read.schema(\"a int\").json(\"/data/tmp/no-body.json\").show\r\n+----+\r\n|   a|\r\n+----+\r\n|null|\r\n+----+\r\n\r\nscala> spark.read.schema(\"a int\").json(\"/data/tmp/no-body.json\").show\r\n23/01/30 02:40:04 WARN GpuOverrides: \r\n!Exec <CollectLimitExec> cannot run on GPU because the Exec CollectLimitExec has been disabled, and is disabled by default because Collect Limit replacement can be slower on the GPU, if huge number of rows in a batch it could help by limiting the number of rows transferred from GPU to CPU. Set spark.rapids.sql.exec.CollectLimitExec to true if you wish to enable it\r\n  @Partitioning <SinglePartition$> could run on GPU\r\n  *Exec <ProjectExec> will run on GPU\r\n    *Expression <Alias> cast(a#46 as string) AS a#49 will run on GPU\r\n      *Expression <Cast> cast(a#46 as string) will run on GPU\r\n    *Exec <FileSourceScanExec> will run on GPU\r\n\r\n23/01/30 02:40:04 ERROR Executor: Exception in task 0.0 in stage 10.0 (TID 10)\r\njava.io.IOException: Error when processing file [path: file:///data/tmp/no-body.json, range: 0-3, partition values: [empty row]]\r\n\tat org.apache.spark.sql.catalyst.json.rapids.JsonPartitionReader.$anonfun$readToTable$1(GpuJsonScan.scala:290)\r\n......\r\nCaused by: ai.rapids.cudf.CudfException: CUDF failure at: /home/jenkins/agent/workspace/jenkins-spark-rapids-jni_nightly-pre_release-106-cuda11/thirdparty/cudf/cpp/src/io/json/reader_impl.cu:639: Error determining column names.\r\n\r\n\tat ai.rapids.cudf.Table.readJSON(Native Method)\r\n\tat ai.rapids.cudf.Table.readJSON(Table.java:1049)\r\n\tat org.apache.spark.sql.catalyst.json.rapids.JsonPartitionReader.$anonfun$readToTable$1(GpuJsonScan.scala:287)\r\n```\r\n\r\n**Expected behavior**\r\nGPU JSON reader should handle it as what Spark does.\r\n\r\n**Additional context**\r\ncudf Python has fixed the second sub issue by [switching the JSON engine to the new reader](https://github.com/rapidsai/cudf/pull/12509), so JNI should also make the same switch [when creating the read option](https://github.com/rapidsai/cudf/blob/branch-23.02/java/src/main/native/src/TableJni.cpp#L1445).\r\nWe need to test it well to make sure no regression will be introduced by this new JSON reader.\r\n\r\nAfter fixing this, we need to enable the tests xfailed in https://github.com/NVIDIA/spark-rapids/pull/7447.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7616/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7616/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}