{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8053",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8053/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8053/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8053/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/8053",
    "id": 1658020389,
    "node_id": "I_kwDOD7z77c5i02Il",
    "number": 8053,
    "title": "Implement Split on Retry for GpuHashPartitioning",
    "user": {
        "login": "tgravescs",
        "id": 4563792,
        "node_id": "MDQ6VXNlcjQ1NjM3OTI=",
        "avatar_url": "https://avatars.githubusercontent.com/u/4563792?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/tgravescs",
        "html_url": "https://github.com/tgravescs",
        "followers_url": "https://api.github.com/users/tgravescs/followers",
        "following_url": "https://api.github.com/users/tgravescs/following{/other_user}",
        "gists_url": "https://api.github.com/users/tgravescs/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/tgravescs/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/tgravescs/subscriptions",
        "organizations_url": "https://api.github.com/users/tgravescs/orgs",
        "repos_url": "https://api.github.com/users/tgravescs/repos",
        "events_url": "https://api.github.com/users/tgravescs/events{/privacy}",
        "received_events_url": "https://api.github.com/users/tgravescs/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735884,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODg0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [
        {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        }
    ],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-04-06T20:41:00Z",
    "updated_at": "2023-04-12T20:15:37Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\nRan into a customer job that had failed tasks that said:\r\n\r\n`com.nvidia.spark.rapids.jni.SplitAndRetryOOM: task should split input and retry operation`\r\n\r\nThis task was spilling data and was doing a regexp extract within a hashpartitioning. There is a PR up to handle retry on this but not one to handle trying to split the data.  It may be nice to handle that. In this case customer job will be configured so that its more performant so not sure priority on it.  Stack trace for this was:\r\n\r\n```\r\ncom.nvidia.spark.rapids.jni.SplitAndRetryOOM: task should split input and retry operation\r\n\tat ai.rapids.cudf.ColumnView.extractRe(Native Method)\r\n\tat ai.rapids.cudf.ColumnView.extractRe(ColumnView.java:3431)\r\n\tat org.apache.spark.sql.rapids.GpuRegExpExtract.doColumnar(stringFunctions.scala:1375)\r\n\tat com.nvidia.spark.rapids.GpuTernaryExpression.$anonfun$columnarEval$8(GpuExpressions.scala:415)\r\n\tat com.nvidia.spark.rapids.Arm.withResourceIfAllowed(Arm.scala:73)\r\n\tat com.nvidia.spark.rapids.Arm.withResourceIfAllowed$(Arm.scala:71)\r\n\tat org.apache.spark.sql.rapids.GpuRegExpTernaryBase.withResourceIfAllowed(stringFunctions.scala:1116)\r\n\tat com.nvidia.spark.rapids.GpuTernaryExpression.$anonfun$columnarEval$7(GpuExpressions.scala:400)\r\n\tat com.nvidia.spark.rapids.Arm.withResourceIfAllowed(Arm.scala:73)\r\n\tat com.nvidia.spark.rapids.Arm.withResourceIfAllowed$(Arm.scala:71)\r\n\tat org.apache.spark.sql.rapids.GpuRegExpTernaryBase.withResourceIfAllowed(stringFunctions.scala:1116)\r\n\tat com.nvidia.spark.rapids.GpuTernaryExpression.$anonfun$columnarEval$6(GpuExpressions.scala:399)\r\n\tat com.nvidia.spark.rapids.Arm.withResourceIfAllowed(Arm.scala:73)\r\n\tat com.nvidia.spark.rapids.Arm.withResourceIfAllowed$(Arm.scala:71)\r\n\tat org.apache.spark.sql.rapids.GpuRegExpTernaryBase.withResourceIfAllowed(stringFunctions.scala:1116)\r\n\tat com.nvidia.spark.rapids.GpuTernaryExpression.columnarEval(GpuExpressions.scala:398)\r\n\tat com.nvidia.spark.rapids.GpuTernaryExpression.columnarEval$(GpuExpressions.scala:396)\r\n\tat org.apache.spark.sql.rapids.GpuRegExpTernaryBase.columnarEval(stringFunctions.scala:1116)\r\n\tat com.nvidia.spark.rapids.RapidsPluginImplicits$ReallyAGpuExpression.columnarEval(implicits.scala:34)\r\n\tat com.nvidia.spark.rapids.GpuConditionalExpression.$anonfun$computeIfElse$2(conditionalExpressions.scala:159)\r\n\tat com.nvidia.spark.rapids.Arm.withResource(Arm.scala:28)\r\n\tat com.nvidia.spark.rapids.Arm.withResource$(Arm.scala:26)\r\n\tat com.nvidia.spark.rapids.GpuCaseWhen.withResource(conditionalExpressions.scala:314)\r\n\tat com.nvidia.spark.rapids.GpuConditionalExpression.$anonfun$computeIfElse$1(conditionalExpressions.scala:158)\r\n\tat com.nvidia.spark.rapids.Arm.withResourceIfAllowed(Arm.scala:73)\r\n\tat com.nvidia.spark.rapids.Arm.withResourceIfAllowed$(Arm.scala:71)\r\n\tat com.nvidia.spark.rapids.GpuCaseWhen.withResourceIfAllowed(conditionalExpressions.scala:314)\r\n\tat com.nvidia.spark.rapids.GpuConditionalExpression.computeIfElse(conditionalExpressions.scala:157)\r\n\tat com.nvidia.spark.rapids.GpuConditionalExpression.computeIfElse$(conditionalExpressions.scala:152)\r\n\tat com.nvidia.spark.rapids.GpuCaseWhen.computeIfElse(conditionalExpressions.scala:314)\r\n\tat com.nvidia.spark.rapids.GpuCaseWhen.$anonfun$columnarEval$6(conditionalExpressions.scala:367)\r\n\tat scala.collection.IndexedSeqOptimized.foldRight(IndexedSeqOptimized.scala:65)\r\n\tat scala.collection.IndexedSeqOptimized.foldRight$(IndexedSeqOptimized.scala:72)\r\n\tat scala.collection.mutable.ArrayBuffer.foldRight(ArrayBuffer.scala:49)\r\n\tat com.nvidia.spark.rapids.GpuCaseWhen.columnarEval(conditionalExpressions.scala:365)\r\n\tat com.nvidia.spark.rapids.RapidsPluginImplicits$ReallyAGpuExpression.columnarEval(implicits.scala:34)\r\n\tat com.nvidia.spark.rapids.GpuExpressionsUtils$.columnarEvalToColumn(GpuExpressions.scala:94)\r\n\tat com.nvidia.spark.rapids.GpuUnaryExpression.columnarEval(GpuExpressions.scala:203)\r\n\tat com.nvidia.spark.rapids.RapidsPluginImplicits$ReallyAGpuExpression.columnarEval(implicits.scala:34)\r\n\tat com.nvidia.spark.rapids.GpuExpressionsUtils$.columnarEvalToColumn(GpuExpressions.scala:94)\r\n\tat com.nvidia.spark.rapids.GpuProjectExec$.projectSingle(basicPhysicalOperators.scala:102)\r\n\tat com.nvidia.spark.rapids.GpuProjectExec$.$anonfun$project$1(basicPhysicalOperators.scala:109)\r\n\tat com.nvidia.spark.rapids.RapidsPluginImplicits$MapsSafely.$anonfun$safeMap$1(implicits.scala:216)\r\n\tat com.nvidia.spark.rapids.RapidsPluginImplicits$MapsSafely.$anonfun$safeMap$1$adapted(implicits.scala:213)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat com.nvidia.spark.rapids.RapidsPluginImplicits$MapsSafely.safeMap(implicits.scala:213)\r\n\tat com.nvidia.spark.rapids.RapidsPluginImplicits$AutoCloseableProducingSeq.safeMap(implicits.scala:248)\r\n\tat com.nvidia.spark.rapids.GpuProjectExec$.project(basicPhysicalOperators.scala:109)\r\n\tat org.apache.spark.sql.rapids.GpuMurmur3Hash$.compute(HashFunctions.scala:47)\r\n\tat com.nvidia.spark.rapids.GpuHashPartitioningBase$.$anonfun$hashPartitionAndClose$2(GpuHashPartitioningBase.scala:72)\r\n\tat com.nvidia.spark.rapids.Arm.withResource(Arm.scala:28)\r\n\tat com.nvidia.spark.rapids.Arm.withResource$(Arm.scala:26)\r\n\tat com.nvidia.spark.rapids.GpuHashPartitioningBase$.withResource(GpuHashPartitioningBase.scala:64)\r\n\tat com.nvidia.spark.rapids.GpuHashPartitioningBase$.$anonfun$hashPartitionAndClose$1(GpuHashPartitioningBase.scala:71)\r\n\tat com.nvidia.spark.rapids.Arm.withResource(Arm.scala:28)\r\n\tat com.nvidia.spark.rapids.Arm.withResource$(Arm.scala:26)\r\n\tat com.nvidia.spark.rapids.GpuHashPartitioningBase$.withResource(GpuHashPartitioningBase.scala:64)\r\n\tat com.nvidia.spark.rapids.GpuHashPartitioningBase$.hashPartitionAndClose(GpuHashPartitioningBase.scala:70)\r\n\tat com.nvidia.spark.rapids.GpuHashPartitioningBase.partitionInternalAndClose(GpuHashPartitioningBase.scala:36)\r\n\tat com.nvidia.spark.rapids.GpuHashPartitioningBase.$anonfun$columnarEval$2(GpuHashPartitioningBase.scala:55)\r\n\tat com.nvidia.spark.rapids.Arm.withResource(Arm.scala:28)\r\n\tat com.nvidia.spark.rapids.Arm.withResource$(Arm.scala:26)\r\n\tat com.nvidia.spark.rapids.GpuHashPartitioningBase.withResource(GpuHashPartitioningBase.scala:27)\r\n\tat com.nvidia.spark.rapids.GpuHashPartitioningBase.$anonfun$columnarEval$1(GpuHashPartitioningBase.scala:54)\r\n\tat com.nvidia.spark.rapids.Arm.withResource(Arm.scala:28)\r\n\tat com.nvidia.spark.rapids.Arm.withResource$(Arm.scala:26)\r\n\tat com.nvidia.spark.rapids.GpuHashPartitioningBase.withResource(GpuHashPartitioningBase.scala:27)\r\n\tat com.nvidia.spark.rapids.GpuHashPartitioningBase.columnarEval(GpuHashPartitioningBase.scala:51)\r\n\tat org.apache.spark.sql.rapids.execution.GpuShuffleExchangeExecBase$.$anonfun$prepareBatchShuffleDependency$3(GpuShuffleExchangeExecBase.scala:302)\r\n\tat org.apache.spark.sql.rapids.execution.GpuShuffleExchangeExecBase$$anon$1.partNextBatch(GpuShuffleExchangeExecBase.scala:326)\r\n\tat org.apache.spark.sql.rapids.execution.GpuShuffleExchangeExecBase$$anon$1.hasNext(GpuShuffleExchangeExecBase.scala:340)\r\n\tat org.apache.spark.sql.rapids.RapidsShuffleThreadedWriterBase.$anonfun$write$2(RapidsShuffleInternalManagerBase.scala:281)\r\n\tat org.apache.spark.sql.rapids.RapidsShuffleThreadedWriterBase.$anonfun$write$2$adapted(RapidsShuffleInternalManagerBase.scala:274)\r\n\tat com.nvidia.spark.rapids.Arm.withResource(Arm.scala:28)\r\n\tat com.nvidia.spark.rapids.Arm.withResource$(Arm.scala:26)\r\n\tat org.apache.spark.sql.rapids.RapidsShuffleThreadedWriterBase.withResource(RapidsShuffleInternalManagerBase.scala:234)\r\n\tat org.apache.spark.sql.rapids.RapidsShuffleThreadedWriterBase.$anonfun$write$1(RapidsShuffleInternalManagerBase.scala:274)\r\n\tat org.apache.spark.sql.rapids.RapidsShuffleThreadedWriterBase.$anonfun$write$1$adapted(RapidsShuffleInternalManagerBase.scala:273)\r\n\tat com.nvidia.spark.rapids.Arm.withResource(Arm.scala:28)\r\n\tat com.nvidia.spark.rapids.Arm.withResource$(Arm.scala:26)\r\n\tat org.apache.spark.sql.rapids.RapidsShuffleThreadedWriterBase.withResource(RapidsShuffleInternalManagerBase.scala:234)\r\n\tat org.apache.spark.sql.rapids.RapidsShuffleThreadedWriterBase.write(RapidsShuffleInternalManagerBase.scala:273)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\r\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\r\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\r\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:156)\r\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:125)\r\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:95)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:832)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1681)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:835)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:690)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\n```\r\n\r\nThe sql query node was:\r\n```\r\n(110) GpuColumnarExchange\r\nInput [12]: XXX\r\nArguments: gpuhashpartitioning(cast(CASE WHEN gpucontains(job_id#922, -worker-) THEN regexp_extract(job_id#922, (\\d+)-worker-(\\d+), 1) ELSE job_id#922 END as int), CASE WHEN gpucontains(job_id#922, -worker-) THEN cast(regexp_extract(job_id#922, (\\d+)-worker-(\\d+), 1) as int) ELSE -1 END, 200), ENSURE_REQUIREMENTS, [id=#3697]\r\n\r\n```",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8053/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8053/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}