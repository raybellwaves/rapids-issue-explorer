{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7650",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7650/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7650/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7650/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7650",
    "id": 1568587393,
    "node_id": "I_kwDOD7z77c5dfr6B",
    "number": 7650,
    "title": "[BUG] Databricks tests don't use the documented jar deploy option",
    "user": {
        "login": "gerashegalov",
        "id": 3187938,
        "node_id": "MDQ6VXNlcjMxODc5Mzg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3187938?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gerashegalov",
        "html_url": "https://github.com/gerashegalov",
        "followers_url": "https://api.github.com/users/gerashegalov/followers",
        "following_url": "https://api.github.com/users/gerashegalov/following{/other_user}",
        "gists_url": "https://api.github.com/users/gerashegalov/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/gerashegalov/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/gerashegalov/subscriptions",
        "organizations_url": "https://api.github.com/users/gerashegalov/orgs",
        "repos_url": "https://api.github.com/users/gerashegalov/repos",
        "events_url": "https://api.github.com/users/gerashegalov/events{/privacy}",
        "received_events_url": "https://api.github.com/users/gerashegalov/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 2061735878,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc4",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/documentation",
            "name": "documentation",
            "color": "0075ca",
            "default": true,
            "description": "Improvements or additions to documentation"
        },
        {
            "id": 2094874947,
            "node_id": "MDU6TGFiZWwyMDk0ODc0OTQ3",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/test",
            "name": "test",
            "color": "60d6d4",
            "default": false,
            "description": "Only impacts tests"
        },
        {
            "id": 2137414845,
            "node_id": "MDU6TGFiZWwyMTM3NDE0ODQ1",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/build",
            "name": "build",
            "color": "0052cc",
            "default": false,
            "description": "Related to CI / CD or cleanly building"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-02-02T18:44:09Z",
    "updated_at": "2023-02-02T18:44:53Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\n\r\nPre-merge on Databricks only tests the Spark user classpath deployment option --jars without testing the system classpath option via placing the plugin jar `$SPARK_HOME/jars` (although this is what we [document](https://github.com/NVIDIA/spark-rapids/blob/5a4e17335493b19db56a55dc699a5ab78656c200/docs/get-started/getting-started-databricks.md?plain=1#L146) for users) or equivalently specifying it in to `spark.*.extraClassPath`\r\n\r\nAs a result,  the CNF Exception on https://github.com/NVIDIA/spark-rapids/pull/7576#issuecomment-1411285388  was only accidentally discovered in manual testing instead of being flagged by premerge.\r\n\r\n**Steps/Code to reproduce bug**\r\nstart a Databricks cluster with a documented init script with the jars from the commit before the fix a3a1f78835a955d1207d9ada5c7d01e75e72b964\r\n\r\n**Expected behavior**\r\nShould successfully test on Databricks with both --jars and $SPARK_HOME/jars deployment options. If constrained by resources, reconcile the doc and the test one way or another.\r\n\r\n**Environment details (please complete the following information)**\r\nDatabricks 11.3\r\n\r\n**Additional context**\r\nit would also be prevented by build if we implemented #6565   ",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7650/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7650/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}