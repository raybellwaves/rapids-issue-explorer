{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10770",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10770/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10770/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10770/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10770",
    "id": 2282341242,
    "node_id": "I_kwDOD7z77c6ICcN6",
    "number": 10770,
    "title": "[BUG] Slow/no progress with cascaded pandas udfs/mapInPandas in Databricks",
    "user": {
        "login": "eordentlich",
        "id": 36281329,
        "node_id": "MDQ6VXNlcjM2MjgxMzI5",
        "avatar_url": "https://avatars.githubusercontent.com/u/36281329?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/eordentlich",
        "html_url": "https://github.com/eordentlich",
        "followers_url": "https://api.github.com/users/eordentlich/followers",
        "following_url": "https://api.github.com/users/eordentlich/following{/other_user}",
        "gists_url": "https://api.github.com/users/eordentlich/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/eordentlich/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/eordentlich/subscriptions",
        "organizations_url": "https://api.github.com/users/eordentlich/orgs",
        "repos_url": "https://api.github.com/users/eordentlich/repos",
        "events_url": "https://api.github.com/users/eordentlich/events{/privacy}",
        "received_events_url": "https://api.github.com/users/eordentlich/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": {
        "login": "firestarman",
        "id": 7280411,
        "node_id": "MDQ6VXNlcjcyODA0MTE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/7280411?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/firestarman",
        "html_url": "https://github.com/firestarman",
        "followers_url": "https://api.github.com/users/firestarman/followers",
        "following_url": "https://api.github.com/users/firestarman/following{/other_user}",
        "gists_url": "https://api.github.com/users/firestarman/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/firestarman/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/firestarman/subscriptions",
        "organizations_url": "https://api.github.com/users/firestarman/orgs",
        "repos_url": "https://api.github.com/users/firestarman/repos",
        "events_url": "https://api.github.com/users/firestarman/events{/privacy}",
        "received_events_url": "https://api.github.com/users/firestarman/received_events",
        "type": "User",
        "site_admin": false
    },
    "assignees": [
        {
            "login": "firestarman",
            "id": 7280411,
            "node_id": "MDQ6VXNlcjcyODA0MTE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7280411?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/firestarman",
            "html_url": "https://github.com/firestarman",
            "followers_url": "https://api.github.com/users/firestarman/followers",
            "following_url": "https://api.github.com/users/firestarman/following{/other_user}",
            "gists_url": "https://api.github.com/users/firestarman/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/firestarman/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/firestarman/subscriptions",
            "organizations_url": "https://api.github.com/users/firestarman/orgs",
            "repos_url": "https://api.github.com/users/firestarman/repos",
            "events_url": "https://api.github.com/users/firestarman/events{/privacy}",
            "received_events_url": "https://api.github.com/users/firestarman/received_events",
            "type": "User",
            "site_admin": false
        }
    ],
    "milestone": null,
    "comments": 6,
    "created_at": "2024-05-07T05:52:48Z",
    "updated_at": "2024-06-06T07:31:00Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nSuccessively applied Pandas UDFs and MapInPandas make no progress in Databricks.\r\n\r\n\r\n**Steps/Code to reproduce bug**\r\n```python\r\nimport pyspark.sql.functions as F\r\nimport numpy as np\r\nimport pandas as pd\r\ntransformed_df = spark.range(1000000) \r\nfrom pyspark.sql.functions import pandas_udf\r\n\r\n@pandas_udf(\"int\")\r\ndef rand_label(col: pd.Series) -> pd.Series: \r\n  import logging\r\n  logger = logging.getLogger('rand_label')\r\n  logger.info(\"in rand label\")\r\n  print(\"in rand label 1\")\r\n  return pd.Series(np.random.randint(0,999,size=col.shape[0]))\r\n\r\n@pandas_udf(\"int\")\r\ndef rand_label2(col: pd.Series) -> pd.Series: \r\n  import logging\r\n  logger = logging.getLogger('rand_label')\r\n  logger.info(\"in rand label\")\r\n  print(\"in rand label 2\")\r\n  return pd.Series(np.random.randint(0,999,size=col.shape[0]))\r\n\r\ntransformed_df_w_label_2 = transformed_df.withColumn(\"label\", rand_label(F.lit(0)))\r\n```\r\n\r\nThe following then is problematic.\r\n```python\r\ntransformed_df = spark.read.parquet(\"s3a://spark-rapids-ml-bm-datasets-public/pca/1m_3k_singlecol_float32_50_files.parquet\")\r\nfeatures_col = 'feature_array'\r\nprediction_col = 'label'\r\ncenters = np.random.rand(1000,3000)\r\nfrom pyspark.sql.types import StructType, StructField, DoubleType\r\n\r\nsc = transformed_df.rdd.context\r\ncenters_bc = sc.broadcast(centers)\r\n\r\ndef partition_score_udf(\r\n    pdf_iter\r\n) :\r\n    local_centers = centers_bc.value.astype(np.float64)\r\n    partition_score = 0.0\r\n    import logging\r\n    logger = logging.getLogger('partition_score_udf')\r\n    logger.info(\"in partition score udf\")\r\n    for pdf in pdf_iter:\r\n        print(\"in partition score udf\")\r\n        input_vecs = np.array(list(pdf[features_col]), dtype=np.float64)\r\n        predictions = list(pdf[prediction_col])\r\n        center_vecs = local_centers[predictions, :]\r\n        partition_score += np.sum((input_vecs - center_vecs) ** 2)\r\n    yield pd.DataFrame({\"partition_score\": [partition_score]})\r\n\r\ntotal_score = (\r\n  # the below is extremely slow\r\n  # if instead of transformed_df_w_label_2 we apply to transformed_df_w_label it runs fine\r\n  # one difference is that transformed_df_ws_label_2 is itself the output of another pandas udf\r\n  # so data for this case is passing back and forth between jvm and python workers multiple times\r\n    transformed_df_w_label_2.mapInPandas(\r\n        partition_score_udf,  # type: ignore\r\n        StructType([StructField(\"partition_score\", DoubleType(), True)]),\r\n    )\r\n    .agg(F.sum(\"partition_score\").alias(\"total_score\"))\r\n    .toPandas()\r\n)  # type: ignore\r\ntotal_score = total_score[\"total_score\"][0]  # type: ignore\r\n```\r\nIn this case, at least in 13.3ML, the computation slows dramatically and may be deadlocked.\r\n\r\n**Expected behavior**\r\nNo slowdowns, like with baseline Spark without the plugin.\r\n\r\n**Environment details (please complete the following information)**\r\n - Environment location: Second example is slow only in Databricks 13.3ML\r\n - Spark configuration settings related to the issue\r\n ```\r\nspark.task.resource.gpu.amount 1\r\nspark.task.cpus 1\r\nspark.databricks.delta.preview.enabled true\r\nspark.python.worker.reuse true\r\nspark.executorEnv.PYTHONPATH /databricks/jars/rapids-4-spark_2.12-24.04.0.jar:/databricks/spark/python\r\nspark.sql.files.minPartitionNum 2\r\nspark.sql.execution.arrow.maxRecordsPerBatch 10000\r\nspark.executor.cores 8\r\nspark.rapids.memory.gpu.minAllocFraction 0.0001\r\nspark.plugins com.nvidia.spark.SQLPlugin\r\nspark.locality.wait 0s\r\nspark.sql.cache.serializer com.nvidia.spark.ParquetCachedBatchSerializer\r\nspark.rapids.memory.gpu.pooling.enabled false\r\nspark.rapids.sql.explain ALL\r\nspark.sql.execution.sortBeforeRepartition false\r\nspark.rapids.sql.python.gpu.enabled true\r\nspark.rapids.memory.pinnedPool.size 2G\r\nspark.python.daemon.module rapids.daemon_databricks\r\nspark.rapids.sql.batchSizeBytes 512m\r\nspark.sql.adaptive.enabled false\r\nspark.sql.execution.arrow.pyspark.enabled true\r\nspark.sql.files.maxPartitionBytes 2000000000000\r\nspark.databricks.delta.optimizeWrite.enabled false\r\nspark.rapids.sql.concurrentGpuTasks 2\r\n```\r\n\r\nCluster shape: 2x workers with  g5.2xlarge and driver with g4dn.xlarge\r\n**Additional context**\r\nAlso, based on print statement output in the logs, the first udf appears to complete fully before the second one starts. The batches should flow through both python udfs incrementally as is the case with baseline Spark.\r\n\r\nMight be related to: https://github.com/NVIDIA/spark-rapids/issues/10751\r\n\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10770/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10770/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}