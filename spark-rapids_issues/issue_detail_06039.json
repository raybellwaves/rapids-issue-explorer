{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6039",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6039/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6039/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6039/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6039",
    "id": 1311421457,
    "node_id": "I_kwDOD7z77c5OKrQR",
    "number": 6039,
    "title": "[SPARK-39667][SQL] Workaround when there is not enough memory to build and broadcast the table",
    "user": {
        "login": "amahussein",
        "id": 50450311,
        "node_id": "MDQ6VXNlcjUwNDUwMzEx",
        "avatar_url": "https://avatars.githubusercontent.com/u/50450311?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/amahussein",
        "html_url": "https://github.com/amahussein",
        "followers_url": "https://api.github.com/users/amahussein/followers",
        "following_url": "https://api.github.com/users/amahussein/following{/other_user}",
        "gists_url": "https://api.github.com/users/amahussein/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/amahussein/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/amahussein/subscriptions",
        "organizations_url": "https://api.github.com/users/amahussein/orgs",
        "repos_url": "https://api.github.com/users/amahussein/repos",
        "events_url": "https://api.github.com/users/amahussein/events{/privacy}",
        "received_events_url": "https://api.github.com/users/amahussein/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 2061735887,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODg3",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/good%20first%20issue",
            "name": "good first issue",
            "color": "7057ff",
            "default": true,
            "description": "Good for newcomers"
        },
        {
            "id": 2223784867,
            "node_id": "MDU6TGFiZWwyMjIzNzg0ODY3",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/P2",
            "name": "P2",
            "color": "8ff7b9",
            "default": false,
            "description": "Not required for release"
        },
        {
            "id": 4073796705,
            "node_id": "LA_kwDOD7z77c7y0TRh",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/audit_3.4.0",
            "name": "audit_3.4.0",
            "color": "8310E8",
            "default": false,
            "description": "Audit related tasks for 3.4.0"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2022-07-20T16:07:27Z",
    "updated_at": "2022-07-27T20:43:28Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nSpark-3.4 adds `ANALYZE TABLE tbl COMPUTE STATISTICS;` as a workaround when there is not enough memory to build and broadcast the table.\r\n\r\nThe OOM exception message has changed from\r\n```\r\n\"Not enough memory to build and broadcast the table to all \" +\r\n        \"worker nodes. As a workaround, you can either disable broadcast by setting \" +\r\n        s\"${SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key} to -1 or increase the spark \" +\r\n        s\"driver memory by setting ${SparkLauncher.DRIVER_MEMORY} to a higher value.\"\r\n```\r\n\r\nto\r\n\r\n```\r\n\"Not enough memory to build and broadcast the table to all \" +\r\n        \"worker nodes. As a workaround, you can either disable broadcast by setting \" +\r\n        s\"${SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key} to -1 or increase the spark \" +\r\n        s\"driver memory by setting ${SparkLauncher.DRIVER_MEMORY} to a higher value\" +\r\n        \"or analyze these tables through: \" +\r\n        s\"${tables.map(t => s\"ANALYZE TABLE $t COMPUTE STATISTICS;\").mkString(\" \")}.\"\r\n```\r\n\r\n**Expected behavior**\r\nNot enough memory to build and broadcast the table to all worker nodes. As a workaround, you can either:\r\n\r\n1. Setting `spark.sql.autoBroadcastJoinThreshold` to -1, but this will disable all broadcast joins.\r\n2. increase `spark.driver.memory` but we don't know the specific value of `spark.driver.memory` should be set.\r\n\r\nthe new change adds more information to the OOM exception message.\r\n\r\n**Additional context**\r\nhttps://github.com/apache/spark/commit/9c5c21ccc9\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6039/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6039/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}