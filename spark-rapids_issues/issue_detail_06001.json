{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6001",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6001/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6001/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6001/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6001",
    "id": 1304895867,
    "node_id": "I_kwDOD7z77c5NxyF7",
    "number": 6001,
    "title": "[BUG] Spark can shutdown the plugin before all tasks complete. This can cause segfaults",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2022-07-14T14:46:18Z",
    "updated_at": "2022-07-19T20:41:17Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nRecently I ran into a segfault that happened after we ran out of memory. This really scared me because the crashes were happening inside of RMM. It turns out that if a task throws an exception that Spark can shut down the process before all of the threads complete. As a part of shutting down, Spark will shut down the plugin, which in turn will shut down RMM. If there is native code running that does not hold onto any device memory buffers (like when reading parquet) then the java CUDF code thinks it is okay to shut down RMM, and this can lead to segfaults.  I am not 100% sure of the best way to deal with this. We could try to keep track of native API calls and not shut down RMM if there are any native calls still active. But this could add a lot of overhead. Because there is no simple fix I though I would file an issue and we can think about/discuss potential fixes.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6001/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6001/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}