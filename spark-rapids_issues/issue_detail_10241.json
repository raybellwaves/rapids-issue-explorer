{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10241",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10241/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10241/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10241/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10241",
    "id": 2094370822,
    "node_id": "I_kwDOD7z77c581ZAG",
    "number": 10241,
    "title": "[FEA] Add support for reading nested JSON in `GpuJsonScan`",
    "user": {
        "login": "andygrove",
        "id": 934084,
        "node_id": "MDQ6VXNlcjkzNDA4NA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/934084?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/andygrove",
        "html_url": "https://github.com/andygrove",
        "followers_url": "https://api.github.com/users/andygrove/followers",
        "following_url": "https://api.github.com/users/andygrove/following{/other_user}",
        "gists_url": "https://api.github.com/users/andygrove/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/andygrove/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/andygrove/subscriptions",
        "organizations_url": "https://api.github.com/users/andygrove/orgs",
        "repos_url": "https://api.github.com/users/andygrove/repos",
        "events_url": "https://api.github.com/users/andygrove/events{/privacy}",
        "received_events_url": "https://api.github.com/users/andygrove/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735884,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODg0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-01-22T17:09:26Z",
    "updated_at": "2024-01-23T21:54:16Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nWe cannot read JSON files containing nested types when using `GpuJsonScan`, even though we do support this in `from_json`.\r\n\r\n## Input:\r\n\r\n```json\r\n{ \"a\": { \"b\": \"hello\" } }\r\n{ \"a\": { \"b\": \"goodbye\" } }\r\n```\r\n\r\n## Test:\r\n```\r\nscala> spark.conf.set(\"spark.rapids.sql.format.json.enabled\", true)\r\nscala> spark.conf.set(\"spark.rapids.sql.format.json.read.enabled\", true)\r\nscala> spark.read.schema(\"a struct<b string>\").json(\"test.json\").show\r\n24/01/22 16:59:06 WARN GpuOverrides: \r\n!Exec <CollectLimitExec> cannot run on GPU because the Exec CollectLimitExec has been disabled, and is disabled by default because Collect Limit replacement can be slower on the GPU, if huge number of rows in a batch it could help by limiting the number of rows transferred from GPU to CPU. Set spark.rapids.sql.exec.CollectLimitExec to true if you wish to enable it\r\n  @Partitioning <SinglePartition$> could run on GPU\r\n  *Exec <ProjectExec> will run on GPU\r\n    *Expression <Alias> toprettystring(a#37, Some(UTC)) AS toprettystring(a)#40 will run on GPU\r\n      *Expression <ToPrettyString> toprettystring(a#37, Some(UTC)) will run on GPU\r\n    !Exec <FileSourceScanExec> cannot run on GPU because unsupported data types StructType(StructField(b,StringType,true)) [a] in read for JSON\r\n```\r\n\r\n**Describe the solution you'd like**\r\nI would like to be able to read JSON files with nested types.\r\n\r\nNote that we already support reading nested types in `from_json`:\r\n\r\n```\r\nscala> val schema = StructType(Seq(StructField(\"a\", StructType(Seq(StructField(\"b\", DataTypes.StringType, true))), true)))\r\n\r\nscala> val df = spark.read.text(\"test.json\").withColumn(\"json\", from_json(col(\"value\"), schema))\r\ndf: org.apache.spark.sql.DataFrame = [value: string, json: struct<a: struct<b: string>>]\r\n\r\n!Exec <CollectLimitExec> cannot run on GPU because the Exec CollectLimitExec has been disabled, and is disabled by default because Collect Limit replacement can be slower on the GPU, if huge number of rows in a batch it could help by limiting the number of rows transferred from GPU to CPU. Set spark.rapids.sql.exec.CollectLimitExec to true if you wish to enable it\r\n  @Partitioning <SinglePartition$> could run on GPU\r\n  *Exec <ProjectExec> will run on GPU\r\n    *Expression <Alias> toprettystring(value#9, Some(UTC)) AS toprettystring(value)#27 will run on GPU\r\n      *Expression <ToPrettyString> toprettystring(value#9, Some(UTC)) will run on GPU\r\n    *Expression <Alias> toprettystring(from_json(StructField(a,StructType(StructField(b,StringType,true)),true), value#9, Some(UTC)), Some(UTC)) AS toprettystring(json)#28 will run on GPU\r\n      *Expression <ToPrettyString> toprettystring(from_json(StructField(a,StructType(StructField(b,StringType,true)),true), value#9, Some(UTC)), Some(UTC)) will run on GPU\r\n        *Expression <JsonToStructs> from_json(StructField(a,StructType(StructField(b,StringType,true)),true), value#9, Some(UTC)) will run on GPU\r\n    !Exec <FileSourceScanExec> cannot run on GPU because unsupported file format: org.apache.spark.sql.execution.datasources.text.TextFileFormat\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nNone\r\n\r\n**Additional context**\r\nNone\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10241/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10241/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}