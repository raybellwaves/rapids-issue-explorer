{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7861",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7861/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7861/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7861/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7861",
    "id": 1616151215,
    "node_id": "I_kwDOD7z77c5gVIKv",
    "number": 7861,
    "title": "[Task] Investigate compliance with SPARK-39347",
    "user": {
        "login": "mythrocks",
        "id": 5607330,
        "node_id": "MDQ6VXNlcjU2MDczMzA=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5607330?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mythrocks",
        "html_url": "https://github.com/mythrocks",
        "followers_url": "https://api.github.com/users/mythrocks/followers",
        "following_url": "https://api.github.com/users/mythrocks/following{/other_user}",
        "gists_url": "https://api.github.com/users/mythrocks/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/mythrocks/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/mythrocks/subscriptions",
        "organizations_url": "https://api.github.com/users/mythrocks/orgs",
        "repos_url": "https://api.github.com/users/mythrocks/repos",
        "events_url": "https://api.github.com/users/mythrocks/events{/privacy}",
        "received_events_url": "https://api.github.com/users/mythrocks/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 4073796705,
            "node_id": "LA_kwDOD7z77c7y0TRh",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/audit_3.4.0",
            "name": "audit_3.4.0",
            "color": "8310E8",
            "default": false,
            "description": "Audit related tasks for 3.4.0"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": {
        "login": "mythrocks",
        "id": 5607330,
        "node_id": "MDQ6VXNlcjU2MDczMzA=",
        "avatar_url": "https://avatars.githubusercontent.com/u/5607330?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/mythrocks",
        "html_url": "https://github.com/mythrocks",
        "followers_url": "https://api.github.com/users/mythrocks/followers",
        "following_url": "https://api.github.com/users/mythrocks/following{/other_user}",
        "gists_url": "https://api.github.com/users/mythrocks/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/mythrocks/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/mythrocks/subscriptions",
        "organizations_url": "https://api.github.com/users/mythrocks/orgs",
        "repos_url": "https://api.github.com/users/mythrocks/repos",
        "events_url": "https://api.github.com/users/mythrocks/events{/privacy}",
        "received_events_url": "https://api.github.com/users/mythrocks/received_events",
        "type": "User",
        "site_admin": false
    },
    "assignees": [
        {
            "login": "mythrocks",
            "id": 5607330,
            "node_id": "MDQ6VXNlcjU2MDczMzA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5607330?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mythrocks",
            "html_url": "https://github.com/mythrocks",
            "followers_url": "https://api.github.com/users/mythrocks/followers",
            "following_url": "https://api.github.com/users/mythrocks/following{/other_user}",
            "gists_url": "https://api.github.com/users/mythrocks/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mythrocks/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mythrocks/subscriptions",
            "organizations_url": "https://api.github.com/users/mythrocks/orgs",
            "repos_url": "https://api.github.com/users/mythrocks/repos",
            "events_url": "https://api.github.com/users/mythrocks/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mythrocks/received_events",
            "type": "User",
            "site_admin": false
        }
    ],
    "milestone": null,
    "comments": 1,
    "created_at": "2023-03-08T23:39:34Z",
    "updated_at": "2023-03-21T21:10:21Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "[SPARK-39347](https://github.com/apache/spark/commit/c3bd9fe292) describes a change in Spark windowing behaviour with regard to window functions evaluated on timestamp values that precede epoch. (i.e. \"negative\" timestamp values).\r\n\r\nHere is the suggested repro:\r\n```scala\r\nval df3 = Seq(\r\n      (\"1969-12-31 00:00:02\", 1),\r\n      (\"1969-12-31 00:00:12\", 2)).toDF(\"time\", \"value\")\r\nval df4 = Seq(\r\n      (LocalDateTime.parse(\"1969-12-31T00:00:02\"), 1),\r\n      (LocalDateTime.parse(\"1969-12-31T00:00:12\"), 2)).toDF(\"time\", \"value\")    \r\n\r\nSeq(df3, df4).foreach { df =>\r\n      checkAnswer(\r\n        df.select(window($\"time\", \"10 seconds\", \"10 seconds\", \"5 seconds\"), $\"value\")\r\n          .orderBy($\"window.start\".asc)\r\n          .select($\"window.start\".cast(StringType), $\"window.end\".cast(StringType), $\"value\"),\r\n        Seq(\r\n          Row(\"1969-12-30 23:59:55\", \"1969-12-31 00:00:05\", 1),\r\n          Row(\"1969-12-31 00:00:05\", \"1969-12-31 00:00:15\", 2))\r\n      )\r\n}\r\n```\r\nThis apparently used to error out with:\r\n```\r\n== Results ==\r\n!== Correct Answer - 2 ==                      == Spark Answer - 2 ==\r\n!struct<>                                      struct<CAST(window.start AS STRING):string,CAST(window.end AS STRING):string,value:int>\r\n![1969-12-30 23:59:55,1969-12-31 00:00:05,1]   [1969-12-31 00:00:05,1969-12-31 00:00:15,1]\r\n![1969-12-31 00:00:05,1969-12-31 00:00:15,2]   [1969-12-31 00:00:15,1969-12-31 00:00:25,2]\r\n```\r\nAuthor's note:\r\n> Notice how this is shifted with one `slideDuration`. It should start with `[1969-12-30 23:59:55,1969-12-31 00:00:05,1]` but spark returns `[1969-12-31 00:00:05,1969-12-31 00:00:15,1]`, right-shifted of one `slideDuration` (10 seconds).\r\n\r\nThis apparently stems from the behaviour of modulo on negative values. E.g. `-1 % 3 == -1`, while Spark now wants it defined as `2`.\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7861/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7861/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}