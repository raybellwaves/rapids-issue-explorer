{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1091",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1091/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1091/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1091/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/1091",
    "id": 740009511,
    "node_id": "MDU6SXNzdWU3NDAwMDk1MTE=",
    "number": 1091,
    "title": "[BUG] Incorrect values when parsing dates from timestamps stored in CSV files",
    "user": {
        "login": "andygrove",
        "id": 934084,
        "node_id": "MDQ6VXNlcjkzNDA4NA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/934084?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/andygrove",
        "html_url": "https://github.com/andygrove",
        "followers_url": "https://api.github.com/users/andygrove/followers",
        "following_url": "https://api.github.com/users/andygrove/following{/other_user}",
        "gists_url": "https://api.github.com/users/andygrove/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/andygrove/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/andygrove/subscriptions",
        "organizations_url": "https://api.github.com/users/andygrove/orgs",
        "repos_url": "https://api.github.com/users/andygrove/repos",
        "events_url": "https://api.github.com/users/andygrove/events{/privacy}",
        "received_events_url": "https://api.github.com/users/andygrove/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 2094499852,
            "node_id": "MDU6TGFiZWwyMDk0NDk5ODUy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/SQL",
            "name": "SQL",
            "color": "8f4df9",
            "default": false,
            "description": "part of the SQL/Dataframe plugin"
        },
        {
            "id": 2223784867,
            "node_id": "MDU6TGFiZWwyMjIzNzg0ODY3",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/P2",
            "name": "P2",
            "color": "8ff7b9",
            "default": false,
            "description": "Not required for release"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2020-11-10T15:29:17Z",
    "updated_at": "2023-08-15T19:40:23Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nIf I specify a schema with a `DateType` when reading from a CSV file containing timestamps, I get corrupt data when the plugin is enabled.\r\n\r\n**Steps/Code to reproduce bug**\r\n\r\nCreate `tests/src/test/resources/timestamps.csv` CSV file:\r\n\r\n```csv\r\n2019-01-03T12:34:56.123456,1\r\n2019-01-03T12:34:56.123456,1\r\n2019-01-03T12:34:56.123456,1\r\n2019-01-05T12:34:56.123456,2\r\n2019-01-05T12:34:56.123456,3\r\n2019-01-06T12:34:56.123456,6\r\n```\r\n\r\nAdd this method to `tests/src/test/scala/com/nvidia/spark/rapids/SparkQueryCompareTestSuite.scala`:\r\n\r\n```scala\r\n  def timestampsAsDatesCsvDf= {\r\n    fromCsvDf(\"timestamps.csv\", StructType(Array(\r\n      StructField(\"dates\", DateType, false),\r\n      StructField(\"ints\", IntegerType, false)\r\n    )))(_)\r\n  }\r\n```\r\n\r\nAdd these tests to `tests/src/test/scala/com/nvidia/spark/rapids/CsvScanSuite.scala`:\r\n\r\n```scala\r\n  testSparkResultsAreEqual(\r\n    \"Test CSV parse dates\",\r\n    datesCsvDf,\r\n    conf=new SparkConf()) {\r\n    df => df.withColumn(\"next_day\", date_add(col(\"dates\"), lit(1)))\r\n  }\r\n\r\n  testSparkResultsAreEqual(\r\n    \"Test CSV parse timestamps as dates\",\r\n    timestampsAsDatesCsvDf,\r\n    conf=new SparkConf()) {\r\n    df => df.withColumn(\"next_day\", date_add(col(\"dates\"), lit(1)))\r\n  }\r\n```\r\n\r\nThe first test passes but the second test fails with:\r\n\r\n```\r\nCPU: WrappedArray([2019-01-03,1,2019-01-04], [2019-01-03,1,2019-01-04], [2019-01-03,1,2019-01-04], [2019-01-05,2,2019-01-06], [2019-01-05,3,2019-01-06], [2019-01-06,6,2019-01-07])\r\n\r\nGPU: WrappedArray([0718-10-22,1,0718-10-23], [0718-10-22,1,0718-10-23], [0718-10-22,1,0718-10-23], [2280-05-20,2,2280-05-21], [2280-05-20,3,2280-05-21], [3779-09-03,6,3779-09-04])\r\n```\r\n\r\n**Expected behavior**\r\nThe tests should both pass because the output should be the same with or without the plugin enabled.\r\n\r\n**Environment details (please complete the following information)**\r\nRunning tests in IDE.\r\n\r\n**Additional context**\r\nN/A\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1091/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1091/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}