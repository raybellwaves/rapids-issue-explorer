{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6981",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6981/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6981/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6981/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6981",
    "id": 1433341863,
    "node_id": "I_kwDOD7z77c5Vbw-n",
    "number": 6981,
    "title": "Partitioned writes may not need to sort the incoming data",
    "user": {
        "login": "jlowe",
        "id": 1360766,
        "node_id": "MDQ6VXNlcjEzNjA3NjY=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1360766?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jlowe",
        "html_url": "https://github.com/jlowe",
        "followers_url": "https://api.github.com/users/jlowe/followers",
        "following_url": "https://api.github.com/users/jlowe/following{/other_user}",
        "gists_url": "https://api.github.com/users/jlowe/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/jlowe/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/jlowe/subscriptions",
        "organizations_url": "https://api.github.com/users/jlowe/orgs",
        "repos_url": "https://api.github.com/users/jlowe/repos",
        "events_url": "https://api.github.com/users/jlowe/events{/privacy}",
        "received_events_url": "https://api.github.com/users/jlowe/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2094500742,
            "node_id": "MDU6TGFiZWwyMDk0NTAwNzQy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/performance",
            "name": "performance",
            "color": "d845b1",
            "default": false,
            "description": "A performance related task/issue"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2022-11-02T15:21:33Z",
    "updated_at": "2022-11-02T16:39:44Z",
    "closed_at": null,
    "author_association": "MEMBER",
    "active_lock_reason": null,
    "body": "Currently writing partitioned data will introduce a sort if the query plan does not already call for an output ordering that matches the partition keys.  However I don't think the ordering is necessary, and it is relatively expensive to perform.  Instead of doing a sort, we distinct and sort the partition keys as we do today, and do a lowerBound against the unsorted incoming batch which produces the partition mapping per row.  We can then call cudf's partition to partition the batch and make the partitions spillable, moving onto the next batch, tracking all the partitions associated with each key as we move through the batches.  Once we reach the end of the batches, we can then proceed to go through the distinct keys, concatenating and encoding the partition data for that key on the GPU, copy the data back to the host, release the GPU semaphore, and write it to the distributed filesystem.\r\n\r\nThis ends up looking very similar to the dynamic partition writer we have today except it does not require concurrent writers be held open, which will save on CPU memory pressure from multiple file handles being held open.  We may still desire multiple file handles if we find it helps performance (e.g.: multithreaded writes against a cloud store), but it is not required.\r\n\r\nNote that doing this refactor should allow us to combine the logic for the dynamic and non-dynamic writers, as they will be quite similar afterwards.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6981/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6981/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}