{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9989",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9989/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9989/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9989/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/9989",
    "id": 2031084482,
    "node_id": "I_kwDOD7z77c55D-PC",
    "number": 9989,
    "title": "[FEA] Explore avoiding sort for unbounded to unbounded window",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2094500742,
            "node_id": "MDU6TGFiZWwyMDk0NTAwNzQy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/performance",
            "name": "performance",
            "color": "d845b1",
            "default": false,
            "description": "A performance related task/issue"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-12-07T16:12:56Z",
    "updated_at": "2023-12-07T19:49:20Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\nUnbounded to unbounded window operations are somewhat common, and it would be really nice to avoid sorting the data, which can be very expensive. An unbounded to unbounded window operation is really doing a group by aggregation on the partition by columns followed by a join on those partition by columns.\r\n\r\nFor example\r\n```\r\nval df = spark.range(200000000).selectExpr(\"id\", \"id % 100 as part\", \"id DIV 100 as data\")\r\nspark.time(df.selectExpr(\"*\", \"MAX(data) over (partition by part order by id rows between unbounded preceding and unbounded following) as m\").orderBy(desc(\"part\"), desc(\"id\")).show())\r\n```\r\ncan be rewritten as\r\n\r\n```\r\nval df = spark.range(200000000).selectExpr(\"id\", \"id % 100 as part\", \"id DIV 100 as data\")\r\nval tmp = df.groupBy(\"part\").agg(max(col(\"data\")).alias(\"m\"))\r\nspark.time(df.as(\"a\").join(tmp.as(\"b\"), col(\"a.part\") <=> col(\"b.part\")).selectExpr(\"id\", \"a.part as part\", \"data\", \"m\").orderBy(desc(\"part\"), desc(\"id\")).show())\r\n```\r\n\r\nOn my desktop the second one is faster, but about 7%. This is even with the downside for the second one of needing to read/generate the input data twice instead of once and extra shuffle data/etc, but I think we can overcome all of this.  What I am thinking is that we want to do this at a smaller level. Instead of rewriting the entire query, we want to do this within the GpuCachedDoublePassWindowExec and the planning for it.  If all of the window operations are unbounded to unbounded and the aggregations are ones that CUDF does not need to sort to do (min/max/sum/count/average on fixed width types), then we remove the sort and tell GpuCachedDoublePassWindowExec that the input data is not going to be sorted, so it will do an aggregate followed by a join internally.  We probably want something at runtime to see if it looks like there are a lot of partitions (perhaps the size of the data after the first batch, to see if it might be worth just doing the window operation as we have it today. That is because if I change part in the example above to be `id % 200000000`, then the join is much much slower than the window, especially if we know that the data is already sorted and the window operation can just run on it's own.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9989/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9989/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}