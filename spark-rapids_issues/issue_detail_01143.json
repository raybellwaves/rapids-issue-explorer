{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1143",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1143/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1143/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1143/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/1143",
    "id": 744991216,
    "node_id": "MDU6SXNzdWU3NDQ5OTEyMTY=",
    "number": 1143,
    "title": "[FEA] Improve performance of Cache plugin",
    "user": {
        "login": "razajafri",
        "id": 8813002,
        "node_id": "MDQ6VXNlcjg4MTMwMDI=",
        "avatar_url": "https://avatars.githubusercontent.com/u/8813002?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/razajafri",
        "html_url": "https://github.com/razajafri",
        "followers_url": "https://api.github.com/users/razajafri/followers",
        "following_url": "https://api.github.com/users/razajafri/following{/other_user}",
        "gists_url": "https://api.github.com/users/razajafri/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/razajafri/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/razajafri/subscriptions",
        "organizations_url": "https://api.github.com/users/razajafri/orgs",
        "repos_url": "https://api.github.com/users/razajafri/repos",
        "events_url": "https://api.github.com/users/razajafri/events{/privacy}",
        "received_events_url": "https://api.github.com/users/razajafri/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2094500742,
            "node_id": "MDU6TGFiZWwyMDk0NTAwNzQy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/performance",
            "name": "performance",
            "color": "d845b1",
            "default": false,
            "description": "A performance related task/issue"
        },
        {
            "id": 2223784867,
            "node_id": "MDU6TGFiZWwyMjIzNzg0ODY3",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/P2",
            "name": "P2",
            "color": "8ff7b9",
            "default": false,
            "description": "Not required for release"
        },
        {
            "id": 2450047019,
            "node_id": "MDU6TGFiZWwyNDUwMDQ3MDE5",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/Spark%203.1+",
            "name": "Spark 3.1+",
            "color": "d93f0b",
            "default": false,
            "description": "Bugs only related to Spark 3.1 or higher"
        },
        {
            "id": 2589743725,
            "node_id": "MDU6TGFiZWwyNTg5NzQzNzI1",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/epic",
            "name": "epic",
            "color": "0E8A16",
            "default": false,
            "description": "Issue that encompasses a significant feature or body of work"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2020-11-17T18:47:42Z",
    "updated_at": "2022-04-27T15:52:23Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "- [x] Support Decimals with negative scales by decomposing it to the long value https://github.com/NVIDIA/spark-rapids/pull/2675\r\n- [x] Use chunked writer when writing the CachedBatch. [Issue](https://github.com/NVIDIA/spark-rapids/issues/979)\r\n- [ ] ~Look into NVComp to see if we can provide a better performance than Parquet - Might not be needed~\r\n- [ ] Look into predicate push down instead of read rows and then throwing them away [Issue](https://github.com/NVIDIA/spark-rapids/issues/1019)\r\n- [ ] Only pass the needed conf instead of broadcasting the Map\r\n- [x] ~Compression is AUTO right now which may compromise performance~ We are now using SNAPPY\r\n- [ ] Improve PCBS CPU read performance. It's currently slower than the DefaultCachedBatchSerializer",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1143/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1143/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}