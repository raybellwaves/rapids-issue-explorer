{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10488",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10488/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10488/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10488/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10488",
    "id": 2151358558,
    "node_id": "I_kwDOD7z77c6AOyBe",
    "number": 10488,
    "title": "[FEA] Understand why we were able to parse a timestamp correctly for `America/Los_Angeles` when all we support is UTC. ",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735884,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODg0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/feature%20request",
            "name": "feature request",
            "color": "a2eeef",
            "default": false,
            "description": "New feature or request"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2024-02-23T15:52:24Z",
    "updated_at": "2024-02-27T22:21:33Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\nThis is really odd to me.  I have a test that is still a WIP.\r\n\r\n```\r\n@pytest.mark.parametrize('zone_id', [\r\n    \"UTC\",\r\n    pytest.param(\"-08:00\",marks=pytest.mark.xfail(reason='https://github.com/NVIDIA/spark-rapids/issues/10485')),\r\n    pytest.param(\"+01:00\",marks=pytest.mark.xfail(reason='https://github.com/NVIDIA/spark-rapids/issues/10485')),\r\n    pytest.param(\"Africa/Dakar\",marks=pytest.mark.xfail(reason='https://github.com/NVIDIA/spark-rapids/issues/10485')),\r\n    \"America/Los_Angeles\", # technically this is passing for this test, but it should not be the same as UTC\r\n    pytest.param(\"Asia/Urumqi\",marks=pytest.mark.xfail(reason='https://github.com/NVIDIA/spark-rapids/issues/10485')),\r\n    pytest.param(\"Asia/Hong_Kong\",marks=pytest.mark.xfail(reason='https://github.com/NVIDIA/spark-rapids/issues/10485')),\r\n    pytest.param(\"Europe/Brussels\",marks=pytest.mark.xfail(reason='https://github.com/NVIDIA/spark-rapids/issues/10485'))], ids=idfn)\r\n@allow_non_gpu(*non_utc_allow)\r\ndef test_spark_from_json_timestamp_format_option_zoneid_but_default_format(zone_id):\r\n    schema = StructType([StructField(\"t\", TimestampType())])\r\n    data = [[r'''{\"t\": \"2016-01-01 00:00:00\"}'''],\r\n        [r'''{\"t\": \"2023-07-27 12:21:05\"}''']]\r\n    assert_gpu_and_cpu_are_equal_collect(\r\n            lambda spark : spark.createDataFrame(data, 'json STRING').select(f.col('json'), f.from_json(f.col('json'), schema, {'timeZone': zone_id})),\r\n        conf = { 'spark.rapids.sql.expression.JsonToStructs': True })\r\n\r\n```\r\n\r\nIt lest you set the timezone for from_json which is used to parse timestamps.  But when I set the timezone to \"America/Los_Angeles\" it works correctly and I don't know why. It shouldn't. It has DST rules that are ongoing.\r\n\r\n```\r\nscala> import java.time.ZoneId\r\nimport java.time.ZoneId\r\n\r\nscala> val al = ZoneId.of(\"America/Los_Angeles\").normalized\r\nal: java.time.ZoneId = America/Los_Angeles\r\n\r\nscala> al.getRules.getTransitions\r\nres1: java.util.List[java.time.zone.ZoneOffsetTransition] = [Transition[Overlap at 1883-11-18T12:07:02-07:52:58 to -08:00], Transition[Gap at 1918-03-31T02:00-08:00 to -07:00], Transition[Overlap at 1918-10-27T02:00-07:00 to -08:00], Transition[Gap at 1919-03-30T02:00-08:00 to -07:00], Transition[Overlap at 1919-10-26T02:00-07:00 to -08:00], Transition[Gap at 1942-02-09T02:00-08:00 to -07:00], Transition[Overlap at 1945-09-30T02:00-07:00 to -08:00], Transition[Gap at 1948-03-14T02:01-08:00 to -07:00], Transition[Overlap at 1949-01-01T02:00-07:00 to -08:00], Transition[Gap at 1950-04-30T01:00-08:00 to -07:00], Transition[Overlap at 1950-09-24T02:00-07:00 to -08:00], Transition[Gap at 1951-04-29T01:00-08:00 to -07:00], Transition[Overlap at 1951-09-30T02:00-07:00...\r\n\r\nscala> al.getRules.getTransitionRules\r\nres2: java.util.List[java.time.zone.ZoneOffsetTransitionRule] = [TransitionRule[Gap -08:00 to -07:00, SUNDAY on or after MARCH 8 at 02:00 WALL, standard offset -08:00], TransitionRule[Overlap -07:00 to -08:00, SUNDAY on or after NOVEMBER 1 at 02:00 WALL, standard offset -08:00]]\r\n```\r\n\r\nWe should not be producing the right answer. More likely Spark is producing the wrong answer somehow.\r\n\r\nhttps://github.com/apache/spark/blob/e6a3385e27fa95391433ea02fa053540fe101d40/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/JsonExpressionsSuite.scala#L529-L571\r\n\r\nis the test that this is based off of. I hope that I am wrong and everything is working fine, but it looks really odd to me.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10488/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10488/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}