{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10561",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10561/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10561/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10561/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10561",
    "id": 2174073325,
    "node_id": "I_kwDOD7z77c6Blbnt",
    "number": 10561,
    "title": "[FEA] Have GpuHashAggregate check for columns that are all nulls and skip some computation",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2094500742,
            "node_id": "MDU6TGFiZWwyMDk0NTAwNzQy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/performance",
            "name": "performance",
            "color": "d845b1",
            "default": false,
            "description": "A performance related task/issue"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2024-03-07T15:03:46Z",
    "updated_at": "2024-03-07T20:04:38Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\nWhen doing multiple distinct aggregations Spark will implement this with an ExpandExec followed by two Aggregation passes. This is to separate out the distinct aggregations from the non-distinct aggregations, and then combine the results back together afterwards.  As a part of this ExpandExec ends up inserting in a lot of null columns into the batches.  Because these are fed directly into the aggregation, it would be really great if we could dynamically detect which columns are all nulls in an aggregation and just not do the aggregation at all for those columns. So like if we are doing a count on a column where there are only nulls in the batch, we don't do the count at all, we just insert in a column of zeros after doing the other aggregations, or whatever it is that Spark would have put in.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10561/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10561/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}