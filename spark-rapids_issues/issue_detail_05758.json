{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5758",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5758/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5758/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5758/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/5758",
    "id": 1262519269,
    "node_id": "I_kwDOD7z77c5LQIPl",
    "number": 5758,
    "title": "[BUG] NoClassDefFoundError for spark-avro when the Plugin is deployed via extraClassPath/driver-class-path",
    "user": {
        "login": "gerashegalov",
        "id": 3187938,
        "node_id": "MDQ6VXNlcjMxODc5Mzg=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3187938?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/gerashegalov",
        "html_url": "https://github.com/gerashegalov",
        "followers_url": "https://api.github.com/users/gerashegalov/followers",
        "following_url": "https://api.github.com/users/gerashegalov/following{/other_user}",
        "gists_url": "https://api.github.com/users/gerashegalov/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/gerashegalov/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/gerashegalov/subscriptions",
        "organizations_url": "https://api.github.com/users/gerashegalov/orgs",
        "repos_url": "https://api.github.com/users/gerashegalov/repos",
        "events_url": "https://api.github.com/users/gerashegalov/events{/privacy}",
        "received_events_url": "https://api.github.com/users/gerashegalov/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        },
        {
            "id": 4029093938,
            "node_id": "LA_kwDOD7z77c7wJxgy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/reliability",
            "name": "reliability",
            "color": "2654AF",
            "default": false,
            "description": "Features to improve reliability or bugs that severly impact the reliability of the plugin"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 1,
    "created_at": "2022-06-06T22:58:35Z",
    "updated_at": "2023-08-30T20:30:18Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nPlugin crashes with `java.lang.NoClassDefFoundError: org/apache/spark/sql/v2/avro/AvroScan` when the Plugin jar(s) are deployed using extraClassPath instead of `--jars` or `--packages` Spark submit options \r\n\r\n**Steps/Code to reproduce bug**\r\nInvoke pyspark with `--driver-class-path`:\r\n```bash\r\npyspark --driver-class-path dist/target/rapids-4-spark_2.12-22.08.0-SNAPSHOT-cuda11.jar \\\r\n  --packages org.apache.spark:spark-avro_2.12:3.2.1 \\\r\n  --conf spark.rapids.sql.enabled=true \\\r\n  --conf spark.plugins=com.nvidia.spark.SQLPlugin\r\n\r\n22/06/06 15:56:02 ERROR RapidsExecutorPlugin: Exception in the executor plugin, shutting down!\r\njava.lang.BootstrapMethodError: java.lang.NoClassDefFoundError: org/apache/spark/sql/v2/avro/AvroScan\r\n        at org.apache.spark.sql.rapids.ExternalSource$.getScans(ExternalSource.scala:128)\r\n        at com.nvidia.spark.rapids.GpuOverrides$.<init>(GpuOverrides.scala:3555)\r\n        at com.nvidia.spark.rapids.GpuOverrides$.<clinit>(GpuOverrides.scala)\r\n        at com.nvidia.spark.rapids.TypeChecks$.areTimestampsSupported(TypeChecks.scala:797)\r\n        at com.nvidia.spark.rapids.RapidsExecutorPlugin.init(Plugin.scala:218)\r\n        at org.apache.spark.internal.plugin.ExecutorPluginContainer.$anonfun$executorPlugins$1(PluginContainer.scala:125)\r\n        at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)\r\n        at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n        at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n        at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)\r\n        at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)\r\n        at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)\r\n        at org.apache.spark.internal.plugin.ExecutorPluginContainer.<init>(PluginContainer.scala:113)\r\n        at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:211)\r\n        at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:199)\r\n        at org.apache.spark.executor.Executor.$anonfun$plugins$1(Executor.scala:253)\r\n        at org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:231)\r\n        at org.apache.spark.executor.Executor.<init>(Executor.scala:253)\r\n        at org.apache.spark.scheduler.local.LocalEndpoint.<init>(LocalSchedulerBackend.scala:64)\r\n        at org.apache.spark.scheduler.local.LocalSchedulerBackend.start(LocalSchedulerBackend.scala:132)\r\n        at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:220)\r\n        at org.apache.spark.SparkContext.<init>(SparkContext.scala:581)\r\n        at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\r\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\r\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n        at py4j.Gateway.invoke(Gateway.java:238)\r\n        at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n        at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n        at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n        at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.NoClassDefFoundError: org/apache/spark/sql/v2/avro/AvroScan\r\n        ... 36 more\r\nCaused by: java.lang.ClassNotFoundException: org.apache.spark.sql.v2.avro.AvroScan\r\n        at java.net.URLClassLoader.findClass(URLClassLoader.java:387)\r\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:418)\r\n        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)\r\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:351)\r\n        ... 36 more\r\n```\r\n\r\n**Expected behavior**\r\nShould work just like `--jars`\r\n```bash\r\npyspark --jars dist/target/rapids-4-spark_2.12-22.08.0-SNAPSHOT-cuda11.jar \\\r\n  --packages org.apache.spark:spark-avro_2.12:3.2.1 \\ \r\n  --conf spark.rapids.sql.enabled=true \\\r\n  --conf spark.plugins=com.nvidia.spark.SQLPlugin \r\n```\r\nwhich loads the Plugin and Avro correctly\r\n\r\n**Environment details (please complete the following information)**\r\nany\r\n\r\n**Additional context**\r\nN/A",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5758/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/5758/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}