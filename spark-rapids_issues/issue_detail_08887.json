{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8887",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8887/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8887/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8887/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/8887",
    "id": 1829953325,
    "node_id": "I_kwDOD7z77c5tEt8t",
    "number": 8887,
    "title": "[FEA] Add Host Memory Retry for Row to Columnar Conversion",
    "user": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2586576266,
            "node_id": "MDU6TGFiZWwyNTg2NTc2MjY2",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/task",
            "name": "task",
            "color": "65abf7",
            "default": false,
            "description": "Work required that improves the product but is not user facing"
        },
        {
            "id": 4029093938,
            "node_id": "LA_kwDOD7z77c7wJxgy",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/reliability",
            "name": "reliability",
            "color": "2654AF",
            "default": false,
            "description": "Features to improve reliability or bugs that severly impact the reliability of the plugin"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": {
        "login": "jlowe",
        "id": 1360766,
        "node_id": "MDQ6VXNlcjEzNjA3NjY=",
        "avatar_url": "https://avatars.githubusercontent.com/u/1360766?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jlowe",
        "html_url": "https://github.com/jlowe",
        "followers_url": "https://api.github.com/users/jlowe/followers",
        "following_url": "https://api.github.com/users/jlowe/following{/other_user}",
        "gists_url": "https://api.github.com/users/jlowe/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/jlowe/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/jlowe/subscriptions",
        "organizations_url": "https://api.github.com/users/jlowe/orgs",
        "repos_url": "https://api.github.com/users/jlowe/repos",
        "events_url": "https://api.github.com/users/jlowe/events{/privacy}",
        "received_events_url": "https://api.github.com/users/jlowe/received_events",
        "type": "User",
        "site_admin": false
    },
    "assignees": [
        {
            "login": "jlowe",
            "id": 1360766,
            "node_id": "MDQ6VXNlcjEzNjA3NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1360766?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jlowe",
            "html_url": "https://github.com/jlowe",
            "followers_url": "https://api.github.com/users/jlowe/followers",
            "following_url": "https://api.github.com/users/jlowe/following{/other_user}",
            "gists_url": "https://api.github.com/users/jlowe/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jlowe/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jlowe/subscriptions",
            "organizations_url": "https://api.github.com/users/jlowe/orgs",
            "repos_url": "https://api.github.com/users/jlowe/repos",
            "events_url": "https://api.github.com/users/jlowe/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jlowe/received_events",
            "type": "User",
            "site_admin": false
        }
    ],
    "milestone": null,
    "comments": 5,
    "created_at": "2023-07-31T20:16:50Z",
    "updated_at": "2024-04-22T16:57:19Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Is your feature request related to a problem? Please describe.**\r\nThis gets to be a little difficult. We have two different implementations that we need to update to deal with this.  `GeneratedInternalRowToCudfRowIterator` and `RowToColumnarIterator`.\r\n\r\nhttps://github.com/NVIDIA/spark-rapids/issues/9862 will add in limits to the host memory being allocated, but we still need to make sure that the allocations can be retried if needed.\r\n\r\nThe generated version uses code gen to put the data into a buffer with a given format, and then uses the GPU to transform that data into a Table on the GPU.  This is relatively simple to deal with because we know how big of a buffer we are going to allocate, and we already have switching the buffer around/allocating new ones/etc in place. So just switching this over to use the new allocation APIs in a blocking allocation is almost good enough. We just have to make sure that we can have the buffer(s) we allocated be spillable after we are done inserting in a new row. This is where having a mutable buffer would be nice. We also need to make sure that we have ways to deal with a single really large row. But in general not too bad. \r\n\r\nIt also looks fairly simple to make the batch smaller so that we could chunk them, and then pass multiple of these batches down to the kernel so we are not holding onto too much non-spillable CPU memory at a time.\r\n\r\nBut the other one that is the slow way. That is much harder because we need a way to limit the host memory and still follow the rules where we would not do a blocking allocation of host memory while holding on to non-spillable buffers. This is especially hard because all of the buffers that we want to work with are in the CUDF java APIs.\r\n\r\nThe problem here is that there is just a lot of coupling between the different parts of the code, and it might be simpler to just copy a lot of the HostColumnVector.ColumnBuilder code out into the plugin for the short term until we can understand exactly how to do this. Then we can move it back if we have clean and generic APIs.  Right now we create a `GpuColumnarBatchBuilder` inside of the plugin with an estimate of the number of rows we want for that table. The buffers are allocated lazily and can grow at any point in time. There just is no good way for us to say that you can do an initial allocation, and it should look this particular way, but don't grow the data, and if you have to stop part way through a row, then we need to make sure that we roll back anything that was partially written for that row so far. Oh and we have to make the buffers spillable in between each call to next to get another row.\r\n\r\nI think what we want to do is to allocate one host memory buffer that is close to a target batch size (possibly smaller if we want to chunk it). We can then slice the buffer up into smaller buffers that would correspond to the estimated size we expect per buffer. The initial guess would come from just the schema, but future guesses could come based off of where we know that we made mistakes in earlier estimates. We would then start to populate these buffers with data, but that update would happen in a two phase commit.  The first pass would copy the data into the buffers, if there is room, and keep track of which buffers didn't have enough room. If all of the buffers had enough room, then we would commit the result and go on to the next row. If any of them didn't have enough room, we would not commit the result. We would update any stats we wanted for a better allocation next time, and process what we have, assuming that there is enough memory for at least a single row.",
    "closed_by": {
        "login": "jbrennan333",
        "id": 69316431,
        "node_id": "MDQ6VXNlcjY5MzE2NDMx",
        "avatar_url": "https://avatars.githubusercontent.com/u/69316431?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/jbrennan333",
        "html_url": "https://github.com/jbrennan333",
        "followers_url": "https://api.github.com/users/jbrennan333/followers",
        "following_url": "https://api.github.com/users/jbrennan333/following{/other_user}",
        "gists_url": "https://api.github.com/users/jbrennan333/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/jbrennan333/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/jbrennan333/subscriptions",
        "organizations_url": "https://api.github.com/users/jbrennan333/orgs",
        "repos_url": "https://api.github.com/users/jbrennan333/repos",
        "events_url": "https://api.github.com/users/jbrennan333/events{/privacy}",
        "received_events_url": "https://api.github.com/users/jbrennan333/received_events",
        "type": "User",
        "site_admin": false
    },
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8887/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/8887/timeline",
    "performed_via_github_app": null,
    "state_reason": "reopened"
}