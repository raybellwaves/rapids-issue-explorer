{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1752",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1752/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1752/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1752/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/1752",
    "id": 811136375,
    "node_id": "MDU6SXNzdWU4MTExMzYzNzU=",
    "number": 1752,
    "title": "[BUG] Spark 3.1.1 integration build using old build - how do we handle when Spark starts rc's",
    "user": {
        "login": "tgravescs",
        "id": 4563792,
        "node_id": "MDQ6VXNlcjQ1NjM3OTI=",
        "avatar_url": "https://avatars.githubusercontent.com/u/4563792?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/tgravescs",
        "html_url": "https://github.com/tgravescs",
        "followers_url": "https://api.github.com/users/tgravescs/followers",
        "following_url": "https://api.github.com/users/tgravescs/following{/other_user}",
        "gists_url": "https://api.github.com/users/tgravescs/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/tgravescs/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/tgravescs/subscriptions",
        "organizations_url": "https://api.github.com/users/tgravescs/orgs",
        "repos_url": "https://api.github.com/users/tgravescs/repos",
        "events_url": "https://api.github.com/users/tgravescs/events{/privacy}",
        "received_events_url": "https://api.github.com/users/tgravescs/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735874,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODc0",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/bug",
            "name": "bug",
            "color": "d73a4a",
            "default": true,
            "description": "Something isn't working"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2021-02-18T14:12:38Z",
    "updated_at": "2021-02-23T21:58:24Z",
    "closed_at": null,
    "author_association": "COLLABORATOR",
    "active_lock_reason": null,
    "body": "**Describe the bug**\r\nWhen Spark starts to take a vote on a release, the CI ends up possibly using an out of date version due to the way Spark changes version numbers creates a release and then changes the version number to next version again.  so if they do multiple RC's many times we don't build a jar to match.  Perhaps we should just start pushing the rc tarballs to urm or we need to pick up the tag (https://github.com/apache/spark/tree/v3.1.1-rc2)\r\n\r\nWe his this with spark 3.1.1 where we were trying to pull in a fix they put into an rc but we didn't have a jar to match.",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1752/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/1752/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}