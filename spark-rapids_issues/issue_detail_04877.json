{
    "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/4877",
    "repository_url": "https://api.github.com/repos/NVIDIA/spark-rapids",
    "labels_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/4877/labels{/name}",
    "comments_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/4877/comments",
    "events_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/4877/events",
    "html_url": "https://github.com/NVIDIA/spark-rapids/issues/4877",
    "id": 1154076641,
    "node_id": "I_kwDOD7z77c5Eyc_h",
    "number": 4877,
    "title": "The improvement of GPU execution efficiency encounters a bottleneck \uff1f ",
    "user": {
        "login": "YeahNew",
        "id": 33194373,
        "node_id": "MDQ6VXNlcjMzMTk0Mzcz",
        "avatar_url": "https://avatars.githubusercontent.com/u/33194373?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/YeahNew",
        "html_url": "https://github.com/YeahNew",
        "followers_url": "https://api.github.com/users/YeahNew/followers",
        "following_url": "https://api.github.com/users/YeahNew/following{/other_user}",
        "gists_url": "https://api.github.com/users/YeahNew/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/YeahNew/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/YeahNew/subscriptions",
        "organizations_url": "https://api.github.com/users/YeahNew/orgs",
        "repos_url": "https://api.github.com/users/YeahNew/repos",
        "events_url": "https://api.github.com/users/YeahNew/events{/privacy}",
        "received_events_url": "https://api.github.com/users/YeahNew/received_events",
        "type": "User",
        "site_admin": false
    },
    "labels": [
        {
            "id": 2061735893,
            "node_id": "MDU6TGFiZWwyMDYxNzM1ODkz",
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/labels/question",
            "name": "question",
            "color": "d876e3",
            "default": true,
            "description": "Further information is requested"
        }
    ],
    "state": "open",
    "locked": false,
    "assignee": {
        "login": "revans2",
        "id": 3441321,
        "node_id": "MDQ6VXNlcjM0NDEzMjE=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/revans2",
        "html_url": "https://github.com/revans2",
        "followers_url": "https://api.github.com/users/revans2/followers",
        "following_url": "https://api.github.com/users/revans2/following{/other_user}",
        "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
        "organizations_url": "https://api.github.com/users/revans2/orgs",
        "repos_url": "https://api.github.com/users/revans2/repos",
        "events_url": "https://api.github.com/users/revans2/events{/privacy}",
        "received_events_url": "https://api.github.com/users/revans2/received_events",
        "type": "User",
        "site_admin": false
    },
    "assignees": [
        {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        }
    ],
    "milestone": null,
    "comments": 5,
    "created_at": "2022-02-28T13:12:55Z",
    "updated_at": "2022-03-02T15:29:57Z",
    "closed_at": null,
    "author_association": "NONE",
    "active_lock_reason": null,
    "body": "Hello,\r\n    I recently used spark3.2 +GPU to do a test based on the TPC-DS dataset, and the entire TPC-DS data scale is 1TB(located in HDFS). But I encountered a problem that I couldn't understand, and I hope to get your help.\r\n    The SQL statement tested is as follows:\r\n    select count(*) from (select c_last_name from store_sales, customer where store_sales.ss_customer_sk = customer.c_customer_sk) hot_cust limit 100;\r\n\r\nTwo tables are used here, and their sizes are: store_sales(387.97GB),customer(1.52GB)\r\n\r\nWhen submitting the application, the driver and executor parameters are set as follows:\r\nDRIVER_OPTIONS=\"--master spark://10.42.101.70:7078 --jars ${CUDF_JAR},${RAPIDS_JAR} \\ \r\n--conf spark.executor.extraClassPath=${CUDF_JAR},${RAPIDS_JAR} \\\r\n--conf spark.driver.extraClassPath=${CUDF_JAR},${RAPIDS_JAR} \\\r\n--conf spark.plugins=com.nvidia.spark.SQLPlugin \\\r\n--conf spark.rapids.sql.incompatibleOps.enabled=true \\\r\n--conf spark.rapids.memory.gpu.pooling.enabled=true \\\r\n--conf spark.shuffle.service.enabled=false \\\r\n--conf spark.rapids.shuffle.transport.enabled=true \\\r\n--conf spark.rapids.shuffle.manager.enabled=true \\\r\n--conf spark.executor.resource.gpu.amount=1 \\\r\n--conf spark.rapids.memory.gpu.allocFraction=0.9 \\\r\n--conf spark.rapids.shuffle.transport.enabled=true \\\r\n--conf spark.rapids.sql.enabled=true \\\r\n--conf spark.rapids.sql.concurrentGpuTasks=4 \\\r\n--conf spark.task.resource.gpu.amount=0.125 \\\r\n--conf spark.driver.maxResultSize=60g \\\r\n--conf spark.locality.wait=0s \\\r\n--conf spark.rapids.sql.hasNans=true \\\r\n--conf spark.executor.extraJavaOptions=\"-Dai.rapids.cudf.prefer-pinned=true\" \\ \r\n--total-executor-cores 24 \\\r\n--driver-memory 50g \\\r\n--conf spark.default.parallelism=30 \\\r\n--conf spark.sql.adaptive.enabled=false \\\r\n--driver-java-options -Dlog4j.configuration=file:///${OUTPUT_DIR}/log4j.properties\"\r\n\r\nEXECUTOR_OPTIONS=\"--executor-cores 8 \\\r\n--conf spark.executor.memory=50g \\\r\n--conf spark.task.cpus=1 \\\r\n--conf spark.sql.shuffle.partitions=30 \\\r\n--conf spark.executor.extraJavaOptions=-Dlog4j.configuration=file:///${OUTPUT_DIR}/log4j.properties \\\r\n--conf spark.sql.crossJoin.enabled=true\"\r\n\r\nThe Spark cluster is built on a physical node with only one worker, and the submitted tasks are in StandAlone mode. A total of 56 cores, 376GB of memory. I kept executor-num=3 unchanged (that is, the total executors remained unchanged), and adjusted executor-cores=2, 4, 8, 12,16. The corresponding application time was: 78s, 57s, 46s, 49s,50s. It was found that the total- executor-cores >=24, the time-consuming is almost unchanged. \r\n\r\nI monitored CPU utilization, IO, and found no bottlenecks. Then I analyzed the task avg time in the longest stage of each application in the spark web UI interface(The longest time-consuming stage in the five test cases are stage2 and stage3). The average time of tasks has been increasing .As shown in the table.\r\n![\u56fe\u7247](https://user-images.githubusercontent.com/33194373/155986351-d3ea73e3-e3ba-438f-a8b7-a12bbae35b35.png)\r\nFrom the table results, when the number of cpu cores increases to a certain level, the execution efficiency hardly increases, and there will be a decline. What is the reason? \r\nUnder the same number of cores, it is found that the execution time of using GPU is about half of that of using CPU (other parameters remain unchanged, just set whether to start GPU). With GPU-accelerated sql, the execution performance doesn't seem to improve significantly\uff08total-executor-cores=48,  CPU:96.6s----->GPU:48.3s).\r\nIs it related to file size and data distribution? \r\n\r\nstage2 picture:\r\n![\u56fe\u7247](https://user-images.githubusercontent.com/33194373/155988928-61f41057-0655-404f-9128-30a702754fb7.png)\r\nstage3 picture:\r\n![\u56fe\u7247](https://user-images.githubusercontent.com/33194373/155989023-985e6992-a19f-4f5c-baf5-6c707c8e5605.png)\r\n\r\nLooking forward to your reply.\r\n\r\n",
    "closed_by": null,
    "reactions": {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/4877/reactions",
        "total_count": 0,
        "+1": 0,
        "-1": 0,
        "laugh": 0,
        "hooray": 0,
        "confused": 0,
        "heart": 0,
        "rocket": 0,
        "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/4877/timeline",
    "performed_via_github_app": null,
    "state_reason": null
}