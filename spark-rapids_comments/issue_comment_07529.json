[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1387704224",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7529#issuecomment-1387704224",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7529",
        "id": 1387704224,
        "node_id": "IC_kwDOD7z77c5Stq-g",
        "user": {
            "login": "jlowe",
            "id": 1360766,
            "node_id": "MDQ6VXNlcjEzNjA3NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1360766?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jlowe",
            "html_url": "https://github.com/jlowe",
            "followers_url": "https://api.github.com/users/jlowe/followers",
            "following_url": "https://api.github.com/users/jlowe/following{/other_user}",
            "gists_url": "https://api.github.com/users/jlowe/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jlowe/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jlowe/subscriptions",
            "organizations_url": "https://api.github.com/users/jlowe/orgs",
            "repos_url": "https://api.github.com/users/jlowe/repos",
            "events_url": "https://api.github.com/users/jlowe/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jlowe/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-18T20:03:42Z",
        "updated_at": "2023-01-18T20:03:42Z",
        "author_association": "MEMBER",
        "body": "@revans2 have you taken an Nsight Systems trace of this case?  Curious if it's primarily a problem with building the hash table vs. probing it via the stream table (or both).  My guess is we're getting killed by the thread collisions on the same key when trying to build the hash table, and it's not so much an issue when we probe it later.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1387704224/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1387713922",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7529#issuecomment-1387713922",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7529",
        "id": 1387713922,
        "node_id": "IC_kwDOD7z77c5SttWC",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-18T20:11:02Z",
        "updated_at": "2023-01-18T20:11:02Z",
        "author_association": "COLLABORATOR",
        "body": "I stopped at finding the issue. I had already spent enough time on this that I wanted to stop and check in on the priority for next steps.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1387713922/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1397424442",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7529#issuecomment-1397424442",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7529",
        "id": 1397424442,
        "node_id": "IC_kwDOD7z77c5TSwE6",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-19T18:25:38Z",
        "updated_at": "2023-01-19T18:25:38Z",
        "author_association": "COLLABORATOR",
        "body": "Okay, I think this is really just us doing a very bad job a join output estimation. The join output estimation code looks at the build side of the table and guesses at a row multiplication factor based off of the average key count. In this case we have a build side with a relatively low cardinality and lots fo duplication. The estimate ends up being about 20,000 for anything that has a build table.  The stream side has a lot of values that are not in the build table. So the average size increase is actually 210, not 20,000. \r\n\r\nSo the more we end up partitioning the input the more likely it is that we end up with an accurate estimate. In many cases the estimation is 0 because there is no build table. In the other cases we have less keys on the stream side that don't match anything.\r\n\r\nI don't think that this is likely to happen in reality, but it could. The only real way to fix this is to have better join estimation that takes into account the stream table too.  We can probably do that if we had some kind of bloom filter in place that would be really nice to look into, and hopefully not too difficult to implement. ",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1397424442/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1397430915",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7529#issuecomment-1397430915",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7529",
        "id": 1397430915,
        "node_id": "IC_kwDOD7z77c5TSxqD",
        "user": {
            "login": "jlowe",
            "id": 1360766,
            "node_id": "MDQ6VXNlcjEzNjA3NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1360766?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jlowe",
            "html_url": "https://github.com/jlowe",
            "followers_url": "https://api.github.com/users/jlowe/followers",
            "following_url": "https://api.github.com/users/jlowe/following{/other_user}",
            "gists_url": "https://api.github.com/users/jlowe/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jlowe/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jlowe/subscriptions",
            "organizations_url": "https://api.github.com/users/jlowe/orgs",
            "repos_url": "https://api.github.com/users/jlowe/repos",
            "events_url": "https://api.github.com/users/jlowe/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jlowe/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-19T18:31:37Z",
        "updated_at": "2023-01-19T18:31:37Z",
        "author_association": "MEMBER",
        "body": "I assume another alternative is to finally solve #2440 where we can get the join output size \"for free\" in most cases but find a way to mitigate the performance pitfalls we ran into there.  IIRC the biggest issue with the last attempt was needing to throw away the built hash table when we decided to split the table we used to build that hash table (e.g.: inner join where we can freely pick).  Join code doesn't currently support splitting what was declared the build side, but the libcudf join algorithm is slower if we don't always pick the smaller table as the build table.  Thus, if the stream batch is smaller than the build batch, we should split the build batch but currently the code isn't prepped to handle that.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1397430915/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1397434937",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7529#issuecomment-1397434937",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7529",
        "id": 1397434937,
        "node_id": "IC_kwDOD7z77c5TSyo5",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-19T18:35:30Z",
        "updated_at": "2023-01-19T18:35:30Z",
        "author_association": "COLLABORATOR",
        "body": "Yes, but how much slower is it to always have the build side be the build side in CUDF? And can we use AQE or something to dynamically switch the build side so we know which one is truly smaller? I think there are ways to fix those issues too.  We might want to have a JOIN optimization epic of some sort where we come up with a plan on how to avoid some of these pitfalls.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1397434937/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1397438542",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7529#issuecomment-1397438542",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7529",
        "id": 1397438542,
        "node_id": "IC_kwDOD7z77c5TSzhO",
        "user": {
            "login": "jlowe",
            "id": 1360766,
            "node_id": "MDQ6VXNlcjEzNjA3NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1360766?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jlowe",
            "html_url": "https://github.com/jlowe",
            "followers_url": "https://api.github.com/users/jlowe/followers",
            "following_url": "https://api.github.com/users/jlowe/following{/other_user}",
            "gists_url": "https://api.github.com/users/jlowe/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jlowe/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jlowe/subscriptions",
            "organizations_url": "https://api.github.com/users/jlowe/orgs",
            "repos_url": "https://api.github.com/users/jlowe/repos",
            "events_url": "https://api.github.com/users/jlowe/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jlowe/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-19T18:39:00Z",
        "updated_at": "2023-01-19T18:39:00Z",
        "author_association": "MEMBER",
        "body": "> Yes, but how much slower is it to always have the build side be the build side in CUDF? \r\n\r\nSlow enough that we didn't check in the first PR attempt because benchmarks showed the guesstimate was faster than the \"for free\" approach.  The biggest issue there is that we don't have a way to make the built hash table spillable, so we can't save it across batches.  If we could not have to rebuild the hash table for every batch, that could be a big win.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1397438542/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1397453409",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7529#issuecomment-1397453409",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7529",
        "id": 1397453409,
        "node_id": "IC_kwDOD7z77c5TS3Jh",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-19T18:53:23Z",
        "updated_at": "2023-01-19T18:53:23Z",
        "author_association": "COLLABORATOR",
        "body": "> If we could not have to rebuild the hash table for every batch, that could be a big win.\r\n\r\nExactly that is what I thought the slowness was. That picking the wrong side was slightly slower in most cases, but in a few it was rather bad. But we were not able to offset the slowness because we had to rebuild the has table each time. I would love to see us resurrect that code and see what happens if we just keep the hash table around.  Just for an experiment to see if it is worth spending the time to make the hash table spillable.  If it is a huge win, then it might be worth it. ",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1397453409/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2138135160",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7529#issuecomment-2138135160",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7529",
        "id": 2138135160,
        "node_id": "IC_kwDOD7z77c5_cVp4",
        "user": {
            "login": "PointKernel",
            "id": 12716979,
            "node_id": "MDQ6VXNlcjEyNzE2OTc5",
            "avatar_url": "https://avatars.githubusercontent.com/u/12716979?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PointKernel",
            "html_url": "https://github.com/PointKernel",
            "followers_url": "https://api.github.com/users/PointKernel/followers",
            "following_url": "https://api.github.com/users/PointKernel/following{/other_user}",
            "gists_url": "https://api.github.com/users/PointKernel/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PointKernel/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PointKernel/subscriptions",
            "organizations_url": "https://api.github.com/users/PointKernel/orgs",
            "repos_url": "https://api.github.com/users/PointKernel/repos",
            "events_url": "https://api.github.com/users/PointKernel/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PointKernel/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-05-29T19:39:05Z",
        "updated_at": "2024-05-29T19:39:05Z",
        "author_association": "MEMBER",
        "body": "We are about to close the related cudf issue (https://github.com/rapidsai/cudf/issues/14948) and want to ensure we understand the performance regression described here properly.\r\n\r\nGoing through the above discussions, it seems that #2440 can help solve the problem and no actions are needed on the libcudf side, did I miss something?",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2138135160/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2138241322",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7529#issuecomment-2138241322",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7529",
        "id": 2138241322,
        "node_id": "IC_kwDOD7z77c5_cvkq",
        "user": {
            "login": "jlowe",
            "id": 1360766,
            "node_id": "MDQ6VXNlcjEzNjA3NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1360766?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jlowe",
            "html_url": "https://github.com/jlowe",
            "followers_url": "https://api.github.com/users/jlowe/followers",
            "following_url": "https://api.github.com/users/jlowe/following{/other_user}",
            "gists_url": "https://api.github.com/users/jlowe/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jlowe/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jlowe/subscriptions",
            "organizations_url": "https://api.github.com/users/jlowe/orgs",
            "repos_url": "https://api.github.com/users/jlowe/repos",
            "events_url": "https://api.github.com/users/jlowe/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jlowe/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-05-29T20:50:43Z",
        "updated_at": "2024-05-29T20:50:43Z",
        "author_association": "MEMBER",
        "body": "@PointKernel rapidsai/cudf#14948 doesn't seem to be related?  I'm assuming this is in reference to rapidsai/cudf#15262.  If so, curious why the latter is going to be closed?  It's not clear to me how optimizations around distinct joins apply to this problem where the issue is about low cardinality, highly duplicated build-side keys that have many collisions and potentially long chain walking when building the hash table.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2138241322/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2138286065",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7529#issuecomment-2138286065",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7529",
        "id": 2138286065,
        "node_id": "IC_kwDOD7z77c5_c6fx",
        "user": {
            "login": "PointKernel",
            "id": 12716979,
            "node_id": "MDQ6VXNlcjEyNzE2OTc5",
            "avatar_url": "https://avatars.githubusercontent.com/u/12716979?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PointKernel",
            "html_url": "https://github.com/PointKernel",
            "followers_url": "https://api.github.com/users/PointKernel/followers",
            "following_url": "https://api.github.com/users/PointKernel/following{/other_user}",
            "gists_url": "https://api.github.com/users/PointKernel/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PointKernel/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PointKernel/subscriptions",
            "organizations_url": "https://api.github.com/users/PointKernel/orgs",
            "repos_url": "https://api.github.com/users/PointKernel/repos",
            "events_url": "https://api.github.com/users/PointKernel/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PointKernel/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-05-29T21:22:41Z",
        "updated_at": "2024-05-29T21:22:41Z",
        "author_association": "MEMBER",
        "body": "I see, https://github.com/rapidsai/cudf/issues/14948 is indeed unrelated then. https://github.com/rapidsai/cudf/issues/15262 probably describes another problem as well since it's for low cardinality groupby IIUC.\r\n\r\n>  the issue is about low cardinality, highly duplicated build-side keys that have many collisions and potentially long chain walking when building the hash table\r\n\r\nTuning CG size can help in this case https://github.com/rapidsai/cudf/blob/9192d259633c382c6f98f956dc7f43d754ebbf44/cpp/include/cudf/detail/join.hpp#L46. Using a larger CG size like 4, 8 or 16 instead of 2 can help with high-multiplicity cases. Is it easy for you to test the performance impact of larger CG sizes? If it's proved to be effective, libcudf can expose CG size in public APIs to make your tuning work easier.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2138286065/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2138306017",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7529#issuecomment-2138306017",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7529",
        "id": 2138306017,
        "node_id": "IC_kwDOD7z77c5_c_Xh",
        "user": {
            "login": "jlowe",
            "id": 1360766,
            "node_id": "MDQ6VXNlcjEzNjA3NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1360766?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jlowe",
            "html_url": "https://github.com/jlowe",
            "followers_url": "https://api.github.com/users/jlowe/followers",
            "following_url": "https://api.github.com/users/jlowe/following{/other_user}",
            "gists_url": "https://api.github.com/users/jlowe/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jlowe/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jlowe/subscriptions",
            "organizations_url": "https://api.github.com/users/jlowe/orgs",
            "repos_url": "https://api.github.com/users/jlowe/repos",
            "events_url": "https://api.github.com/users/jlowe/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jlowe/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-05-29T21:38:36Z",
        "updated_at": "2024-05-29T21:38:36Z",
        "author_association": "MEMBER",
        "body": "@PointKernel thanks for the pointers.  Can you comment on rapidsai/cudf#15262?  That's the issue tracking the poor performance of highly duplicated build-side keys when building hash tables.  I know it's talking about aggregations, but I believe the problem is common between that and joins -- both start with building a hash table, and that build is particularly slow when there are many key collisions and long chaining.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2138306017/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]