[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1300836797",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6981#issuecomment-1300836797",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6981",
        "id": 1300836797,
        "node_id": "IC_kwDOD7z77c5NiTG9",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-02T16:28:54Z",
        "updated_at": "2022-11-02T16:28:54Z",
        "author_association": "COLLABORATOR",
        "body": "As a follow on to this we might be able to play some performance games even when there is an order by column.  The performance of sorting a single simple columns is much less than sorting multiple columns.  Here is a quick test from my desktop.\r\n\r\n```\r\nspark.time(spark.range(10000000000L).selectExpr(\"id\", \"500000000 - id as other\", \"id + 1000000 as even_other\")\r\n   .orderBy(\"other\").show())\r\n5.2 seconds\r\n\r\nspark.time(spark.range(10000000000L).selectExpr(\"id\", \"500000000 - id as other\", \"id + 1000000 as even_other\")\r\n   .orderBy(\"other\", \"id\").show())\r\n11.1 seconds\r\n\r\nspark.time(spark.range(10000000000L).selectExpr(\"id\", \"500000000 - id as other\", \"id + 1000000 as even_other\")\r\n   .orderBy(\"other\", \"id\", \"even_other\").show())\r\n11.1 seconds\r\n```\r\n\r\nWhen going from 1 to 2 columns in the order by the time more than doubled, but when going from 2 to 3 columns the time stayed the same.\r\n\r\nThe point is that even if we have an order-by clause in the output and the order by is for a single simple column, then we could sort by the single simple column instead of sorting by all of the columns and still do the \"dynamic partition writer\" assuming that the order of the output rows is preserved when we do the partition call. Which I think it would have to for the proposed code above to do the right thing anyways.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1300836797/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1300863422",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6981#issuecomment-1300863422",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6981",
        "id": 1300863422,
        "node_id": "IC_kwDOD7z77c5NiZm-",
        "user": {
            "login": "jlowe",
            "id": 1360766,
            "node_id": "MDQ6VXNlcjEzNjA3NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1360766?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jlowe",
            "html_url": "https://github.com/jlowe",
            "followers_url": "https://api.github.com/users/jlowe/followers",
            "following_url": "https://api.github.com/users/jlowe/following{/other_user}",
            "gists_url": "https://api.github.com/users/jlowe/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jlowe/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jlowe/subscriptions",
            "organizations_url": "https://api.github.com/users/jlowe/orgs",
            "repos_url": "https://api.github.com/users/jlowe/repos",
            "events_url": "https://api.github.com/users/jlowe/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jlowe/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-11-02T16:39:44Z",
        "updated_at": "2022-11-02T16:39:44Z",
        "author_association": "MEMBER",
        "body": "cudf does not guarantee the order within partitions after `partition` is called, so we could not rely on that.  Therefore if we're using cudf's `partition` we could only perform this optimization if the query does not require any order before the write.  However it may be difficult to distinguish in the physical CPU plan whether a required ordering on the write came from normal partitioning logic on the CPU or an explicit orderBy requested by the user as part of the write.\r\n\r\nAlternatively we could work with cudf to implement a partition that does preserve order (or write our own).",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1300863422/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]