[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2099586657",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10770#issuecomment-2099586657",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10770",
        "id": 2099586657,
        "node_id": "IC_kwDOD7z77c59JSZh",
        "user": {
            "login": "firestarman",
            "id": 7280411,
            "node_id": "MDQ6VXNlcjcyODA0MTE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7280411?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/firestarman",
            "html_url": "https://github.com/firestarman",
            "followers_url": "https://api.github.com/users/firestarman/followers",
            "following_url": "https://api.github.com/users/firestarman/following{/other_user}",
            "gists_url": "https://api.github.com/users/firestarman/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/firestarman/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/firestarman/subscriptions",
            "organizations_url": "https://api.github.com/users/firestarman/orgs",
            "repos_url": "https://api.github.com/users/firestarman/repos",
            "events_url": "https://api.github.com/users/firestarman/events{/privacy}",
            "received_events_url": "https://api.github.com/users/firestarman/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-05-08T01:50:35Z",
        "updated_at": "2024-05-08T01:50:35Z",
        "author_association": "COLLABORATOR",
        "body": "could u first try to increase the value of \"concurrentGpuTask\" to see if we can get any better perf ?",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2099586657/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2101598895",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10770#issuecomment-2101598895",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10770",
        "id": 2101598895,
        "node_id": "IC_kwDOD7z77c59Q9qv",
        "user": {
            "login": "eordentlich",
            "id": 36281329,
            "node_id": "MDQ6VXNlcjM2MjgxMzI5",
            "avatar_url": "https://avatars.githubusercontent.com/u/36281329?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/eordentlich",
            "html_url": "https://github.com/eordentlich",
            "followers_url": "https://api.github.com/users/eordentlich/followers",
            "following_url": "https://api.github.com/users/eordentlich/following{/other_user}",
            "gists_url": "https://api.github.com/users/eordentlich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/eordentlich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/eordentlich/subscriptions",
            "organizations_url": "https://api.github.com/users/eordentlich/orgs",
            "repos_url": "https://api.github.com/users/eordentlich/repos",
            "events_url": "https://api.github.com/users/eordentlich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/eordentlich/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-05-08T22:22:51Z",
        "updated_at": "2024-05-08T22:22:51Z",
        "author_association": "CONTRIBUTOR",
        "body": "The computation gets pretty much stuck with essentially no progress.   I don't think that will make a difference.   Partial stack trace after reaching this point (might be from similar but not identical example to this repro):\r\n<details><summary>Details</summary>\r\n<p>\r\n\r\n```\r\n```\r\n\tat sun.misc.Unsafe.copyMemory(Native Method)\r\n\tat sun.misc.Unsafe.copyMemory(Unsafe.java:560)\r\n\tat java.nio.DirectByteBuffer.put(DirectByteBuffer.java:331)\r\n\tat org.apache.spark.util.DirectByteBufferOutputStream.grow(DirectByteBufferOutputStream.scala:63)\r\n\tat org.apache.spark.util.DirectByteBufferOutputStream.ensureCapacity(DirectByteBufferOutputStream.scala:49)\r\n\tat org.apache.spark.util.DirectByteBufferOutputStream.write(DirectByteBufferOutputStream.scala:44)\r\n\tat java.io.DataOutputStream.write(DataOutputStream.java:107)\r\n\t- locked <0x0000000768a99630> (a java.io.DataOutputStream)\r\n\tat org.apache.spark.sql.rapids.execution.python.BufferToStreamWriter.$anonfun$handleBuffer$1(GpuArrowWriter.scala:48)\r\n\tat org.apache.spark.sql.rapids.execution.python.BufferToStreamWriter.$anonfun$handleBuffer$1$adapted(GpuArrowWriter.scala:42)\r\n\tat org.apache.spark.sql.rapids.execution.python.BufferToStreamWriter$$Lambda$3498/1244767780.apply(Unknown Source)\r\n\tat com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:30)\r\n\tat org.apache.spark.sql.rapids.execution.python.BufferToStreamWriter.handleBuffer(GpuArrowWriter.scala:42)\r\n\tat ai.rapids.cudf.Table.writeArrowIPCArrowChunk(Native Method)\r\n\tat ai.rapids.cudf.Table.access$2000(Table.java:41)\r\n\tat ai.rapids.cudf.Table$ArrowIPCTableWriter.write(Table.java:1739)\r\n\tat org.apache.spark.sql.rapids.execution.python.GpuArrowWriter.$anonfun$write$1(GpuArrowWriter.scala:99)\r\n\tat org.apache.spark.sql.rapids.execution.python.GpuArrowWriter.$anonfun$write$1$adapted(GpuArrowWriter.scala:97)\r\n\tat org.apache.spark.sql.rapids.execution.python.GpuArrowWriter$$Lambda$3493/108528776.apply(Unknown Source)\r\n\tat com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:30)\r\n\tat org.apache.spark.sql.rapids.execution.python.GpuArrowWriter.write(GpuArrowWriter.scala:97)\r\n\tat org.apache.spark.sql.rapids.execution.python.GpuArrowWriter.write$(GpuArrowWriter.scala:96)\r\n\tat org.apache.spark.sql.rapids.execution.python.GpuArrowPythonWriter.write(GpuArrowWriter.scala:144)\r\n\tat org.apache.spark.sql.rapids.execution.python.GpuArrowWriter.$anonfun$writeAndClose$1(GpuArrowWriter.scala:93)\r\n\tat org.apache.spark.sql.rapids.execution.python.GpuArrowWriter.$anonfun$writeAndClose$1$adapted(GpuArrowWriter.scala:92)\r\n\tat org.apache.spark.sql.rapids.execution.python.GpuArrowWriter$$Lambda$3492/1674125626.apply(Unknown Source)\r\n\tat com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:30)\r\n\tat org.apache.spark.sql.rapids.execution.python.GpuArrowWriter.writeAndClose(GpuArrowWriter.scala:92)\r\n\tat org.apache.spark.sql.rapids.execution.python.GpuArrowWriter.writeAndClose$(GpuArrowWriter.scala:92)\r\n\tat org.apache.spark.sql.rapids.execution.python.GpuArrowPythonWriter.writeAndClose(GpuArrowWriter.scala:144)\r\n\tat org.apache.spark.sql.rapids.execution.python.shims.GpuArrowPythonRunner$$anon$1.writeNextInputToStream(GpuArrowPythonRunner.scala:74)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.writeAdditionalInputToPythonWorker(PythonRunner.scala:931)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:851)\r\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\r\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\r\n\t- locked <0x0000000765602c48> (a java.io.BufferedInputStream)\r\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\r\n\tat org.apache.spark.sql.rapids.execution.python.shims.GpuArrowPythonOutput$$anon$1.read(GpuArrowPythonOutput.scala:71)\r\n\tat org.apache.spark.sql.rapids.execution.python.shims.GpuArrowPythonOutput$$anon$1.read(GpuArrowPythonOutput.scala:48)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:635)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat com.nvidia.spark.rapids.AbstractProjectSplitIterator.hasNext(basicPhysicalOperators.scala:233)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat com.nvidia.spark.rapids.GpuMergeAggregateIterator.$anonfun$next$2(GpuAggregateExec.scala:751)\r\n\tat com.nvidia.spark.rapids.GpuMergeAggregateIterator$$Lambda$3706/165795055.apply(Unknown Source)```\r\n\r\n</p>\r\n</details> \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2101598895/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2151289800",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10770#issuecomment-2151289800",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10770",
        "id": 2151289800,
        "node_id": "IC_kwDOD7z77c6AOhPI",
        "user": {
            "login": "firestarman",
            "id": 7280411,
            "node_id": "MDQ6VXNlcjcyODA0MTE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7280411?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/firestarman",
            "html_url": "https://github.com/firestarman",
            "followers_url": "https://api.github.com/users/firestarman/followers",
            "following_url": "https://api.github.com/users/firestarman/following{/other_user}",
            "gists_url": "https://api.github.com/users/firestarman/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/firestarman/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/firestarman/subscriptions",
            "organizations_url": "https://api.github.com/users/firestarman/orgs",
            "repos_url": "https://api.github.com/users/firestarman/repos",
            "events_url": "https://api.github.com/users/firestarman/events{/privacy}",
            "received_events_url": "https://api.github.com/users/firestarman/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-06-06T02:13:01Z",
        "updated_at": "2024-06-06T02:13:14Z",
        "author_association": "COLLABORATOR",
        "body": "Hi @eordentlich, where can i get the file `s3a://spark-rapids-ml-bm-datasets-public/pca/1m_3k_singlecol_float32_50_files.parquet ?`",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2151289800/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2151347584",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10770#issuecomment-2151347584",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10770",
        "id": 2151347584,
        "node_id": "IC_kwDOD7z77c6AOvWA",
        "user": {
            "login": "firestarman",
            "id": 7280411,
            "node_id": "MDQ6VXNlcjcyODA0MTE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7280411?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/firestarman",
            "html_url": "https://github.com/firestarman",
            "followers_url": "https://api.github.com/users/firestarman/followers",
            "following_url": "https://api.github.com/users/firestarman/following{/other_user}",
            "gists_url": "https://api.github.com/users/firestarman/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/firestarman/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/firestarman/subscriptions",
            "organizations_url": "https://api.github.com/users/firestarman/orgs",
            "repos_url": "https://api.github.com/users/firestarman/repos",
            "events_url": "https://api.github.com/users/firestarman/events{/privacy}",
            "received_events_url": "https://api.github.com/users/firestarman/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-06-06T03:32:06Z",
        "updated_at": "2024-06-06T03:32:06Z",
        "author_association": "COLLABORATOR",
        "body": "And another try is to set the `spark.rapids.sql.python.gpu.enabled` to `false` and remove this line `spark.python.daemon.module rapids.daemon_databricks` if no GPU is required in the UDFs.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2151347584/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2151496647",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10770#issuecomment-2151496647",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10770",
        "id": 2151496647,
        "node_id": "IC_kwDOD7z77c6APTvH",
        "user": {
            "login": "eordentlich",
            "id": 36281329,
            "node_id": "MDQ6VXNlcjM2MjgxMzI5",
            "avatar_url": "https://avatars.githubusercontent.com/u/36281329?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/eordentlich",
            "html_url": "https://github.com/eordentlich",
            "followers_url": "https://api.github.com/users/eordentlich/followers",
            "following_url": "https://api.github.com/users/eordentlich/following{/other_user}",
            "gists_url": "https://api.github.com/users/eordentlich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/eordentlich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/eordentlich/subscriptions",
            "organizations_url": "https://api.github.com/users/eordentlich/orgs",
            "repos_url": "https://api.github.com/users/eordentlich/repos",
            "events_url": "https://api.github.com/users/eordentlich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/eordentlich/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-06-06T06:21:59Z",
        "updated_at": "2024-06-06T06:21:59Z",
        "author_association": "CONTRIBUTOR",
        "body": "> Hi @eordentlich, where can i get the file `s3a://spark-rapids-ml-bm-datasets-public/pca/1m_3k_singlecol_float32_50_files.parquet ?`\r\n\r\nIt's a public s3 bucket/file.   Can you access via spark parquet reader or s3 cli?",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2151496647/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2154278336",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10770#issuecomment-2154278336",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10770",
        "id": 2154278336,
        "node_id": "IC_kwDOD7z77c6AZ63A",
        "user": {
            "login": "firestarman",
            "id": 7280411,
            "node_id": "MDQ6VXNlcjcyODA0MTE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7280411?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/firestarman",
            "html_url": "https://github.com/firestarman",
            "followers_url": "https://api.github.com/users/firestarman/followers",
            "following_url": "https://api.github.com/users/firestarman/following{/other_user}",
            "gists_url": "https://api.github.com/users/firestarman/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/firestarman/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/firestarman/subscriptions",
            "organizations_url": "https://api.github.com/users/firestarman/orgs",
            "repos_url": "https://api.github.com/users/firestarman/repos",
            "events_url": "https://api.github.com/users/firestarman/events{/privacy}",
            "received_events_url": "https://api.github.com/users/firestarman/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-06-07T07:43:40Z",
        "updated_at": "2024-06-07T08:09:09Z",
        "author_association": "COLLABORATOR",
        "body": "> It's a public s3 bucket/file. Can you access via spark parquet reader or s3 cli?\r\n\r\nI tried to reproduce this locally, but always getting the error as below, seems there is something I missed.\r\n```\r\nCaused by: org.apache.hadoop.fs.s3a.auth.NoAuthWithAWSException: No AWS Credentials provided by TemporaryAWSCredentialsProvider SimpleAWSCredentialsProvider EnvironmentVariableCredentialsProvider IAMInstanceCredentialsProvider : com.amazonaws.SdkClientException: Unable to load AWS credentials from environment variables (AWS_ACCESS_KEY_ID (or AWS_ACCESS_KEY) and AWS_SECRET_KEY (or AWS_SECRET_ACCESS_KEY))\r\n\tat org.apache.hadoop.fs.s3a.AWSCredentialProviderList.getCredentials(AWSCredentialProviderList.java:216)\r\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.getCredentialsFromContext(AmazonHttpClient.java:1269)\r\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.runBeforeRequestHandlers(AmazonHttpClient.java:845)\r\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:794)\r\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:781)\r\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:755)\r\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:715)\r\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:697)\r\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:561)\r\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:541)\r\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5456)\r\n\tat com.amazonaws.services.s3.AmazonS3Client.getBucketRegionViaHeadRequest(AmazonS3Client.java:6431)\r\n\tat com.amazonaws.services.s3.AmazonS3Client.fetchRegionFromCache(AmazonS3Client.java:6404)\r\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5441)\r\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5403)\r\n\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1372)\r\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$getObjectMetadata$10(S3AFileSystem.java:2545)\r\n\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:414)\r\n\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:377)\r\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2533)\r\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2513)\r\n\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3776)\r\n\t... 22 more\r\nCaused by: com.amazonaws.SdkClientException: Unable to load AWS credentials from environment variables (AWS_ACCESS_KEY_ID (or AWS_ACCESS_KEY) and AWS_SECRET_KEY (or AWS_SECRET_ACCESS_KEY))\r\n\tat com.amazonaws.auth.EnvironmentVariableCredentialsProvider.getCredentials(EnvironmentVariableCredentialsProvider.java:50)\r\n\tat org.apache.hadoop.fs.s3a.AWSCredentialProviderList.getCredentials(AWSCredentialProviderList.java:177)\r\n\t... 43 more\r\n\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2154278336/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]