[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1277875523",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6745#issuecomment-1277875523",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6745",
        "id": 1277875523,
        "node_id": "IC_kwDOD7z77c5MKtVD",
        "user": {
            "login": "abellina",
            "id": 1901059,
            "node_id": "MDQ6VXNlcjE5MDEwNTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1901059?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abellina",
            "html_url": "https://github.com/abellina",
            "followers_url": "https://api.github.com/users/abellina/followers",
            "following_url": "https://api.github.com/users/abellina/following{/other_user}",
            "gists_url": "https://api.github.com/users/abellina/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abellina/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abellina/subscriptions",
            "organizations_url": "https://api.github.com/users/abellina/orgs",
            "repos_url": "https://api.github.com/users/abellina/repos",
            "events_url": "https://api.github.com/users/abellina/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abellina/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-10-13T16:22:30Z",
        "updated_at": "2022-10-13T18:11:12Z",
        "author_association": "COLLABORATOR",
        "body": "Thought about this issue a bit more, what I think we want is a version of the [tracking_resource_adaptor](https://github.com/rapidsai/rmm/blob/branch-22.12/include/rmm/mr/device/tracking_resource_adaptor.hpp) but, rather than have a single map for all threads, I think that we want to keep track of the maximum outstanding GPU footprint _per thread_. Also to note, the main motivation here would be to figure out if our estimation on memory usage for some GPU code is higher than anticipated, to help us debug waste or inform heuristics to control what tasks we allow on the GPU.\r\n\r\nThis should allow us to do the following:\r\n\r\n```\r\nval maxOutstandingUsage = withMemoryTracking { \r\n  val gpuData = materialize data on gpu\r\n  val result = withResource(gpuData) { _.callCudfFunction }\r\n  result.close() \r\n    // at this point our maximum outstanding should be:\r\n    // gpuData + max(allocated) inside of `callCudfFunction`\r\n}\r\n```\r\n\r\nIn this scenario when we enter the `withMemoryTracking` block, we would ask a per-thread tracking resource to start tracking _this_ thread before we materialize data. The materialization of `gpuData` incurs calls to rmm to get memory, so that adds to the outstanding amount, and then the call to the cuDF code could be allocations that are kept around (outstanding) for a while, allocations and frees that happen within the C++ code before the kernel, or results from this code. So we can keep track of how much is outstanding at any given time by adding to a thread-local variable how many bytes have been requested, and subtracting when we call free.\r\n\r\nIf one of our allocations failed and we handled them via a spill it shouldn't matter. That is because the spill code should be careful to disable the tracking for those spills (e.g. a `withoutMemoryTracking` call). This means we wouldn't discount frees in `this` thread for some other thread's allocations that are irrelevant to the code being tracked.\r\n\r\nI hope/believe this could be a pretty low overhead system. Note this doesn't, I don't think, help tracking when an expensive kernel is loaded, as far as I understand that can be a one-time-penalty when we open the shared library. I know we have seen this with some of the regular expression kernels in the past. Pinging @jlowe on this overall for comments.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1277875523/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1280866635",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6745#issuecomment-1280866635",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6745",
        "id": 1280866635,
        "node_id": "IC_kwDOD7z77c5MWHlL",
        "user": {
            "login": "abellina",
            "id": 1901059,
            "node_id": "MDQ6VXNlcjE5MDEwNTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1901059?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abellina",
            "html_url": "https://github.com/abellina",
            "followers_url": "https://api.github.com/users/abellina/followers",
            "following_url": "https://api.github.com/users/abellina/following{/other_user}",
            "gists_url": "https://api.github.com/users/abellina/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abellina/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abellina/subscriptions",
            "organizations_url": "https://api.github.com/users/abellina/orgs",
            "repos_url": "https://api.github.com/users/abellina/repos",
            "events_url": "https://api.github.com/users/abellina/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abellina/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-10-17T13:31:36Z",
        "updated_at": "2022-10-17T13:35:43Z",
        "author_association": "COLLABORATOR",
        "body": "I think one approach here is to have a stack of simple memory tracking info in RmmJni. When a `withMemoryTracking` block is issued we push to the stack one of these objects. The `tracking_resource_adaptor` could then check this stack for the current thread, and if it has something in it, it uses the top tracker to track allocations for now.\n\nWhen `withMemoryTracking` is finishing, it calls a function in the RMM jni bits to pop this element from the stack. If it is the last element, we have turned the feature off. If it is not the last element we get the amount tracked in this scope and add the maximum outstanding we just popped to the next element in the stack (the calling scope also saw that maximum outstanding), and we continue to track with the remaining tracker in the stack.\n\nWe also need to keep a set of addresses we allocated in _this_ thread, unfortunately. Given spill, the current thread may need to spill to satisfy an allocation. It seems we could ignore frees that we didn't allocate while tracking. The hope is that these `withMemoryTracking` blocks are as close as possible to a cuDF call.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1280866635/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1426098896",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6745#issuecomment-1426098896",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6745",
        "id": 1426098896,
        "node_id": "IC_kwDOD7z77c5VAIrQ",
        "user": {
            "login": "abellina",
            "id": 1901059,
            "node_id": "MDQ6VXNlcjE5MDEwNTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1901059?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abellina",
            "html_url": "https://github.com/abellina",
            "followers_url": "https://api.github.com/users/abellina/followers",
            "following_url": "https://api.github.com/users/abellina/following{/other_user}",
            "gists_url": "https://api.github.com/users/abellina/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abellina/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abellina/subscriptions",
            "organizations_url": "https://api.github.com/users/abellina/orgs",
            "repos_url": "https://api.github.com/users/abellina/repos",
            "events_url": "https://api.github.com/users/abellina/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abellina/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-02-10T17:08:24Z",
        "updated_at": "2023-02-10T17:08:24Z",
        "author_association": "COLLABORATOR",
        "body": "Nsys has added memory tracking capabilities as of late, and we believe we can use the correlationId + NVTX ranges  to accomplish this as a post processing step given an NVTX range. We should investigate if this solution does what we need.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1426098896/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1778907276",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6745#issuecomment-1778907276",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6745",
        "id": 1778907276,
        "node_id": "IC_kwDOD7z77c5qB_iM",
        "user": {
            "login": "wjxiz1992",
            "id": 20476954,
            "node_id": "MDQ6VXNlcjIwNDc2OTU0",
            "avatar_url": "https://avatars.githubusercontent.com/u/20476954?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wjxiz1992",
            "html_url": "https://github.com/wjxiz1992",
            "followers_url": "https://api.github.com/users/wjxiz1992/followers",
            "following_url": "https://api.github.com/users/wjxiz1992/following{/other_user}",
            "gists_url": "https://api.github.com/users/wjxiz1992/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wjxiz1992/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wjxiz1992/subscriptions",
            "organizations_url": "https://api.github.com/users/wjxiz1992/orgs",
            "repos_url": "https://api.github.com/users/wjxiz1992/repos",
            "events_url": "https://api.github.com/users/wjxiz1992/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wjxiz1992/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-10-25T09:51:19Z",
        "updated_at": "2023-10-26T07:21:08Z",
        "author_association": "COLLABORATOR",
        "body": "Hi @abellina I am trying to profile the GPU memory usage during a query run. I used nsys to profile, but didn't find metrics like `peak memory usage`\r\n![image](https://github.com/NVIDIA/spark-rapids/assets/20476954/da1a442c-c2a1-438a-a03f-d928e3573946)\r\n \r\nI was using `NVIDIA Nsight Systems version 2022.2.1.31-5fe97ab` installed in our internal cluster. \r\nI saw a post about it: https://forums.developer.nvidia.com/t/nsys-measure-memory/118394 which is posted on 2021, but it contains the `memory usage` part in the graph...\r\n\r\n\r\nUpdate:\r\nThe memory usage metrics are disabled by default, it can be turned on by an extra nsys argument `--cuda-memory-usage=true`\r\nThen we can see the memory utilization part in the graph:\r\n![image](https://github.com/NVIDIA/spark-rapids/assets/20476954/fc8621f3-8339-4414-a1e6-50e8f4cfbab9)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1778907276/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1783076931",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6745#issuecomment-1783076931",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6745",
        "id": 1783076931,
        "node_id": "IC_kwDOD7z77c5qR5hD",
        "user": {
            "login": "abellina",
            "id": 1901059,
            "node_id": "MDQ6VXNlcjE5MDEwNTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1901059?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abellina",
            "html_url": "https://github.com/abellina",
            "followers_url": "https://api.github.com/users/abellina/followers",
            "following_url": "https://api.github.com/users/abellina/following{/other_user}",
            "gists_url": "https://api.github.com/users/abellina/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abellina/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abellina/subscriptions",
            "organizations_url": "https://api.github.com/users/abellina/orgs",
            "repos_url": "https://api.github.com/users/abellina/repos",
            "events_url": "https://api.github.com/users/abellina/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abellina/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-10-27T15:07:56Z",
        "updated_at": "2023-10-27T15:07:56Z",
        "author_association": "COLLABORATOR",
        "body": "I haven't used this feature, the main question I'd have is whether it works with a pool, especially the async pools. It most definitely does not work with ARENA because that's all CPU managed, but cudaAsync I'd hope shows it. ",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1783076931/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1784527518",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6745#issuecomment-1784527518",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6745",
        "id": 1784527518,
        "node_id": "IC_kwDOD7z77c5qXbqe",
        "user": {
            "login": "wjxiz1992",
            "id": 20476954,
            "node_id": "MDQ6VXNlcjIwNDc2OTU0",
            "avatar_url": "https://avatars.githubusercontent.com/u/20476954?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wjxiz1992",
            "html_url": "https://github.com/wjxiz1992",
            "followers_url": "https://api.github.com/users/wjxiz1992/followers",
            "following_url": "https://api.github.com/users/wjxiz1992/following{/other_user}",
            "gists_url": "https://api.github.com/users/wjxiz1992/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wjxiz1992/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wjxiz1992/subscriptions",
            "organizations_url": "https://api.github.com/users/wjxiz1992/orgs",
            "repos_url": "https://api.github.com/users/wjxiz1992/repos",
            "events_url": "https://api.github.com/users/wjxiz1992/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wjxiz1992/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-10-30T05:52:48Z",
        "updated_at": "2023-10-30T05:52:48Z",
        "author_association": "COLLABORATOR",
        "body": "The profile result above is from a run with ASYNC pool.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1784527518/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]