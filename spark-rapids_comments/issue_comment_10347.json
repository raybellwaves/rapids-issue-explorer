[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1939201860",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10347#issuecomment-1939201860",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10347",
        "id": 1939201860,
        "node_id": "IC_kwDOD7z77c5zld9E",
        "user": {
            "login": "NVnavkumar",
            "id": 97137715,
            "node_id": "U_kgDOBco0Mw",
            "avatar_url": "https://avatars.githubusercontent.com/u/97137715?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NVnavkumar",
            "html_url": "https://github.com/NVnavkumar",
            "followers_url": "https://api.github.com/users/NVnavkumar/followers",
            "following_url": "https://api.github.com/users/NVnavkumar/following{/other_user}",
            "gists_url": "https://api.github.com/users/NVnavkumar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NVnavkumar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NVnavkumar/subscriptions",
            "organizations_url": "https://api.github.com/users/NVnavkumar/orgs",
            "repos_url": "https://api.github.com/users/NVnavkumar/repos",
            "events_url": "https://api.github.com/users/NVnavkumar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NVnavkumar/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-02-12T17:29:07Z",
        "updated_at": "2024-02-12T17:29:07Z",
        "author_association": "COLLABORATOR",
        "body": "Using `grep`, extracted out the list of failing tests.\r\n\r\n```\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_unary_minus[Decimal(36,5)]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_unary_minus[Decimal(38,10)][INJECT_OOM]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_unary_minus[Decimal(38,0)]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_unary_minus[Decimal(36,-5)][INJECT_OOM]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_unary_minus[Decimal(38,-10)][INJECT_OOM]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_unary_minus_ansi_no_overflow[Decimal(36,5)]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_unary_minus_ansi_no_overflow[Decimal(38,10)]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_unary_minus_ansi_no_overflow[Decimal(38,0)][INJECT_OOM]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_unary_minus_ansi_no_overflow[Decimal(36,-5)][INJECT_OOM]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_unary_minus_ansi_no_overflow[Decimal(38,-10)]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_abs[Decimal(36,5)][INJECT_OOM]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_abs[Decimal(38,10)][INJECT_OOM]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_abs[Decimal(38,0)][INJECT_OOM]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_abs[Decimal(36,-5)][INJECT_OOM]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_abs[Decimal(38,-10)]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_abs_ansi_no_overflow[Decimal(36,5)][INJECT_OOM]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_abs_ansi_no_overflow[Decimal(38,10)][INJECT_OOM]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_abs_ansi_no_overflow[Decimal(38,0)]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_abs_ansi_no_overflow[Decimal(36,-5)][INJECT_OOM]\r\narithmetic-ops-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/arithmetic_ops_test.py::test_abs_ansi_no_overflow[Decimal(38,-10)][INJECT_OOM]\r\nast-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/ast_test.py::test_eq[(String, False)]\r\nast-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/ast_test.py::test_ne[(String, False)]\r\nast-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/ast_test.py::test_lt[(String, False)][INJECT_OOM]\r\nast-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/ast_test.py::test_lte[(String, False)]\r\nast-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/ast_test.py::test_gt[(String, False)]\r\nast-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/ast_test.py::test_gte[(String, False)]\r\ncast-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/cast_test.py::test_cast_decimal_to[to:ByteType()-from:Decimal(7,-3)][APPROXIMATE_FLOAT]\r\ncast-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/cast_test.py::test_cast_decimal_to[to:ShortType()-from:Decimal(7,-3)][APPROXIMATE_FLOAT]\r\ncast-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/cast_test.py::test_cast_decimal_to[to:IntegerType()-from:Decimal(7,-3)][INJECT_OOM, APPROXIMATE_FLOAT]\r\ncast-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/cast_test.py::test_cast_decimal_to[to:LongType()-from:Decimal(7,-3)][INJECT_OOM, APPROXIMATE_FLOAT]\r\ncol-size-exceeding-cudf-limit-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/col_size_exceeding_cudf_limit_test.py::test_col_size_exceeding_cudf_limit[single_partition_int_value-orc]\r\ncol-size-exceeding-cudf-limit-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/col_size_exceeding_cudf_limit_test.py::test_col_size_exceeding_cudf_limit[single_partition_single_value_without_nulls-orc]\r\ncol-size-exceeding-cudf-limit-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/col_size_exceeding_cudf_limit_test.py::test_col_size_exceeding_cudf_limit[single_partition_empty_value_with_nulls-orc][INJECT_OOM]\r\ncol-size-exceeding-cudf-limit-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/col_size_exceeding_cudf_limit_test.py::test_col_size_exceeding_cudf_limit[single_partition_single_empty_value_with_nulls-orc][INJECT_OOM]\r\ncol-size-exceeding-cudf-limit-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/col_size_exceeding_cudf_limit_test.py::test_col_size_exceeding_cudf_limit[single_partition_multiple_value-orc]\r\ncol-size-exceeding-cudf-limit-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/col_size_exceeding_cudf_limit_test.py::test_col_size_exceeding_cudf_limit[multiple_partition_single_value-orc]\r\ncol-size-exceeding-cudf-limit-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/col_size_exceeding_cudf_limit_test.py::test_col_size_exceeding_cudf_limit[multiple_partition_int_value-orc][INJECT_OOM]\r\ncol-size-exceeding-cudf-limit-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/col_size_exceeding_cudf_limit_test.py::test_col_size_exceeding_cudf_limit[multiple_partition_multiple_value_wider_first_col-orc][INJECT_OOM]\r\ncol-size-exceeding-cudf-limit-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/col_size_exceeding_cudf_limit_test.py::test_col_size_exceeding_cudf_limit[multiple_partition_multiple_value_narrow_first_col-orc]\r\ndatasourcev2-read-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/datasourcev2_read_test.py::test_read_int\r\ndatasourcev2-read-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/datasourcev2_read_test.py::test_read_strings\r\ndatasourcev2-read-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/datasourcev2_read_test.py::test_read_all_types[INJECT_OOM]\r\ndatasourcev2-read-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/datasourcev2_read_test.py::test_read_all_types_count\r\ndatasourcev2-read-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/datasourcev2_read_test.py::test_read_arrow_off[INJECT_OOM]\r\ndatasourcev2-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/datasourcev2_write_test.py::test_write_hive_bucketed_table_fallback[parquet][IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\ndatasourcev2-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/datasourcev2_write_test.py::test_write_hive_bucketed_table_fallback[orc][IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nexplain-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/explain_test.py::test_explain_bucketd_scan[ALLOW_NON_GPU(ANY)]\r\nexplain-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/explain_test.py::test_explain_bucket_column_not_read[INJECT_OOM, ALLOW_NON_GPU(ANY)]\r\nexplain-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/explain_test.py::test_explain_bucket_disabled_by_conf[INJECT_OOM, ALLOW_NON_GPU(ANY)]\r\nexplain-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/explain_test.py::test_explain_bucket_disabled_by_query_planner[INJECT_OOM, ALLOW_NON_GPU(ANY)]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Byte(not_null)][INJECT_OOM]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Byte][INJECT_OOM]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Short(not_null)]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Short][INJECT_OOM]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Integer(not_null)]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Integer]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Long(not_null)][INJECT_OOM]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Long][INJECT_OOM]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Float(not_null)]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Float][INJECT_OOM]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Double(not_null)]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Double]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Decimal(not_null)(18,0)][INJECT_OOM]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_written_with_fastparquet[Decimal(18,0)]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_rewritten_with_fastparquet[Date(not_null)-int961][INJECT_OOM]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_rewritten_with_fastparquet[Date-int96]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_rewritten_with_fastparquet[Timestamp(not_null)-int960][INJECT_OOM]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_rewritten_with_fastparquet[Timestamp-int96]\r\nfastparquet-compatibility-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/fastparquet_compatibility_test.py::test_reading_file_rewritten_with_fastparquet[Struct(not_null)(('first', Integer(not_null)))-int96]\r\nhive-delimited-text-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_delimited_text_test.py::test_read_compressed_hive_text[BZip2Codec]\r\nhive-delimited-text-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_delimited_text_test.py::test_read_compressed_hive_text[DefaultCodec]\r\nhive-delimited-text-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_delimited_text_test.py::test_read_compressed_hive_text[GzipCodec][INJECT_OOM]\r\nhive-delimited-text-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_delimited_text_test.py::test_partitioned_hive_text_write[PartitionWriteMode.Static][IGNORE_ORDER({'local': True})]\r\nhive-delimited-text-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_delimited_text_test.py::test_partitioned_hive_text_write[PartitionWriteMode.Dynamic][INJECT_OOM, IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_basic[PARQUET-[Byte, Short, Integer, Long, Float, Double, String, Boolean, Date, Timestamp, Decimal(7,3), Decimal(12,2), Decimal(20,2)]][IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_basic[PARQUET-[Struct(['child0', Byte],['child1', Short],['child2', Integer],['child3', Long],['child4', Float],['child5', Double],['child6', String],['child7', Boolean],['child8', Date],['child9', Timestamp],['child10', Decimal(7,3)],['child11', Decimal(12,2)],['child12', Decimal(20,2)]), Struct(['child0', Byte],['child1', Struct(['child0', Byte],['child1', Short],['child2', Integer],['child3', Long],['child4', Float],['child5', Double],['child6', String],['child7', Boolean],['child8', Date],['child9', Timestamp],['child10', Decimal(7,3)],['child11', Decimal(12,2)],['child12', Decimal(20,2)])]), Struct(['child0', Array(Short)],['child1', Double])]][IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_basic[PARQUET-[Array(Byte), Array(Short), Array(Integer), Array(Long), Array(Float), Array(Double), Array(String), Array(Boolean), Array(Date), Array(Timestamp), Array(Decimal(7,3)), Array(Decimal(12,2)), Array(Decimal(20,2)), Array(Array(Short)), Array(Array(String)), Array(Struct(['child0', Byte],['child1', String],['child2', Float]))]][INJECT_OOM, IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_basic[PARQUET-[Map(String(not_null),String), Map(Boolean(not_null),Boolean), Map(Byte(not_null),Byte), Map(Short(not_null),Short), Map(Integer(not_null),Integer), Map(Long(not_null),Long), Map(Float(not_null),Float), Map(Double(not_null),Double), Map(Timestamp(not_null),Timestamp), Map(Date(not_null),Date), Map(Decimal(not_null)(15,1),Decimal(15,1)), Map(Decimal(not_null)(36,5),Decimal(36,5))]][IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_basic[nativeorc-[Byte, Short, Integer, Long, Float, Double, String, Boolean, Date, Timestamp, Decimal(7,3), Decimal(12,2), Decimal(20,2)]][INJECT_OOM, IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_basic[nativeorc-[Struct(['child0', Byte],['child1', Short],['child2', Integer],['child3', Long],['child4', Float],['child5', Double],['child6', String],['child7', Boolean],['child8', Date],['child9', Timestamp],['child10', Decimal(7,3)],['child11', Decimal(12,2)],['child12', Decimal(20,2)]), Struct(['child0', Byte],['child1', Struct(['child0', Byte],['child1', Short],['child2', Integer],['child3', Long],['child4', Float],['child5', Double],['child6', String],['child7', Boolean],['child8', Date],['child9', Timestamp],['child10', Decimal(7,3)],['child11', Decimal(12,2)],['child12', Decimal(20,2)])]), Struct(['child0', Array(Short)],['child1', Double])]][INJECT_OOM, IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_basic[nativeorc-[Array(Byte), Array(Short), Array(Integer), Array(Long), Array(Float), Array(Double), Array(String), Array(Boolean), Array(Date), Array(Timestamp), Array(Decimal(7,3)), Array(Decimal(12,2)), Array(Decimal(20,2)), Array(Array(Short)), Array(Array(String)), Array(Struct(['child0', Byte],['child1', String],['child2', Float]))]][INJECT_OOM, IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_basic[nativeorc-[Map(String(not_null),String), Map(Boolean(not_null),Boolean), Map(Byte(not_null),Byte), Map(Short(not_null),Short), Map(Integer(not_null),Integer), Map(Long(not_null),Long), Map(Float(not_null),Float), Map(Double(not_null),Double), Map(Timestamp(not_null),Timestamp), Map(Date(not_null),Date), Map(Decimal(not_null)(15,1),Decimal(15,1)), Map(Decimal(not_null)(36,5),Decimal(36,5))]][INJECT_OOM, IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_basic[hiveorc-[Byte, Short, Integer, Long, Float, Double, String, Boolean, Date, Timestamp, Decimal(7,3), Decimal(12,2), Decimal(20,2)]][IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_basic[hiveorc-[Struct(['child0', Byte],['child1', Short],['child2', Integer],['child3', Long],['child4', Float],['child5', Double],['child6', String],['child7', Boolean],['child8', Date],['child9', Timestamp],['child10', Decimal(7,3)],['child11', Decimal(12,2)],['child12', Decimal(20,2)]), Struct(['child0', Byte],['child1', Struct(['child0', Byte],['child1', Short],['child2', Integer],['child3', Long],['child4', Float],['child5', Double],['child6', String],['child7', Boolean],['child8', Date],['child9', Timestamp],['child10', Decimal(7,3)],['child11', Decimal(12,2)],['child12', Decimal(20,2)])]), Struct(['child0', Array(Short)],['child1', Double])]][IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_basic[hiveorc-[Array(Byte), Array(Short), Array(Integer), Array(Long), Array(Float), Array(Double), Array(String), Array(Boolean), Array(Date), Array(Timestamp), Array(Decimal(7,3)), Array(Decimal(12,2)), Array(Decimal(20,2)), Array(Array(Short)), Array(Array(String)), Array(Struct(['child0', Byte],['child1', String],['child2', Float]))]][INJECT_OOM, IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_basic[hiveorc-[Map(String(not_null),String), Map(Boolean(not_null),Boolean), Map(Byte(not_null),Byte), Map(Short(not_null),Short), Map(Integer(not_null),Integer), Map(Long(not_null),Long), Map(Float(not_null),Float), Map(Double(not_null),Double), Map(Timestamp(not_null),Timestamp), Map(Date(not_null),Date), Map(Decimal(not_null)(15,1),Decimal(15,1)), Map(Decimal(not_null)(36,5),Decimal(36,5))]][IGNORE_ORDER({'local': True})]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_configs_fallback[('PARQUET', {'spark.sql.legacy.parquet.datetimeRebaseModeInWrite': 'LEGACY', 'spark.sql.legacy.parquet.int96RebaseModeInWrite': 'LEGACY'})-[Byte, Short, Integer, Long, Float, Double, String, Boolean, Date, Timestamp, Decimal(7,3), Decimal(12,2), Decimal(20,2)]][INJECT_OOM, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_configs_fallback[('PARQUET', {'parquet.encryption.footer.key': 'k1', 'parquet.encryption.column.keys': 'k2:a'})-[Byte, Short, Integer, Long, Float, Double, String, Boolean, Date, Timestamp, Decimal(7,3), Decimal(12,2), Decimal(20,2)]][INJECT_OOM, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_configs_fallback[('PARQUET', {'spark.sql.parquet.compression.codec': 'gzip'})-[Byte, Short, Integer, Long, Float, Double, String, Boolean, Date, Timestamp, Decimal(7,3), Decimal(12,2), Decimal(20,2)]][ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_configs_fallback[('PARQUET', {'spark.sql.parquet.writeLegacyFormat': 'true'})-[Byte, Short, Integer, Long, Float, Double, String, Boolean, Date, Timestamp, Decimal(7,3), Decimal(12,2), Decimal(20,2)]][INJECT_OOM, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_configs_fallback[('ORC', {'spark.sql.orc.compression.codec': 'zlib'})-[Byte, Short, Integer, Long, Float, Double, String, Boolean, Date, Timestamp, Decimal(7,3), Decimal(12,2), Decimal(20,2)]][INJECT_OOM, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_options_fallback[('PARQUET', {'parquet.encryption.footer.key': 'k1', 'parquet.encryption.column.keys': 'k2:a'})-[Byte, Short, Integer, Long, Float, Double, String, Boolean, Date, Timestamp, Decimal(7,3), Decimal(12,2), Decimal(20,2)]][ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_ctas_options_fallback[('ORC', {'orc.compress': 'zlib'})-[Byte, Short, Integer, Long, Float, Double, String, Boolean, Date, Timestamp, Decimal(7,3), Decimal(12,2), Decimal(20,2)]][ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_bucketed_fallback_33X[PARQUET-[Byte, Short, Integer, Long, Float, Double, String, Boolean, Date, Timestamp, Decimal(7,3), Decimal(12,2), Decimal(20,2)]][INJECT_OOM, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_optimized_hive_bucketed_fallback_33X[ORC-[Byte, Short, Integer, Long, Float, Double, String, Boolean, Date, Timestamp, Decimal(7,3), Decimal(12,2), Decimal(20,2)]][ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_hive_copy_ints_to_long\r\nhive-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/hive_write_test.py::test_hive_copy_longs_to_float[INJECT_OOM]\r\njoin-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/join_test.py::test_broadcast_join_with_condition_ast_type_fallback[Left-String][IGNORE_ORDER({'local': True}), ALLOW_NON_GPU(BroadcastExchangeExec,BroadcastHashJoinExec,Cast,GreaterThan,SortMergeJoinExec)]\r\njoin-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/join_test.py::test_broadcast_join_with_condition_ast_type_fallback[Right-String][INJECT_OOM, IGNORE_ORDER({'local': True}), ALLOW_NON_GPU(BroadcastExchangeExec,BroadcastHashJoinExec,Cast,GreaterThan,SortMergeJoinExec)]\r\njoin-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/join_test.py::test_broadcast_join_with_condition_ast_type_fallback[FullOuter-String][IGNORE_ORDER({'local': True}), ALLOW_NON_GPU(BroadcastExchangeExec,BroadcastHashJoinExec,Cast,GreaterThan,SortMergeJoinExec)]\r\njoin-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/join_test.py::test_broadcast_join_with_condition_ast_type_fallback[LeftSemi-String][IGNORE_ORDER({'local': True}), ALLOW_NON_GPU(BroadcastExchangeExec,BroadcastHashJoinExec,Cast,GreaterThan,SortMergeJoinExec)]\r\njoin-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/join_test.py::test_broadcast_join_with_condition_ast_type_fallback[LeftAnti-String][IGNORE_ORDER({'local': True}), ALLOW_NON_GPU(BroadcastExchangeExec,BroadcastHashJoinExec,Cast,GreaterThan,SortMergeJoinExec)]\r\njoin-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/join_test.py::test_sortmerge_join_with_condition_ast_type_fallback[Left-String][INJECT_OOM, IGNORE_ORDER({'local': True}), ALLOW_NON_GPU(GreaterThan,ShuffleExchangeExec,SortMergeJoinExec)]\r\njoin-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/join_test.py::test_sortmerge_join_with_condition_ast_type_fallback[Right-String][INJECT_OOM, IGNORE_ORDER({'local': True}), ALLOW_NON_GPU(GreaterThan,ShuffleExchangeExec,SortMergeJoinExec)]\r\njoin-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/join_test.py::test_sortmerge_join_with_condition_ast_type_fallback[FullOuter-String][IGNORE_ORDER({'local': True}), ALLOW_NON_GPU(GreaterThan,ShuffleExchangeExec,SortMergeJoinExec)]\r\njoin-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/join_test.py::test_sortmerge_join_with_condition_ast_type_fallback[LeftSemi-String][IGNORE_ORDER({'local': True}), ALLOW_NON_GPU(GreaterThan,ShuffleExchangeExec,SortMergeJoinExec)]\r\njoin-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/join_test.py::test_sortmerge_join_with_condition_ast_type_fallback[LeftAnti-String][INJECT_OOM, IGNORE_ORDER({'local': True}), ALLOW_NON_GPU(GreaterThan,ShuffleExchangeExec,SortMergeJoinExec)]\r\njoin-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/join_test.py::test_join_bucketed_table[true][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\njoin-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/join_test.py::test_join_bucketed_table[false][IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs0-LEGACY-INT96-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs0-LEGACY-TIMESTAMP_MICROS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs0-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs1-LEGACY-INT96-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs1-LEGACY-TIMESTAMP_MICROS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs1-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs2-LEGACY-INT96-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs2-LEGACY-TIMESTAMP_MICROS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs2-LEGACY-TIMESTAMP_MILLIS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs3-LEGACY-INT96-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs3-LEGACY-TIMESTAMP_MICROS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs3-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs4-LEGACY-INT96-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs4-LEGACY-TIMESTAMP_MICROS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs4-LEGACY-TIMESTAMP_MILLIS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs5-LEGACY-INT96-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs5-LEGACY-TIMESTAMP_MICROS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs5-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs6-LEGACY-INT96-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs6-LEGACY-TIMESTAMP_MICROS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs6-LEGACY-TIMESTAMP_MILLIS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs7-LEGACY-INT96-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs7-LEGACY-TIMESTAMP_MICROS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs7-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs8-LEGACY-INT96-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs8-LEGACY-TIMESTAMP_MICROS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs8-LEGACY-TIMESTAMP_MILLIS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs9-LEGACY-INT96-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs9-LEGACY-TIMESTAMP_MICROS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs9-LEGACY-TIMESTAMP_MILLIS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs10-LEGACY-INT96-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs10-LEGACY-TIMESTAMP_MICROS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[-reader_confs10-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs0-LEGACY-INT96-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs0-LEGACY-TIMESTAMP_MICROS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs0-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs1-LEGACY-INT96-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs1-LEGACY-TIMESTAMP_MICROS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs1-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs2-LEGACY-INT96-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs2-LEGACY-TIMESTAMP_MICROS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs2-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs3-LEGACY-INT96-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs3-LEGACY-TIMESTAMP_MICROS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs3-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs4-LEGACY-INT96-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs4-LEGACY-TIMESTAMP_MICROS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs4-LEGACY-TIMESTAMP_MILLIS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs5-LEGACY-INT96-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs5-LEGACY-TIMESTAMP_MICROS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs5-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs6-LEGACY-INT96-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs6-LEGACY-TIMESTAMP_MICROS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs6-LEGACY-TIMESTAMP_MILLIS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs7-LEGACY-INT96-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs7-LEGACY-TIMESTAMP_MICROS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs7-LEGACY-TIMESTAMP_MILLIS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs8-LEGACY-INT96-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs8-LEGACY-TIMESTAMP_MICROS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs8-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs9-LEGACY-INT96-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs9-LEGACY-TIMESTAMP_MICROS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs9-LEGACY-TIMESTAMP_MILLIS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs10-LEGACY-INT96-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs10-LEGACY-TIMESTAMP_MICROS-Timestamp]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_ts_read_fails_datetime_legacy[parquet-reader_confs10-LEGACY-TIMESTAMP_MILLIS-Timestamp][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[-reader_confs0][IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[-reader_confs1][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[-reader_confs2][IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[-reader_confs3][IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[-reader_confs4][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[-reader_confs5][IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[-reader_confs6][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[-reader_confs7][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[-reader_confs8][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[-reader_confs9][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[-reader_confs10][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[parquet-reader_confs0][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[parquet-reader_confs1][IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[parquet-reader_confs2][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[parquet-reader_confs3][IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[parquet-reader_confs4][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[parquet-reader_confs5][IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[parquet-reader_confs6][IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[parquet-reader_confs7][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[parquet-reader_confs8][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[parquet-reader_confs9][IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_buckets[parquet-reader_confs10][INJECT_OOM, IGNORE_ORDER, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[-{'spark.rapids.sql.format.parquet.reader.type': 'PERFILE', 'spark.rapids.sql.format.parquet.reader.footer.type': 'NATIVE'}][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[-{'spark.rapids.sql.format.parquet.reader.type': 'MULTITHREADED', 'spark.rapids.sql.format.parquet.reader.footer.type': 'NATIVE', 'spark.rapids.sql.reader.multithreaded.combine.sizeBytes': '0', 'spark.rapids.sql.reader.multithreaded.read.keepOrder': True}][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[-{'spark.rapids.sql.format.parquet.reader.type': 'COALESCING', 'spark.rapids.sql.format.parquet.reader.footer.type': 'NATIVE'}][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[-{'spark.rapids.sql.format.parquet.reader.type': 'COALESCING', 'spark.rapids.sql.coalescing.reader.numFilterParallel': '2', 'spark.rapids.sql.reader.chunked': True}]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[-{'spark.rapids.sql.format.parquet.reader.type': 'COALESCING', 'spark.rapids.sql.format.parquet.reader.footer.type': 'NATIVE', 'spark.rapids.sql.reader.chunked': True}]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[-{'spark.rapids.sql.format.parquet.reader.type': 'PERFILE'}]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[-{'spark.rapids.sql.format.parquet.reader.type': 'MULTITHREADED', 'spark.rapids.sql.reader.multithreaded.combine.sizeBytes': '0', 'spark.rapids.sql.reader.multithreaded.read.keepOrder': True}][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[-{'spark.rapids.sql.format.parquet.reader.type': 'COALESCING'}]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[-{'spark.rapids.sql.format.parquet.reader.type': 'COALESCING', 'spark.rapids.sql.coalescing.reader.numFilterParallel': '2', 'spark.rapids.sql.reader.chunked': False}][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[-{'spark.rapids.sql.format.parquet.reader.type': 'MULTITHREADED', 'spark.rapids.sql.reader.multithreaded.combine.sizeBytes': '64m', 'spark.rapids.sql.reader.multithreaded.read.keepOrder': True}][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[-{'spark.rapids.sql.format.parquet.reader.type': 'MULTITHREADED', 'spark.rapids.sql.format.parquet.multithreaded.combine.sizeBytes': '64m', 'spark.rapids.sql.format.parquet.multithreaded.read.keepOrder': True}]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[parquet-{'spark.rapids.sql.format.parquet.reader.type': 'PERFILE', 'spark.rapids.sql.format.parquet.reader.footer.type': 'NATIVE'}][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[parquet-{'spark.rapids.sql.format.parquet.reader.type': 'MULTITHREADED', 'spark.rapids.sql.format.parquet.reader.footer.type': 'NATIVE', 'spark.rapids.sql.reader.multithreaded.combine.sizeBytes': '0', 'spark.rapids.sql.reader.multithreaded.read.keepOrder': True}]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[parquet-{'spark.rapids.sql.format.parquet.reader.type': 'COALESCING', 'spark.rapids.sql.format.parquet.reader.footer.type': 'NATIVE'}][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[parquet-{'spark.rapids.sql.format.parquet.reader.type': 'COALESCING', 'spark.rapids.sql.coalescing.reader.numFilterParallel': '2', 'spark.rapids.sql.reader.chunked': True}]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[parquet-{'spark.rapids.sql.format.parquet.reader.type': 'COALESCING', 'spark.rapids.sql.format.parquet.reader.footer.type': 'NATIVE', 'spark.rapids.sql.reader.chunked': True}]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[parquet-{'spark.rapids.sql.format.parquet.reader.type': 'PERFILE'}][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[parquet-{'spark.rapids.sql.format.parquet.reader.type': 'MULTITHREADED', 'spark.rapids.sql.reader.multithreaded.combine.sizeBytes': '0', 'spark.rapids.sql.reader.multithreaded.read.keepOrder': True}][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[parquet-{'spark.rapids.sql.format.parquet.reader.type': 'COALESCING'}]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[parquet-{'spark.rapids.sql.format.parquet.reader.type': 'COALESCING', 'spark.rapids.sql.coalescing.reader.numFilterParallel': '2', 'spark.rapids.sql.reader.chunked': False}][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[parquet-{'spark.rapids.sql.format.parquet.reader.type': 'MULTITHREADED', 'spark.rapids.sql.reader.multithreaded.combine.sizeBytes': '64m', 'spark.rapids.sql.reader.multithreaded.read.keepOrder': True}][INJECT_OOM]\r\nparquet-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_test.py::test_disorder_read_schema[parquet-{'spark.rapids.sql.format.parquet.reader.type': 'MULTITHREADED', 'spark.rapids.sql.format.parquet.multithreaded.combine.sizeBytes': '64m', 'spark.rapids.sql.format.parquet.multithreaded.read.keepOrder': True}]\r\nparquet-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_write_test.py::test_parquet_write_legacy_fallback[LEGACY-INT96][ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_write_test.py::test_parquet_write_legacy_fallback[LEGACY-TIMESTAMP_MICROS][ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_write_test.py::test_parquet_write_legacy_fallback[LEGACY-TIMESTAMP_MILLIS][INJECT_OOM, ALLOW_NON_GPU(DataWritingCommandExec,ExecutedCommandExec,WriteFilesExec)]\r\nparquet-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_write_test.py::test_partitioned_sql_parquet_write[PartitionWriteMode.Static][IGNORE_ORDER({'local': True})]\r\nparquet-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_write_test.py::test_partitioned_sql_parquet_write[PartitionWriteMode.Dynamic][INJECT_OOM, IGNORE_ORDER({'local': True})]\r\nparquet-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_write_test.py::test_dynamic_partitioned_parquet_write[INJECT_OOM, IGNORE_ORDER({'local': True})]\r\nparquet-write-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/parquet_write_test.py::test_hive_timestamp_value_fallback[INJECT_OOM, ALLOW_NON_GPU(DataWritingCommandExec,WriteFilesExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_project[orc-False][INJECT_OOM]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_project[orc-True]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_project[orc-False][INJECT_OOM, ALLOW_NON_GPU(ProjectExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_project[orc-True][ALLOW_NON_GPU(ProjectExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_filter_project[a-orc-False]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_filter_project[a-orc-True][INJECT_OOM]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_filter_project[b-orc-False][INJECT_OOM]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_filter_project[b-orc-True]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_filter_project[c-orc-False]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_filter_project[c-orc-True][INJECT_OOM]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_filter_and_project[a-orc-False][ALLOW_NON_GPU(ProjectExec,FilterExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_filter_and_project[a-orc-True][INJECT_OOM, ALLOW_NON_GPU(ProjectExec,FilterExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_filter_and_project[b-orc-False][ALLOW_NON_GPU(ProjectExec,FilterExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_filter_and_project[b-orc-True][INJECT_OOM, ALLOW_NON_GPU(ProjectExec,FilterExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_filter_and_project[c-orc-False][ALLOW_NON_GPU(ProjectExec,FilterExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_filter_and_project[c-orc-True][INJECT_OOM, ALLOW_NON_GPU(ProjectExec,FilterExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_filter_project[a-orc-False][INJECT_OOM, ALLOW_NON_GPU(FilterExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_filter_project[a-orc-True][ALLOW_NON_GPU(FilterExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_filter_project[b-orc-False][ALLOW_NON_GPU(FilterExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_filter_project[b-orc-True][ALLOW_NON_GPU(FilterExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_filter_project[c-orc-False][INJECT_OOM, ALLOW_NON_GPU(FilterExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_fallback_filter_project[c-orc-True][ALLOW_NON_GPU(FilterExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_filter_fallback_project[a-orc-False][INJECT_OOM, ALLOW_NON_GPU(ProjectExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_filter_fallback_project[a-orc-True][INJECT_OOM, ALLOW_NON_GPU(ProjectExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_filter_fallback_project[b-orc-False][ALLOW_NON_GPU(ProjectExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_filter_fallback_project[b-orc-True][ALLOW_NON_GPU(ProjectExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_filter_fallback_project[c-orc-False][ALLOW_NON_GPU(ProjectExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_prune_partition_column_when_filter_fallback_project[c-orc-True][ALLOW_NON_GPU(ProjectExec)]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_select_complex_field[orc-True-select friends.middle, friends from {} where p=1-struct<friends:array<struct<first:string,middle:string,last:string>>>]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_select_complex_field[orc-True-select name.first from {} where name.first = 'Jane'-struct<name:struct<first:string>>][INJECT_OOM]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_select_complex_field[orc-False-select friends.middle, friends from {} where p=1-struct<friends:array<struct<first:string,middle:string,last:string>>>]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_select_complex_field[orc-False-select name.first from {} where name.first = 'Jane'-struct<name:struct<first:string>>][INJECT_OOM]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_nested_column_prune_on_generator_output[orc-True-friend.First-struct<friends:array<struct<first:string>>>]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_nested_column_prune_on_generator_output[orc-True-friend.MIDDLE-struct<friends:array<struct<middle:string>>>]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_nested_column_prune_on_generator_output[orc-False-friend.First-struct<friends:array<struct<first:string>>>][INJECT_OOM]\r\nprune-partition-column-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/prune_partition_column_test.py::test_nested_column_prune_on_generator_output[orc-False-friend.MIDDLE-struct<friends:array<struct<middle:string>>>][INJECT_OOM]\r\nrow-based-udf-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/row-based_udf_test.py::test_hive_empty_simple_udf\r\nrow-based-udf-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/row-based_udf_test.py::test_hive_empty_generic_udf\r\nschema-evolution-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/schema_evolution_test.py::test_column_add_after_partition[parquet][IGNORE_ORDER({'local': True})]\r\nschema-evolution-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/schema_evolution_test.py::test_column_add_after_partition[orc][IGNORE_ORDER({'local': True})]\r\nudf-test_output.txt:FAILED ../../../../home/spark-rapids/integration_tests/src/main/python/udf_test.py::test_cogroup_apply_udf[Short(not_null)][INJECT_OOM, IGNORE_ORDER]\r\n\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1939201860/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1958716903",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10347#issuecomment-1958716903",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10347",
        "id": 1958716903,
        "node_id": "IC_kwDOD7z77c50v6Xn",
        "user": {
            "login": "NVnavkumar",
            "id": 97137715,
            "node_id": "U_kgDOBco0Mw",
            "avatar_url": "https://avatars.githubusercontent.com/u/97137715?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NVnavkumar",
            "html_url": "https://github.com/NVnavkumar",
            "followers_url": "https://api.github.com/users/NVnavkumar/followers",
            "following_url": "https://api.github.com/users/NVnavkumar/following{/other_user}",
            "gists_url": "https://api.github.com/users/NVnavkumar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NVnavkumar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NVnavkumar/subscriptions",
            "organizations_url": "https://api.github.com/users/NVnavkumar/orgs",
            "repos_url": "https://api.github.com/users/NVnavkumar/repos",
            "events_url": "https://api.github.com/users/NVnavkumar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NVnavkumar/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-02-22T05:14:49Z",
        "updated_at": "2024-02-22T05:14:49Z",
        "author_association": "COLLABORATOR",
        "body": "It looks like the test container (which contains the test files) being used was out of date. I tried just the arithmetic_ops_test.py tests with an updated container, and all the tests in that file pass. I think we should try this with an updated container and updated JAR and close this issue if all the tests pass.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1958716903/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1958719582",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10347#issuecomment-1958719582",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10347",
        "id": 1958719582,
        "node_id": "IC_kwDOD7z77c50v7Be",
        "user": {
            "login": "NVnavkumar",
            "id": 97137715,
            "node_id": "U_kgDOBco0Mw",
            "avatar_url": "https://avatars.githubusercontent.com/u/97137715?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NVnavkumar",
            "html_url": "https://github.com/NVnavkumar",
            "followers_url": "https://api.github.com/users/NVnavkumar/followers",
            "following_url": "https://api.github.com/users/NVnavkumar/following{/other_user}",
            "gists_url": "https://api.github.com/users/NVnavkumar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NVnavkumar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NVnavkumar/subscriptions",
            "organizations_url": "https://api.github.com/users/NVnavkumar/orgs",
            "repos_url": "https://api.github.com/users/NVnavkumar/repos",
            "events_url": "https://api.github.com/users/NVnavkumar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NVnavkumar/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-02-22T05:18:11Z",
        "updated_at": "2024-02-22T05:18:11Z",
        "author_association": "COLLABORATOR",
        "body": "> It looks like the test container (which contains the test files) being used was out of date. I tried just the arithmetic_ops_test.py tests with an updated container, and all the tests in that file pass. I think we should try this with an updated container and updated JAR and close this issue if all the tests pass.\r\n\r\nTo elaborate with more context, there are several integration tests that were updated when the Scala 2.13 build was enabled, and certain tests in arithmetic_ops_test (for certain) were skipped if the runtime detected Scala 2.13 (mostly because Spark built with Scala 2.13 had inconsistent behavior with high precision Decimal values)",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1958719582/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1986936934",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10347#issuecomment-1986936934",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10347",
        "id": 1986936934,
        "node_id": "IC_kwDOD7z77c52bkBm",
        "user": {
            "login": "NVnavkumar",
            "id": 97137715,
            "node_id": "U_kgDOBco0Mw",
            "avatar_url": "https://avatars.githubusercontent.com/u/97137715?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NVnavkumar",
            "html_url": "https://github.com/NVnavkumar",
            "followers_url": "https://api.github.com/users/NVnavkumar/followers",
            "following_url": "https://api.github.com/users/NVnavkumar/following{/other_user}",
            "gists_url": "https://api.github.com/users/NVnavkumar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NVnavkumar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NVnavkumar/subscriptions",
            "organizations_url": "https://api.github.com/users/NVnavkumar/orgs",
            "repos_url": "https://api.github.com/users/NVnavkumar/repos",
            "events_url": "https://api.github.com/users/NVnavkumar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NVnavkumar/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-09T18:08:19Z",
        "updated_at": "2024-03-09T18:08:19Z",
        "author_association": "COLLABORATOR",
        "body": "Decimal cast tests to integer are failing on CPU Spark here. Will defer those until later.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1986936934/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1989735149",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10347#issuecomment-1989735149",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10347",
        "id": 1989735149,
        "node_id": "IC_kwDOD7z77c52mPLt",
        "user": {
            "login": "NVnavkumar",
            "id": 97137715,
            "node_id": "U_kgDOBco0Mw",
            "avatar_url": "https://avatars.githubusercontent.com/u/97137715?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NVnavkumar",
            "html_url": "https://github.com/NVnavkumar",
            "followers_url": "https://api.github.com/users/NVnavkumar/followers",
            "following_url": "https://api.github.com/users/NVnavkumar/following{/other_user}",
            "gists_url": "https://api.github.com/users/NVnavkumar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NVnavkumar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NVnavkumar/subscriptions",
            "organizations_url": "https://api.github.com/users/NVnavkumar/orgs",
            "repos_url": "https://api.github.com/users/NVnavkumar/repos",
            "events_url": "https://api.github.com/users/NVnavkumar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NVnavkumar/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-12T01:21:27Z",
        "updated_at": "2024-03-12T01:21:27Z",
        "author_association": "COLLABORATOR",
        "body": "So in general, the challenge is that GCP Dataproc Serverless is currently using 23.12.1 of the plugin (makes sense, it's the latest release), so we need to use integration tests from that version of plugin. Re-running them with an updated container that only takes the tests from that version of plugin.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1989735149/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1998579475",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10347#issuecomment-1998579475",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10347",
        "id": 1998579475,
        "node_id": "IC_kwDOD7z77c53H-cT",
        "user": {
            "login": "NVnavkumar",
            "id": 97137715,
            "node_id": "U_kgDOBco0Mw",
            "avatar_url": "https://avatars.githubusercontent.com/u/97137715?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NVnavkumar",
            "html_url": "https://github.com/NVnavkumar",
            "followers_url": "https://api.github.com/users/NVnavkumar/followers",
            "following_url": "https://api.github.com/users/NVnavkumar/following{/other_user}",
            "gists_url": "https://api.github.com/users/NVnavkumar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NVnavkumar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NVnavkumar/subscriptions",
            "organizations_url": "https://api.github.com/users/NVnavkumar/orgs",
            "repos_url": "https://api.github.com/users/NVnavkumar/repos",
            "events_url": "https://api.github.com/users/NVnavkumar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NVnavkumar/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-14T22:23:07Z",
        "updated_at": "2024-03-14T22:23:07Z",
        "author_association": "COLLABORATOR",
        "body": "So a couple of fixes that have worked for several groups of tests:\r\n\r\n* Deploying a [Dataproc Metastore](https://cloud.google.com/dataproc-metastore/docs) that we configure with our integration test batches. This enables access to `saveAsTable()` and other Hive-related functionality.  This moves it further in line with how our nightly integration test runs are deployed. In particular, this helped enable all of the tests in parquet_test.py and hive tests to pass.  There are more tests spread out that have also moved from FAILED to PASSED.\r\n\r\n* Incorporating the JARs that are created for integration_tests. There are a few tests that rely on some classes defined in this part  of the codebase that aren't normally shipped with the release JAR.  So we add these to the custom container \r\n\r\n* Many tests are failing due to insufficient resources when using the test script, so we need to figure out how to detect that failure and re-run the set of tests.\r\n\r\nCurrent blockers:\r\n* ORC support is impacted by a class path issue. The relevant error is:\r\n```\r\nE                   Caused by: java.lang.NoSuchMethodError: 'com.google.protobuf.CodedInputStream org.apache.orc.impl.InStream.createCodedInputStream(org.apache.orc.impl.InStream)'\r\nE                   \tat com.nvidia.spark.rapids.shims.OrcShims320untilAllBase.$anonfun$parseFooterFromBuffer$1(OrcShims320untilAllBase.scala:153)\r\nE                   \tat com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:29)\r\nE                   \tat com.nvidia.spark.rapids.shims.OrcShims320untilAllBase.parseFooterFromBuffer(OrcShims320untilAllBase.scala:148)\r\nE                   \tat com.nvidia.spark.rapids.shims.OrcShims320untilAllBase.parseFooterFromBuffer$(OrcShims320untilAllBase.scala:140)\r\nE                   \tat com.nvidia.spark.rapids.shims.OrcShims$.parseFooterFromBuffer(OrcShims.scala:34)\r\nE                   \tat com.nvidia.spark.rapids.GpuOrcFileFilterHandler$.loadOrcTailFromBuffer(GpuOrcScan.scala:1795)\r\nE                   \tat com.nvidia.spark.rapids.GpuOrcFileFilterHandler$.com$nvidia$spark$rapids$GpuOrcFileFilterHandler$$getOrcTail(GpuOrcScan.scala:1780)\r\nE                   \tat com.nvidia.spark.rapids.GpuOrcFileFilterHandler.filterStripes(GpuOrcScan.scala:1328)\r\nE                   \tat com.nvidia.spark.rapids.MultiFileCloudOrcPartitionReader$ReadBatchRunner.doRead(GpuOrcScan.scala:2051)\r\nE                   \tat com.nvidia.spark.rapids.MultiFileCloudOrcPartitionReader$ReadBatchRunner.call(GpuOrcScan.scala:2029)\r\nE                   \tat com.nvidia.spark.rapids.MultiFileCloudOrcPartitionReader$ReadBatchRunner.call(GpuOrcScan.scala:2018)\r\nE                   \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n```\r\n\r\nThis particular issue is currently responsible for the majority of current test failures on Dataproc Serverless.\r\n\r\n* Decimal support in cast_test.py.  This is actually a CPU failure where Dataproc Serverless seemingly runs into a codepath in Apache Spark that doesn't handle negative scale well. This also only happens in integration tests and not in the notebook environment.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1998579475/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2115873769",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10347#issuecomment-2115873769",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10347",
        "id": 2115873769,
        "node_id": "IC_kwDOD7z77c5-Havp",
        "user": {
            "login": "NVnavkumar",
            "id": 97137715,
            "node_id": "U_kgDOBco0Mw",
            "avatar_url": "https://avatars.githubusercontent.com/u/97137715?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NVnavkumar",
            "html_url": "https://github.com/NVnavkumar",
            "followers_url": "https://api.github.com/users/NVnavkumar/followers",
            "following_url": "https://api.github.com/users/NVnavkumar/following{/other_user}",
            "gists_url": "https://api.github.com/users/NVnavkumar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NVnavkumar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NVnavkumar/subscriptions",
            "organizations_url": "https://api.github.com/users/NVnavkumar/orgs",
            "repos_url": "https://api.github.com/users/NVnavkumar/repos",
            "events_url": "https://api.github.com/users/NVnavkumar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NVnavkumar/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-05-16T17:58:06Z",
        "updated_at": "2024-05-16T17:58:06Z",
        "author_association": "COLLABORATOR",
        "body": "Update on ORC support:\r\n\r\nGoogle uses an ORC jar with a shaded protobuf:\r\n\r\n `orc-core-1.8.6-shaded-protobuf.jar`, so I'm guessing that `org.apache.orc.impl.InStream.createCodedInputStream(org.apache.orc.impl.InStream)` is probably returning a version of CodedInputStream in a shaded package path.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2115873769/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2116305068",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10347#issuecomment-2116305068",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10347",
        "id": 2116305068,
        "node_id": "IC_kwDOD7z77c5-JECs",
        "user": {
            "login": "NVnavkumar",
            "id": 97137715,
            "node_id": "U_kgDOBco0Mw",
            "avatar_url": "https://avatars.githubusercontent.com/u/97137715?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NVnavkumar",
            "html_url": "https://github.com/NVnavkumar",
            "followers_url": "https://api.github.com/users/NVnavkumar/followers",
            "following_url": "https://api.github.com/users/NVnavkumar/following{/other_user}",
            "gists_url": "https://api.github.com/users/NVnavkumar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NVnavkumar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NVnavkumar/subscriptions",
            "organizations_url": "https://api.github.com/users/NVnavkumar/orgs",
            "repos_url": "https://api.github.com/users/NVnavkumar/repos",
            "events_url": "https://api.github.com/users/NVnavkumar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NVnavkumar/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-05-16T22:26:10Z",
        "updated_at": "2024-05-16T22:26:10Z",
        "author_association": "COLLABORATOR",
        "body": "> Update on ORC support:\r\n> \r\n> Google uses an ORC jar with a shaded protobuf:\r\n> \r\n> `orc-core-1.8.6-shaded-protobuf.jar`, so I'm guessing that `org.apache.orc.impl.InStream.createCodedInputStream(org.apache.orc.impl.InStream)` is probably returning a version of CodedInputStream in a shaded package path.\r\n\r\nI was actually able to simulate the GCP serverless environment issue this by replacing the following jars in $SPARK_HOME:\r\n\r\norc-core-1.7.10.jar ---> orc-core-1.8.6-shaded-protobuf.jar\r\norc-mapreduce-1.7.10.jar ---> orc-mapreduce-1.8.6-shaded-protobuf.jar\r\norc-shims-1.7.10.jar ---> orc-shims-1.8.6.jar\r\nprotobuf-java-2.5.0.jar ---> protobuf-java-3.21.12.jar\r\n ",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2116305068/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2137606901",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10347#issuecomment-2137606901",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10347",
        "id": 2137606901,
        "node_id": "IC_kwDOD7z77c5_aUr1",
        "user": {
            "login": "NVnavkumar",
            "id": 97137715,
            "node_id": "U_kgDOBco0Mw",
            "avatar_url": "https://avatars.githubusercontent.com/u/97137715?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NVnavkumar",
            "html_url": "https://github.com/NVnavkumar",
            "followers_url": "https://api.github.com/users/NVnavkumar/followers",
            "following_url": "https://api.github.com/users/NVnavkumar/following{/other_user}",
            "gists_url": "https://api.github.com/users/NVnavkumar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NVnavkumar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NVnavkumar/subscriptions",
            "organizations_url": "https://api.github.com/users/NVnavkumar/orgs",
            "repos_url": "https://api.github.com/users/NVnavkumar/repos",
            "events_url": "https://api.github.com/users/NVnavkumar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NVnavkumar/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-05-29T14:49:18Z",
        "updated_at": "2024-05-29T14:49:18Z",
        "author_association": "COLLABORATOR",
        "body": "The ORC tests in `orc_test.py` actually pass with Serverless Runtime 2.1, which uses Spark 3.4.1 and our shim already handles the orc with shaded protobuf JARs.  However, there are other failures to investigate, which could be test-related.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/2137606901/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]