[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1411095655",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7616#issuecomment-1411095655",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7616",
        "id": 1411095655,
        "node_id": "IC_kwDOD7z77c5UG5xn",
        "user": {
            "login": "sameerz",
            "id": 7036315,
            "node_id": "MDQ6VXNlcjcwMzYzMTU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7036315?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sameerz",
            "html_url": "https://github.com/sameerz",
            "followers_url": "https://api.github.com/users/sameerz/followers",
            "following_url": "https://api.github.com/users/sameerz/following{/other_user}",
            "gists_url": "https://api.github.com/users/sameerz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sameerz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sameerz/subscriptions",
            "organizations_url": "https://api.github.com/users/sameerz/orgs",
            "repos_url": "https://api.github.com/users/sameerz/repos",
            "events_url": "https://api.github.com/users/sameerz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sameerz/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-01-31T21:31:13Z",
        "updated_at": "2023-01-31T21:31:13Z",
        "author_association": "COLLABORATOR",
        "body": "We should switch to the new JSON reader per issue #[7518](https://github.com/NVIDIA/spark-rapids/issues/7518)",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1411095655/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1894714393",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7616#issuecomment-1894714393",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7616",
        "id": 1894714393,
        "node_id": "IC_kwDOD7z77c5w7wwZ",
        "user": {
            "login": "andygrove",
            "id": 934084,
            "node_id": "MDQ6VXNlcjkzNDA4NA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/934084?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/andygrove",
            "html_url": "https://github.com/andygrove",
            "followers_url": "https://api.github.com/users/andygrove/followers",
            "following_url": "https://api.github.com/users/andygrove/following{/other_user}",
            "gists_url": "https://api.github.com/users/andygrove/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/andygrove/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/andygrove/subscriptions",
            "organizations_url": "https://api.github.com/users/andygrove/orgs",
            "repos_url": "https://api.github.com/users/andygrove/repos",
            "events_url": "https://api.github.com/users/andygrove/events{/privacy}",
            "received_events_url": "https://api.github.com/users/andygrove/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-01-17T00:06:33Z",
        "updated_at": "2024-01-17T00:06:33Z",
        "author_association": "CONTRIBUTOR",
        "body": "I just re-tested this, and it is still an issue even after switching to the new engine.\r\n\r\n```\r\nscala> spark.read.json(\"no-body.json\").show\r\n24/01/17 00:02:09 WARN GpuOverrides: \r\n!Exec <FileSourceScanExec> cannot run on GPU because unsupported file format: org.apache.spark.sql.execution.datasources.text.TextFileFormat\r\n\r\n24/01/17 00:02:09 WARN GpuOverrides: \r\n!Exec <CollectLimitExec> cannot run on GPU because the Exec CollectLimitExec has been disabled, and is disabled by default because Collect Limit replacement can be slower on the GPU, if huge number of rows in a batch it could help by limiting the number of rows transferred from GPU to CPU. Set spark.rapids.sql.exec.CollectLimitExec to true if you wish to enable it\r\n  @Partitioning <SinglePartition$> could run on GPU\r\n  *Exec <FileSourceScanExec> will run on GPU\r\n\r\n24/01/17 00:02:09 ERROR Executor: Exception in task 0.0 in stage 6.0 (TID 6)\r\njava.lang.UnsupportedOperationException: empty.min\r\n\tat scala.collection.TraversableOnce.min(TraversableOnce.scala:227)\r\n\tat scala.collection.TraversableOnce.min$(TraversableOnce.scala:225)\r\n\tat org.apache.spark.sql.types.StructType.min(StructType.scala:102)\r\n\tat com.nvidia.spark.rapids.GpuTextBasedPartitionReader.readToTable(GpuTextBasedPartitionReader.scala:298)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1894714393/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1894735320",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7616#issuecomment-1894735320",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7616",
        "id": 1894735320,
        "node_id": "IC_kwDOD7z77c5w713Y",
        "user": {
            "login": "andygrove",
            "id": 934084,
            "node_id": "MDQ6VXNlcjkzNDA4NA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/934084?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/andygrove",
            "html_url": "https://github.com/andygrove",
            "followers_url": "https://api.github.com/users/andygrove/followers",
            "following_url": "https://api.github.com/users/andygrove/following{/other_user}",
            "gists_url": "https://api.github.com/users/andygrove/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/andygrove/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/andygrove/subscriptions",
            "organizations_url": "https://api.github.com/users/andygrove/orgs",
            "repos_url": "https://api.github.com/users/andygrove/repos",
            "events_url": "https://api.github.com/users/andygrove/events{/privacy}",
            "received_events_url": "https://api.github.com/users/andygrove/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-01-17T00:29:15Z",
        "updated_at": "2024-01-17T00:29:15Z",
        "author_association": "CONTRIBUTOR",
        "body": "This only seems to be an issue for a JSON file that only contains empty entries.  If there is at least one non-empty row, then we match Spark.\r\n\r\n```\r\n$ cat with-body.json \r\n{}\r\n{ \"a\": 4 }\r\n```\r\n\r\n```\r\nscala> spark.read.json(\"with-body.json\").show\r\n24/01/17 00:26:26 WARN GpuOverrides: \r\n!Exec <FileSourceScanExec> cannot run on GPU because unsupported file format: org.apache.spark.sql.execution.datasources.text.TextFileFormat\r\n\r\n24/01/17 00:26:26 WARN GpuOverrides: \r\n!Exec <CollectLimitExec> cannot run on GPU because the Exec CollectLimitExec has been disabled, and is disabled by default because Collect Limit replacement can be slower on the GPU, if huge number of rows in a batch it could help by limiting the number of rows transferred from GPU to CPU. Set spark.rapids.sql.exec.CollectLimitExec to true if you wish to enable it\r\n  @Partitioning <SinglePartition$> could run on GPU\r\n  *Exec <ProjectExec> will run on GPU\r\n    *Expression <Alias> cast(a#22L as string) AS a#25 will run on GPU\r\n      *Expression <Cast> cast(a#22L as string) will run on GPU\r\n    !Exec <FileSourceScanExec> cannot run on GPU because JSON input and output has been disabled. To enable set spark.rapids.sql.format.json.enabled to true\r\n\r\n+----+\r\n|   a|\r\n+----+\r\n|null|\r\n|   4|\r\n+----+\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1894735320/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1995836099",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7616#issuecomment-1995836099",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7616",
        "id": 1995836099,
        "node_id": "IC_kwDOD7z77c529grD",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-13T21:12:20Z",
        "updated_at": "2024-03-13T21:12:20Z",
        "author_association": "COLLABORATOR",
        "body": "@res-life are you still planning on working on this?\r\n\r\nThe failures are happening in two places. If you don't provide a schema, then schema discovery returns with an empty schema. CUDF does not like this so we try to make one up, and try to pull something out of the dataSchema, which is also empty and results in a crash.\r\n\r\nIf we do provide a schema, then we run into a null pointer exception when trying to read the data.\r\n\r\n```\r\nspark.read.schema(\"a string\").json(\"./no-body.json\").show\r\n...\r\nCaused by: java.lang.NullPointerException\r\n  at ai.rapids.cudf.TableWithMeta.getColumnNames(TableWithMeta.java:132)\r\n  at ai.rapids.cudf.Table.gatherJSONColumns(Table.java:1211)\r\n  at ai.rapids.cudf.Table.readJSON(Table.java:1373)\r\n  at org.apache.spark.sql.catalyst.json.rapids.JsonPartitionReader$.$anonfun$readToTable$2(GpuJsonScan.scala:325)\r\n  at com.nvidia.spark.rapids.Arm$.withResource(Arm.scala:30)\r\n  at org.apache.spark.sql.catalyst.json.rapids.JsonPartitionReader$.$anonfun$readToTable$1(GpuJsonScan.scala:323)\r\n  at com.nvidia.spark.rapids.RmmRapidsRetryIterator$AutoCloseableAttemptSpliterator.next(RmmRapidsRetryIterator.scala:477)\r\n  at com.nvidia.spark.rapids.RmmRapidsRetryIterator$RmmRapidsRetryIterator.next(RmmRapidsRetryIterator.scala:613)\r\n  at com.nvidia.spark.rapids.RmmRapidsRetryIterator$RmmRapidsRetryAutoCloseableIterator.next(RmmRapidsRetryIterator.scala:517)\r\n```\r\n\r\nWe should not be trying to use the data schema if the read data schema is empty.  That might result in us reading in the wrong data if it actually succeeded, because the only time that readDataSchema is empty but data schema is not is if we have partition columns.\r\n\r\nIn the short term I think we just need to fall back to the CPU if the readDataSchema is empty, and we should concentrate on fixing the null pointer exception.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1995836099/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1998732252",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/7616#issuecomment-1998732252",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/7616",
        "id": 1998732252,
        "node_id": "IC_kwDOD7z77c53Ijvc",
        "user": {
            "login": "res-life",
            "id": 8166419,
            "node_id": "MDQ6VXNlcjgxNjY0MTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8166419?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/res-life",
            "html_url": "https://github.com/res-life",
            "followers_url": "https://api.github.com/users/res-life/followers",
            "following_url": "https://api.github.com/users/res-life/following{/other_user}",
            "gists_url": "https://api.github.com/users/res-life/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/res-life/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/res-life/subscriptions",
            "organizations_url": "https://api.github.com/users/res-life/orgs",
            "repos_url": "https://api.github.com/users/res-life/repos",
            "events_url": "https://api.github.com/users/res-life/events{/privacy}",
            "received_events_url": "https://api.github.com/users/res-life/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-03-15T01:22:44Z",
        "updated_at": "2024-03-15T01:23:04Z",
        "author_association": "COLLABORATOR",
        "body": "> @res-life are you still planning on working on this?\r\n\r\nNo, I'm now focusing on `get-json-object` issues, maybe anyone else can take this.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1998732252/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]