[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/959803463",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/9#issuecomment-959803463",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9",
        "id": 959803463,
        "node_id": "IC_kwDOD7z77c45NXBH",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-03T18:22:26Z",
        "updated_at": "2021-11-03T18:22:26Z",
        "author_association": "COLLABORATOR",
        "body": "We have had a customer ask about this, so we might bump up the priority on this.  I have been looking at the JSON parsing and how that relates to the existing CSV parsing.  Just like CSV parsing it is not great, but I think we could do with JSON what we want to do with CSV and parse all of the atomic types as Strings and then handle casting/parsing them ourselves. This will make the code a lot more robust in terms of Spark compatibility.  But there are still a number of issues that we have to look into and probably address.\r\n\r\n\r\n 1. The current CUDF code does not support nested types for parsing JSON. https://github.com/rapidsai/cudf/issues/8827 should fix that, but it is not done yet.\r\n 2. The current CUDF code parses types how they want to, and not how Spark wants them to be parsed.  Like I said above we might be able to ask CUDF to read all of the types as Strings and then parse them ourselves. This will not fix everything because looking at cast there are a number of types that we do not fully support when casting from a string still. But it will be a step in the right direction and should let us avoid most of the enable this type for JSON configs.  We could at a minimum reused the cast from string configs that already exist.\r\n 3. \"allowSingleQuotes\" option. This is set to true by default so Spark allows parsing values with single quotes instead of just double quotes. The CUDF code does not. So we probably want to file an issue with CUDF to ask for this, and also in the short term document that we cannot support this.\r\n 4. There are also a number of configs in Spark that we will need to play around with in CUDF, but I am fairly sure if they are enabled we will have to fall back to the CPU, or at least really document well the inconsistencies.  These include\r\n   a. \"allowComments\" C/C++ style comments `//` and `/* */`\r\n   b. \"allowUnquotesFieldNames\"\r\n   c. \"allowNumericLeadingZeros\" Here the parser strips the leading zeros for numeric JSON types instead of marking them as corrupt entries, so if I had something like `{\"a\": 0001, \"b\": 01.1000000000}` both entries would cause the row to be marked as corrupt. Even if we provide a schema an ask for both a and b to be strings they show up as nulls because the values are technically corrupt. If I set the option to true they are parsed, but the leading and in the case of the float, trailing zeros are stripped from the resulting string.\r\n   d. \"allowNonNumericNumbers\" The docs say that this mean INF, -INF, and NaN but I could not make INF work, just -INF. Not sure how well used this is.\r\n   e. \"allowBackslashEscapingAnyCharacter\" typically only a few chars in the JSON standard are allowed. In CUDF they only support \\\", \\\\, \\t, \\r, and \\b.  Not sure if there are others in JSON or not. Also not sure what happens if CUDF if others are encountered vs in Spark.\r\n   f. \"allowUnquotedControlChars\" Docs say ASCII characters with a value less than 32.  My guess is CUDF just allows these all the time.\r\n5. The \"parseMode\" and \"columnNameOfCorruptRecord\" parse mode config probably needs to always be lenient and we need to fall back to the CPU like with CSV if we ever see the columnNameOfCorruptRecord in the schema. We just don't support that and I don't know what it would take for CUDF to be able to do it.\r\n6. \"ignoreNullFields\" and \"dropFieldIfAllNull\" are things we might be able to do with post processing, but we need to play around with it a little.\r\n7. IF we see multi-line we have to fall back to the CPU. We just cannot support it.\r\n8. We need to look at encodings and see if we have to fall back to the CPU or not. I hope that we can normalize things as we read it in like we do with the line ending in CSV and will have to do with the line ending here, but I am not 100% sure on that.\r\n9. We need to check the zoneId like with CSV and fallback if it is not UTC\r\n10. Need to check the date/timestamp formats too and see if there is anything in there that we cannot support.\r\n11. We also need to play around with JSON parsing in general and see what falls out.  It looks like Spark is fairly strict in parsing and there can be odd corner cases. For example it looks like unquoted number values, if they are going to be interpreted as a string, are parsed as numbers first and then cast to a string, So 3.00 becomes 3.0 but \"3.00\" remains unchanged. I don't see any way we can match this behavior and probably will just need to document it.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/959803463/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/959809596",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/9#issuecomment-959809596",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9",
        "id": 959809596,
        "node_id": "IC_kwDOD7z77c45NYg8",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-03T18:30:12Z",
        "updated_at": "2021-11-03T18:30:12Z",
        "author_association": "COLLABORATOR",
        "body": "Oh, also a single line can contain multiple entries if the top level is an array.\r\n\r\n```\r\n[{\"a\": 1, \"b\": 1}, {\"a\": 2}]\r\n[{\"a\": 1, \"b\": 2.0}]\r\n{\"a\": 1, \"b\": \"inf\"}\r\n```\r\nproduces\r\n\r\n```\r\n+---+----+\r\n|  a|   b|\r\n+---+----+\r\n|  1|   1|\r\n|  2|null|\r\n|  1| 2.0|\r\n|  1| inf|\r\n+---+----+\r\n```\r\nBut if there is extra JSON like stuff at the end of the line, it is ignored.\r\n\r\n```\r\n{\"a\": 1, \"b\": 1}, {\"other\": 2}\r\n{\"a\": 1, \"b\": \"inf\"} garbage\r\n{\"a\": 1, \"b\": 1} {\"more\": 2}\r\n```\r\n\r\nproduces the following with no errors.  Which feels really odd to me.\r\n\r\n```\r\n+---+---+\r\n|  a|  b|\r\n+---+---+\r\n|  1|  1|\r\n|  1|inf|\r\n|  1|  1|\r\n+---+---+\r\n```\r\n\r\nThere may be a lot of other odd cases, that we need to look into.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/959809596/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/959811580",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/9#issuecomment-959811580",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9",
        "id": 959811580,
        "node_id": "IC_kwDOD7z77c45NY_8",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-03T18:32:59Z",
        "updated_at": "2021-11-03T18:32:59Z",
        "author_association": "COLLABORATOR",
        "body": "We might want to look at some of the Spark JSON tests, but they are not that complete.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/959811580/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/959822790",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/9#issuecomment-959822790",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9",
        "id": 959822790,
        "node_id": "IC_kwDOD7z77c45NbvG",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-03T18:48:17Z",
        "updated_at": "2021-11-03T18:48:17Z",
        "author_association": "COLLABORATOR",
        "body": "Oh that is interesting. The parsing of the JSON keys is case sensitive, but auto detection of the schema is not totally so you can get errors if you let Spark detect the schema and there are keys with different cases. i.e. A vs a. So we should test if we can select the keys in a case sensitive way.\r\n\r\nAlso if there are multiple keys in a record. For spark it looks like the last one wins. Not sure what CUDF does in those cases.\r\n\r\n```\r\n{\"a\": 1, \"b\": 1}\r\n{\"a\": 1, \"a\": 2}\r\n{\"a\": 1, \"b\": 1}\r\n```\r\n\r\nproduces\r\n\r\n```\r\n+---+----+\r\n|  a|   b|\r\n+---+----+\r\n|  1|   1|\r\n|  2|null|\r\n|  1|   1|\r\n+---+----+\r\n```\r\n\r\nwith no errors",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/959822790/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/959828103",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/9#issuecomment-959828103",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/9",
        "id": 959828103,
        "node_id": "IC_kwDOD7z77c45NdCH",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-03T18:54:49Z",
        "updated_at": "2021-11-03T18:54:49Z",
        "author_association": "COLLABORATOR",
        "body": "Added Needs Triage back on so we can look at this again because I think most of the analysis of this is done.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/959828103/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]