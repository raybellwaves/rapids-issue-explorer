[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1202922081",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6149#issuecomment-1202922081",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6149",
        "id": 1202922081,
        "node_id": "IC_kwDOD7z77c5HsyJh",
        "user": {
            "login": "jlowe",
            "id": 1360766,
            "node_id": "MDQ6VXNlcjEzNjA3NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1360766?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jlowe",
            "html_url": "https://github.com/jlowe",
            "followers_url": "https://api.github.com/users/jlowe/followers",
            "following_url": "https://api.github.com/users/jlowe/following{/other_user}",
            "gists_url": "https://api.github.com/users/jlowe/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jlowe/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jlowe/subscriptions",
            "organizations_url": "https://api.github.com/users/jlowe/orgs",
            "repos_url": "https://api.github.com/users/jlowe/repos",
            "events_url": "https://api.github.com/users/jlowe/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jlowe/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-02T16:08:14Z",
        "updated_at": "2022-08-02T16:08:14Z",
        "author_association": "MEMBER",
        "body": "Note that for the CHAR type, casting to a string requires stripping the trailing whitespaces from the value to match the CPU behavior.  See https://github.com/NVIDIA/spark-rapids/pull/6188#discussion_r935683053.  It would be nice if we could ask libcudf to load the CHAR column by stripping trailing whitespace instead of adding it, so we don't have to perform a post-processing step on the CHAR columns.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1202922081/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1210457354",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6149#issuecomment-1210457354",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6149",
        "id": 1210457354,
        "node_id": "IC_kwDOD7z77c5IJh0K",
        "user": {
            "login": "sinkinben",
            "id": 31923950,
            "node_id": "MDQ6VXNlcjMxOTIzOTUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/31923950?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sinkinben",
            "html_url": "https://github.com/sinkinben",
            "followers_url": "https://api.github.com/users/sinkinben/followers",
            "following_url": "https://api.github.com/users/sinkinben/following{/other_user}",
            "gists_url": "https://api.github.com/users/sinkinben/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sinkinben/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sinkinben/subscriptions",
            "organizations_url": "https://api.github.com/users/sinkinben/orgs",
            "repos_url": "https://api.github.com/users/sinkinben/repos",
            "events_url": "https://api.github.com/users/sinkinben/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sinkinben/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-10T10:09:39Z",
        "updated_at": "2022-09-06T07:12:36Z",
        "author_association": "CONTRIBUTOR",
        "body": "I divide these castings into these subcategories, according to the source type.\r\n\r\n- [X] `integer -> integer` (It was done in #5960 .)\r\n- [x] `bool/int8/int16/int32/int64 -> {string, float, double(float64), timestamp}`. \r\n  + Issue #6272 \r\n  + PR #6273 \r\n----\r\n- [x] `float32 -> {bool, integer types, double, string, timestamp}`\r\n- [x] `double  -> {bool, integer types, float32, string, timestamp}`\r\n  + Issue #6291\r\n  + PR #6319\r\n----\r\n- [ ] [Pending] `date -> {string, timestamp}`\r\n  + Issue #6357 \r\n  + [branch: orc-cast-date](https://github.com/sinkinben/spark-rapids/commit/c293a1173905670ecdcd85b8ca82a54b199f7109)\r\n----\r\n- [ ] [Pending] `string  -> {bool, integer types, float32, double, timestamp, date}`\r\n  + Issue #6394 \r\n  + Draft PR #6411 \r\n\r\n----\r\n\r\n- [ ] `timestamp -> {integer types, float32, double, string, date}`\r\n\r\n\r\nTwo special case:\r\n- [ ] `decimal <-> {bool, integer types, float, double, string, timestamp}`\r\n- [ ] `binary <-> string`\r\n\r\nWhitespaces of char/varchar/string should be paied attention to, which is mentioned above.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1210457354/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1217733527",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6149#issuecomment-1217733527",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6149",
        "id": 1217733527,
        "node_id": "IC_kwDOD7z77c5IlSOX",
        "user": {
            "login": "sinkinben",
            "id": 31923950,
            "node_id": "MDQ6VXNlcjMxOTIzOTUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/31923950?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sinkinben",
            "html_url": "https://github.com/sinkinben",
            "followers_url": "https://api.github.com/users/sinkinben/followers",
            "following_url": "https://api.github.com/users/sinkinben/following{/other_user}",
            "gists_url": "https://api.github.com/users/sinkinben/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sinkinben/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sinkinben/subscriptions",
            "organizations_url": "https://api.github.com/users/sinkinben/orgs",
            "repos_url": "https://api.github.com/users/sinkinben/repos",
            "events_url": "https://api.github.com/users/sinkinben/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sinkinben/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-17T09:19:05Z",
        "updated_at": "2022-08-31T09:21:24Z",
        "author_association": "CONTRIBUTOR",
        "body": "## A Summary of Implementation Details\r\n\r\n**Casting from Integer Types**\r\n\r\n| Casting                                | Implementation Description                                   |\r\n| :------------------------------------- | :----------------------------------------------------------- |\r\n| `bool -> float/double`                 | Based on `ColumnVector.castTo` in cuDF.                      |\r\n| `bool -> string`                       | Call `castTo`, and convert them into upper cases `TRUE/FALSE` (as CPU code did). |\r\n| `int8/16/32/64 -> float/double/string` | Call `castTo`                                                |\r\n| `bool/int8/16/32 -> timestamp`         | The original value is in seconds, and convert them into micro-seconds. Since `timestamp` is stored in `int64`, there is no integer-overflow. |\r\n| `int64 -> timestamp`                   | 1. From spark311 until spark320 (inluding 311, 312, 313, 314), they consider the integers as milliseconds when casting integers to timestamp. <br />2. For spark320+ (including spark320), they consider the integers as seconds.<br />3. For both cases, convert them to microseconds. |\r\n\r\n\r\n\r\n\r\n\r\n**Casting from Float types**\r\n\r\n| Casting                                 | Implementation Description                                   |\r\n| --------------------------------------- | ------------------------------------------------------------ |\r\n| `float/double -> {bool, int8/16/32/64}` | 1. First replace rows that cannot fit in long with nulls.<br />2. Convert the ColumnVector to Long type<br />3. Down cast long to the target integral type. |\r\n| `float <-> double`                      | 1. Call `ColumnView.castTo`. <br />2. When casting `double -> float`, if `double` value is greater than `FLOAT_MAX`, then mark this value with `Infinite`. |\r\n| `float/double -> string`                | 1. cuDF keep 9 decimal numbers after the decimal point, and CPU keeps more than 10.<br />2. Added a config item `spark.rapids.sql.format.orc.floatTypesToString.enable` (default value is true) to control whether if we can cast `float/double -> string` while reading ORC. |\r\n| `float/double -> timestamp`             | 1. ORC assumes the original `float/double` values are in seconds.<br />2. If `ROUND(val * 1000) > LONG_MAX` , replace it with null, e.g. `val = 1e20`. Otherwise, keep these values, and convert them into milli-seonds vector.<br />3. Multiply 1000, convert them into micro-seconds vector. Pay attention to long(INT64) overflow here, since timestamp is stored in `INT64`. |\r\n\r\n\r\n**Casting from string**\r\n\r\n| Casting                        | Implementation Description                                   |\r\n| ------------------------------ | ------------------------------------------------------------ |\r\n| `string -> bool/int8/16/32/64` | 1. Check the pattern of input strings by regular expression, replace invalid strings with `null`.<br />2. Follow the CPU ORC conversion. Firstly convert string to long, then down cast long to target integral type.<br />3. For `string -> bool`, cases `\"true\",\"false` are invalid, they should be `\"0\", \"1\"`. |\r\n| `string -> float/double`       | 1. Check the pattern of input strings by regex. The leading/trailing spaces should be ignored. Replace the invalid strings with `null`.<br />2. Call `castTo(FLOAT)` or `castTo(DOUBLE)` in cuDF. |\r\n| `string -> date/timestamp`     | Working on it.                                               |\r\n\r\n\r\n**Casting from Date types (TODO)**\r\n\r\n| Casting             | Implementation Description                                   |\r\n| ------------------- | ------------------------------------------------------------ |\r\n| `date -> string`    | Call `ColumnView.asString()`, and it will call `asStrings(\"%Y-%m-%d\")` inside. |\r\n| `date -> timestamp` | 1. Convert the `date` columnar vector into `INT64` type.<br />2. Multiply it with `24 * 60 * 60 * 1e6`, and then convert it into `TIMESTAMP_MICROSECONDS`. |\r\n\r\n\r\nHowever, there are still some issues. For more details, see the comments in #6357 .\r\n\r\nHere is the [Code branch](https://github.com/sinkinben/spark-rapids/commit/c293a1173905670ecdcd85b8ca82a54b199f7109).\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1217733527/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1231220260",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/6149#issuecomment-1231220260",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/6149",
        "id": 1231220260,
        "node_id": "IC_kwDOD7z77c5JYu4k",
        "user": {
            "login": "sinkinben",
            "id": 31923950,
            "node_id": "MDQ6VXNlcjMxOTIzOTUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/31923950?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sinkinben",
            "html_url": "https://github.com/sinkinben",
            "followers_url": "https://api.github.com/users/sinkinben/followers",
            "following_url": "https://api.github.com/users/sinkinben/following{/other_user}",
            "gists_url": "https://api.github.com/users/sinkinben/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sinkinben/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sinkinben/subscriptions",
            "organizations_url": "https://api.github.com/users/sinkinben/orgs",
            "repos_url": "https://api.github.com/users/sinkinben/repos",
            "events_url": "https://api.github.com/users/sinkinben/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sinkinben/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-08-30T06:45:32Z",
        "updated_at": "2022-08-30T06:46:06Z",
        "author_association": "CONTRIBUTOR",
        "body": "As the discussion mentioned in https://github.com/apache/orc/issues/1237, \r\n> Both Apache Spark and ORC community recommend to use explicit SQL CAST method instead of depending on data source's Schema Evolution.\r\n\r\nThat is we can replace Schema evolution with `CAST` in SQL. \r\n\r\nFor example, if we have an ORC file, it contains one column `date_str`, and `date_str` is some strings with a pattern of `YYYY-mm-dd`.\r\n```shell\r\n# Read `date_str` in type of string, do not use schema evolution\r\nscala> var df = spark.read.schema(\"date_str string\").orc(\"/tmp/orc/data.orc\");\r\nscala> df.show()\r\n+----------+\r\n|  date_str|\r\n+----------+\r\n|2002-01-01|\r\n|2022-08-29|\r\n|2022-08-31|\r\n|2022-01-32|\r\n|9808-02-30|\r\n|2022-06-31|\r\n+----------+\r\n# Cast `date_str` to type of `date`, using SQL-CAST\r\nscala> df.registerTempTable(\"table\")\r\nscala> df.sqlContext.sql(\"select CAST(date_str as date) from table\").show()\r\n+----------+\r\n|  date_str|\r\n+----------+\r\n|2002-01-01|\r\n|2022-08-29|\r\n|2022-08-31|\r\n|      null|\r\n|      null|\r\n|      null|\r\n+----------+\r\n\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1231220260/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]