[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1863515964",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10045#issuecomment-1863515964",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10045",
        "id": 1863515964,
        "node_id": "IC_kwDOD7z77c5vEv88",
        "user": {
            "login": "mattahrens",
            "id": 5303895,
            "node_id": "MDQ6VXNlcjUzMDM4OTU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5303895?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mattahrens",
            "html_url": "https://github.com/mattahrens",
            "followers_url": "https://api.github.com/users/mattahrens/followers",
            "following_url": "https://api.github.com/users/mattahrens/following{/other_user}",
            "gists_url": "https://api.github.com/users/mattahrens/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mattahrens/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mattahrens/subscriptions",
            "organizations_url": "https://api.github.com/users/mattahrens/orgs",
            "repos_url": "https://api.github.com/users/mattahrens/repos",
            "events_url": "https://api.github.com/users/mattahrens/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mattahrens/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-12-19T21:45:21Z",
        "updated_at": "2023-12-19T21:45:21Z",
        "author_association": "COLLABORATOR",
        "body": "Is the issue that the current output should not be recommending `spark.rapids.sql.format.hive.text.write.enabled to true` because it is already true?  Instead, you want it to recommend this: `spark.sql.hive.convertMetastoreParquet=true`.  Just want to confirm that is sufficient for the desired output.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1863515964/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1870567998",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10045#issuecomment-1870567998",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10045",
        "id": 1870567998,
        "node_id": "IC_kwDOD7z77c5vfpo-",
        "user": {
            "login": "viadea",
            "id": 9665750,
            "node_id": "MDQ6VXNlcjk2NjU3NTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9665750?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/viadea",
            "html_url": "https://github.com/viadea",
            "followers_url": "https://api.github.com/users/viadea/followers",
            "following_url": "https://api.github.com/users/viadea/following{/other_user}",
            "gists_url": "https://api.github.com/users/viadea/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/viadea/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/viadea/subscriptions",
            "organizations_url": "https://api.github.com/users/viadea/orgs",
            "repos_url": "https://api.github.com/users/viadea/repos",
            "events_url": "https://api.github.com/users/viadea/events{/privacy}",
            "received_events_url": "https://api.github.com/users/viadea/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-12-27T19:22:35Z",
        "updated_at": "2023-12-27T19:22:35Z",
        "author_association": "COLLABORATOR",
        "body": "@mattahrens Currently Spark RAPIDS can only support Hive table write when spark.sql.hive.convertMetastoreParquet=true. This is default true as well.\r\nSo if a Spark user disabled spark.sql.hive.convertMetastoreParquet and then above original driver log message will show up.\r\nTo the user, they did not know what parameter to turn on to avoid the CPU fallback. \r\n\r\nThat is why I suggest we should mention spark.sql.hive.convertMetastoreParquet=true in the driver log to make sure user enables this parameter to avoid CPU fallback.\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1870567998/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1870664862",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10045#issuecomment-1870664862",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10045",
        "id": 1870664862,
        "node_id": "IC_kwDOD7z77c5vgBSe",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-12-27T22:26:12Z",
        "updated_at": "2023-12-27T22:26:12Z",
        "author_association": "COLLABORATOR",
        "body": "There are multiple different config settings that go into this on the Spark side.\r\n\r\n`spark.sql.hive.convertMetastoreParquet` and `spark.sql.hive.convertInsertingPartitionedTable` are a few of them. Spark can even throw an exception telling the user to set `spark.sql.hive.convertMetastoreParquet` to false as a work around to potential errors in how Spark tries to determine the write schema. I don't think we want to tell the user to turn any of these configs on, if someone decided that they should be off.\r\n\r\nIn addition to that we would need to replicate the logic in https://github.com/apache/spark/blob/5430c700ba64b07cf0c32b906a3328df8a7bef71/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala#L164-L168 to be able to tell the user what is the correct config to turn on. It might be good to just explain that we cannot support this at this time and leave it at that.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1870664862/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1876201419",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10045#issuecomment-1876201419",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10045",
        "id": 1876201419,
        "node_id": "IC_kwDOD7z77c5v1I_L",
        "user": {
            "login": "viadea",
            "id": 9665750,
            "node_id": "MDQ6VXNlcjk2NjU3NTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9665750?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/viadea",
            "html_url": "https://github.com/viadea",
            "followers_url": "https://api.github.com/users/viadea/followers",
            "following_url": "https://api.github.com/users/viadea/following{/other_user}",
            "gists_url": "https://api.github.com/users/viadea/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/viadea/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/viadea/subscriptions",
            "organizations_url": "https://api.github.com/users/viadea/orgs",
            "repos_url": "https://api.github.com/users/viadea/repos",
            "events_url": "https://api.github.com/users/viadea/events{/privacy}",
            "received_events_url": "https://api.github.com/users/viadea/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-01-04T01:50:16Z",
        "updated_at": "2024-01-04T01:50:16Z",
        "author_association": "COLLABORATOR",
        "body": "I would suggest make this warning message more straightforward. \r\nCurrently it will mention:\r\n1. unsupported output-format found: Some(org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat)\r\n2. writing Hive delimited text tables has been disabled, to enable this, set spark.rapids.sql.format.hive.text.write.enabled to true;\r\n3. unsupported serde found: Some(org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe), only org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe is currently supported\r\n\r\nIt might be confusing to customer on what parameter needs to be turned on. Such as user might blindly enable `spark.rapids.sql.format.hive.text.write.enabled=true` but actually the parameter is unrelated.\r\n\r\nI think based on my experience, there are only below possibilities:\r\na. It is a Hive parquet table but user disabled `spark.sql.hive.convertMetastoreParquet ` or some other Spark parameter as @revans2  mentioned;\r\nb. It is a Hive parquet table but user customized Spark so that it somehow could not be translated into a Spark native parque write.\r\nc. It is a Hive Text table. (Which means setting `spark.rapids.sql.format.hive.text.write.enabled=true` is the right solution)\r\n\r\nNot sure if our plugin can firstly detect the Hive formats(based on serde) and then show the message accordingly based on a, b, c possibilities? (I know #b is hard, but at least distinguish a and c is doable? )\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1876201419/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]