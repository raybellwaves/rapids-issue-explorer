[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/708506298",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/946#issuecomment-708506298",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/946",
        "id": 708506298,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcwODUwNjI5OA==",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-10-14T16:12:07Z",
        "updated_at": "2020-10-14T16:12:07Z",
        "author_association": "COLLABORATOR",
        "body": "Sadly we don't have a great way to do it right now.  \r\n\r\nNormally you could look at the GPU itself but because we use a pooling memory manager (RMM) the amount used is hidden because we have allocated a large block of memory up front.\r\n\r\nFor some operators we have a peak memory metric, but it just tells you about a single task not the actual state of the GPU and it is mostly looking at the inputs and output it does not tell how much memory is being used by the algorithm itself.\r\n\r\nWe could have visibility into exactly how much memory is being requested at any point in time by way of intercepting calls to the pooling memory manager, but have no easy way in Spark to export that data. We really just use it right now to see if we should try and free up memory to allow an allocation to succeed. Even then we do not know how fragmented the memory is.\r\n\r\n@jlowe @tgravescs did I miss anything?",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/708506298/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/708553678",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/946#issuecomment-708553678",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/946",
        "id": 708553678,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcwODU1MzY3OA==",
        "user": {
            "login": "jlowe",
            "id": 1360766,
            "node_id": "MDQ6VXNlcjEzNjA3NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1360766?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jlowe",
            "html_url": "https://github.com/jlowe",
            "followers_url": "https://api.github.com/users/jlowe/followers",
            "following_url": "https://api.github.com/users/jlowe/following{/other_user}",
            "gists_url": "https://api.github.com/users/jlowe/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jlowe/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jlowe/subscriptions",
            "organizations_url": "https://api.github.com/users/jlowe/orgs",
            "repos_url": "https://api.github.com/users/jlowe/repos",
            "events_url": "https://api.github.com/users/jlowe/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jlowe/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-10-14T17:37:08Z",
        "updated_at": "2020-10-14T17:37:08Z",
        "author_association": "MEMBER",
        "body": "Agree with @revans2 there isn't a great way to do it today.\r\n\r\nWe're already hooked into most GPU allocations via a custom RMM memory handler used for JVM callbacks on OOM, so tracking total allocated RMM memory from the pool would be very straightforward (albeit with no information on pool fragmentation).  However reporting this via Spark metrics in a useful way is unclear.  This seems to be ideally an executor metric reporting peak GPU memory, but I believe Spark's executor metrics are a fixed set and not extensible to cover concepts like GPU memory.  We may want to propose an Apache Spark feature to make executor metrics extensible by plugins, but that is probably not a simple, straightforward task.\r\n\r\nThat leaves us with task/SQL metrics.  We could track the maximum RMM pool allocation level, getting and resetting this max level atomically when a task completes.  Then at least one task will show the true maximum RMM pool memory used. However this gets a bit less useful when using the RAPIDS shuffle manager which caches shuffle outputs in GPU memory, as some of the GPU memory used and \"charged\" to a particular task/stage could have been produced in an earlier stage or even by an unrelated job.  In that case it may be useful for a task SQL metric to report both peak total RMM pool usage and peak spillable GPU memory usage, although even with those two metrics one can't assume both peaks were achieved at the same time.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/708553678/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/708564889",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/946#issuecomment-708564889",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/946",
        "id": 708564889,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcwODU2NDg4OQ==",
        "user": {
            "login": "abellina",
            "id": 1901059,
            "node_id": "MDQ6VXNlcjE5MDEwNTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1901059?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abellina",
            "html_url": "https://github.com/abellina",
            "followers_url": "https://api.github.com/users/abellina/followers",
            "following_url": "https://api.github.com/users/abellina/following{/other_user}",
            "gists_url": "https://api.github.com/users/abellina/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abellina/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abellina/subscriptions",
            "organizations_url": "https://api.github.com/users/abellina/orgs",
            "repos_url": "https://api.github.com/users/abellina/repos",
            "events_url": "https://api.github.com/users/abellina/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abellina/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-10-14T17:57:05Z",
        "updated_at": "2020-10-14T17:57:30Z",
        "author_association": "COLLABORATOR",
        "body": "On executor metrics, we can add metrics via the metrics registry in the executor. The registry is available via the `SparkEnv`. These are reported using the standard codahale metrics system, so it's not something that shows up in the UI, but can be piped to CSV at least with a Console sink, Prometheus, or other sinks as well.\r\n\r\nI am working on a change to add some metrics for shuffle, but not for GPU memory metrics. If @jlowe @revans2 think this would be a good idea perhaps we can add pool memory usage to these metrics.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/708564889/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/708568475",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/946#issuecomment-708568475",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/946",
        "id": 708568475,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcwODU2ODQ3NQ==",
        "user": {
            "login": "jlowe",
            "id": 1360766,
            "node_id": "MDQ6VXNlcjEzNjA3NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1360766?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jlowe",
            "html_url": "https://github.com/jlowe",
            "followers_url": "https://api.github.com/users/jlowe/followers",
            "following_url": "https://api.github.com/users/jlowe/following{/other_user}",
            "gists_url": "https://api.github.com/users/jlowe/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jlowe/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jlowe/subscriptions",
            "organizations_url": "https://api.github.com/users/jlowe/orgs",
            "repos_url": "https://api.github.com/users/jlowe/repos",
            "events_url": "https://api.github.com/users/jlowe/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jlowe/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-10-14T18:03:08Z",
        "updated_at": "2020-10-14T18:03:08Z",
        "author_association": "MEMBER",
        "body": "> These are reported using the standard codahale metrics system, so it's not something that shows up in the UI\r\n\r\nYes, sorry, I was referring to the UI.  We can definitely report custom executor metrics, but if they are not available in the standard Spark web UI and eventlog then IMHO the utility in practice is significantly diminished.  I agree that having _some_ way to get the metrics beats nothing. :smile:",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/708568475/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]