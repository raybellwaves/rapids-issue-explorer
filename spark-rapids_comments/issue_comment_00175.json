[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/644275338",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/175#issuecomment-644275338",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/175",
        "id": 644275338,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY0NDI3NTMzOA==",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-06-15T17:43:41Z",
        "updated_at": "2020-06-15T17:43:41Z",
        "author_association": "COLLABORATOR",
        "body": "I think a part of this is going to be making our code work with stage level scheduling.  It is simple to say if the entire job needs GPUs or not, but on the GPU side we need to make sure that the operators can tell spark for each stage that we translated something to the GPU that it is needed.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/644275338/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/675706192",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/175#issuecomment-675706192",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/175",
        "id": 675706192,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY3NTcwNjE5Mg==",
        "user": {
            "login": "sameerz",
            "id": 7036315,
            "node_id": "MDQ6VXNlcjcwMzYzMTU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7036315?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sameerz",
            "html_url": "https://github.com/sameerz",
            "followers_url": "https://api.github.com/users/sameerz/followers",
            "following_url": "https://api.github.com/users/sameerz/following{/other_user}",
            "gists_url": "https://api.github.com/users/sameerz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sameerz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sameerz/subscriptions",
            "organizations_url": "https://api.github.com/users/sameerz/orgs",
            "repos_url": "https://api.github.com/users/sameerz/repos",
            "events_url": "https://api.github.com/users/sameerz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sameerz/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-08-18T20:39:23Z",
        "updated_at": "2020-08-18T20:39:23Z",
        "author_association": "COLLABORATOR",
        "body": "After discussion, the right thing to do is create an example where we can demonstrate running an ETL job with the plugin and then in a subsequent stage running still on the GPU but without the plugin.  For example, an ETL job followed by an XGBoost job reading from Parquet files.  In between stages the configuration of the executors will change.    \r\n\r\nThis can then be turned into a test case.  ",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/675706192/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]