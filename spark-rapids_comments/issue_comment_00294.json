[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/650373367",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/294#issuecomment-650373367",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/294",
        "id": 650373367,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY1MDM3MzM2Nw==",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-06-26T20:02:46Z",
        "updated_at": "2020-06-26T20:02:46Z",
        "author_association": "COLLABORATOR",
        "body": "I filed https://issues.apache.org/jira/browse/SPARK-32110 to document what I have found in spark.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/650373367/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/653216189",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/294#issuecomment-653216189",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/294",
        "id": 653216189,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY1MzIxNjE4OQ==",
        "user": {
            "login": "mythrocks",
            "id": 5607330,
            "node_id": "MDQ6VXNlcjU2MDczMzA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5607330?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mythrocks",
            "html_url": "https://github.com/mythrocks",
            "followers_url": "https://api.github.com/users/mythrocks/followers",
            "following_url": "https://api.github.com/users/mythrocks/following{/other_user}",
            "gists_url": "https://api.github.com/users/mythrocks/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mythrocks/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mythrocks/subscriptions",
            "organizations_url": "https://api.github.com/users/mythrocks/orgs",
            "repos_url": "https://api.github.com/users/mythrocks/repos",
            "events_url": "https://api.github.com/users/mythrocks/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mythrocks/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-07-02T20:55:04Z",
        "updated_at": "2020-07-02T20:55:04Z",
        "author_association": "COLLABORATOR",
        "body": "Some findings when compared against Apache Hive 3.x:\r\n\r\n1. Literals: Both Hive CLI and SparkSQL treat the literals `0.0` and `-0.0` as equivalent. i.e. `0.0 = -0.0 `is `TRUE`. `SELECT 0.0 as a, -0.0 as b` selects `0.0` and `0.0`.\r\n1. From data sources/files: The Spark REPL (and Scala, I\u2019m guessing) treat the same literals as distinct. We can use this to write `-0.0` into a file. E.g. `Seq((-0.0, 0.0)).toDF.write.orc()` writes distinct values.\r\n1. Equi-join: Hive 3 does not normalize float/double. Joining `0.0` and `-0.0` from ORC-file sources does not match rows. Spark normalizes, and thus matches.\r\n1. Inequality joins: Both Hive 3 and SparkSQL 3 matches on `-0.0` < `0.0`. This is because neither normalizes on non-equijoins.\r\n\r\nSo in this regard, the only material difference between Hive and SparkSQL is that on equijoins, Hive does not normalize, and treats `-0.0` as distinct from `0.0`. It is consistent(ly wrong?) within itself. Spark normalizes, but only for equijoin.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/653216189/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/732301313",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/294#issuecomment-732301313",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/294",
        "id": 732301313,
        "node_id": "MDEyOklzc3VlQ29tbWVudDczMjMwMTMxMw==",
        "user": {
            "login": "revans2",
            "id": 3441321,
            "node_id": "MDQ6VXNlcjM0NDEzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3441321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revans2",
            "html_url": "https://github.com/revans2",
            "followers_url": "https://api.github.com/users/revans2/followers",
            "following_url": "https://api.github.com/users/revans2/following{/other_user}",
            "gists_url": "https://api.github.com/users/revans2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revans2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revans2/subscriptions",
            "organizations_url": "https://api.github.com/users/revans2/orgs",
            "repos_url": "https://api.github.com/users/revans2/repos",
            "events_url": "https://api.github.com/users/revans2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revans2/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-23T17:15:14Z",
        "updated_at": "2020-11-23T17:15:14Z",
        "author_association": "COLLABORATOR",
        "body": "I filed https://github.com/rapidsai/cudf/issues/6834 in cudf so we can work around things with bit-wise operations if possible. I believe that we should be able to make comparisons and sort match exactly with Spark.  On joins we are going to have a much harder time, but we still might be able to do it.  We need to be very careful with this though.  -0.0 and the various NaN values are rather rare in real life. I am not sure if it is worth the added performance cost for sort to do this, and the join I am especially concerned about what it would take to make it work.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/732301313/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]