[
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1871748626",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10062#issuecomment-1871748626",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10062",
        "id": 1871748626,
        "node_id": "IC_kwDOD7z77c5vkJ4S",
        "user": {
            "login": "abellina",
            "id": 1901059,
            "node_id": "MDQ6VXNlcjE5MDEwNTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1901059?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abellina",
            "html_url": "https://github.com/abellina",
            "followers_url": "https://api.github.com/users/abellina/followers",
            "following_url": "https://api.github.com/users/abellina/following{/other_user}",
            "gists_url": "https://api.github.com/users/abellina/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abellina/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abellina/subscriptions",
            "organizations_url": "https://api.github.com/users/abellina/orgs",
            "repos_url": "https://api.github.com/users/abellina/repos",
            "events_url": "https://api.github.com/users/abellina/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abellina/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2023-12-29T05:54:57Z",
        "updated_at": "2023-12-29T05:54:57Z",
        "author_association": "COLLABORATOR",
        "body": "Also fails with `DATAGEN_SEED=1703803344` as CI just showed here https://github.com/NVIDIA/spark-rapids/pull/10109. I am adding a temporary seed=0 override.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1871748626/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1918665956",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10062#issuecomment-1918665956",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10062",
        "id": 1918665956,
        "node_id": "IC_kwDOD7z77c5yXITk",
        "user": {
            "login": "thirtiseven",
            "id": 7326403,
            "node_id": "MDQ6VXNlcjczMjY0MDM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7326403?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thirtiseven",
            "html_url": "https://github.com/thirtiseven",
            "followers_url": "https://api.github.com/users/thirtiseven/followers",
            "following_url": "https://api.github.com/users/thirtiseven/following{/other_user}",
            "gists_url": "https://api.github.com/users/thirtiseven/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thirtiseven/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thirtiseven/subscriptions",
            "organizations_url": "https://api.github.com/users/thirtiseven/orgs",
            "repos_url": "https://api.github.com/users/thirtiseven/repos",
            "events_url": "https://api.github.com/users/thirtiseven/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thirtiseven/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-01-31T08:59:47Z",
        "updated_at": "2024-01-31T09:13:09Z",
        "author_association": "COLLABORATOR",
        "body": "This issue is quite weird to me, here is what I know about it now:\r\n\r\n**repro**\r\nMany thing in this test is irrelevant to repro this failure, like the type of agg functions, configs, incompat and approximate_float marks, here is a minimal repro:\r\n```python\r\n@ignore_order(local=True)\r\ndef test_hash_multiple_grpby_pivot():\r\n    assert_gpu_and_cpu_are_equal_collect(\r\n        lambda spark: gen_df(spark, [('a', LongGen()), ('b', IntegerGen()), ('c', LongGen())], length=100)\r\n            .groupby('a','b')\r\n            .pivot('b')\r\n            .agg(f.count('c'), f.max('c')))\r\n```\r\nAnd many other things seem to be required to reproduce this failure, like the length of the data (around 100), the number of group by keys (2) , and the number of agg functions (2) .\r\n\r\nI tried to find a repro with shorter/simpler data to find a pattern in the data that could lead to this failure, but I failed to find one.\r\n\r\n**failure**\r\n\r\nThe test failed because the second group by key \"b\" is wrong in the result, most of the values are 0 in the gpu result, but they are not in the cpu result.\r\n\r\n```\r\nRow(a=-9223372036854775808, b=0, null_count(c)=None, null_max(c)=None, -2147483648_count(c)=None, ...\r\nRow(a=-9223372036854775808, b=0, null_count(c)=None, null_max(c)=None, -2147483648_count(c)=None, ...\r\nRow(a=-9223372036854775808, b=167810688, null_count(c)=None, null_max(c)=None, -2147483648_count(c)=None, ...\r\nRow(a=-9018433402683060375, b=0, null_count(c)=None, null_max(c)=None, -2147483648_count(c)=None, ...\r\n......\r\n```\r\n\r\n**different results and plans for different test methods**\r\n\r\nAn interesting thing is that if you run the data with `collect` or `take` method, the result is wrong, but if you run it with `show` method, the result is correct.\r\n\r\nThe plan for them are also slightly different, the main difference is:\r\n\r\ntake(1000):\r\n```\r\n......\r\n24/01/31 11:47:50 WARN GpuOverrides:\r\n!Exec <CollectLimitExec> cannot run on GPU because the Exec CollectLimitExec has been disabled, and is disabled by default because Collect Limit replacement can be slower on the GPU, if huge number of rows in a batch it could help by limiting the number of rows transferred from GPU to CPU. Set spark.rapids.sql.exec.CollectLimitExec to true if you wish to enable it\r\n  @Partitioning <SinglePartition$> could run on GPU\r\n  *Exec <ProjectExec> will run on GPU\r\n    *Expression <Alias> __pivot_count(c) AS `count(c)`#209[0] AS null_count(c)#402L will run on GPU\r\n      *Expression <GetArrayItem> __pivot_count(c) AS `count(c)`#209[0] will run on GPU\r\n    *Expression <Alias> __pivot_max(c) AS `max(c)`#401[0] AS null_max(c)#403L will run on GPU\r\n      *Expression <GetArrayItem> __pivot_max(c) AS `max(c)`#401[0] will run on GPU\r\n    *Expression <Alias> __pivot_count(c) AS `count(c)`#209[1] AS -2147483648_count(c)#404L will run on GPU\r\n      *Expression <GetArrayItem> __pivot_count(c) AS `count(c)`#209[1] will run on GPU\r\n......\r\n```\r\n\r\nshow:\r\n```\r\n......\r\n24/01/30 18:25:40 WARN GpuOverrides:\r\n!Exec <CollectLimitExec> cannot run on GPU because the Exec CollectLimitExec has been disabled, and is disabled by default because Collect Limit replacement can be slower on the GPU, if huge number of rows in a batch it could help by limiting the number of rows transferred from GPU to CPU. Set spark.rapids.sql.exec.CollectLimitExec to true if you wish to enable it\r\n  @Partitioning <SinglePartition$> could run on GPU\r\n  *Exec <ProjectExec> will run on GPU\r\n    *Expression <Alias> cast(a#0L as string) AS a#1356 will run on GPU\r\n      *Expression <Cast> cast(a#0L as string) will run on GPU\r\n    *Expression <Alias> cast(b#1 as string) AS b#1357 will run on GPU\r\n      *Expression <Cast> cast(b#1 as string) will run on GPU\r\n    *Expression <Alias> cast(__pivot_count(c) AS `count(c)`#209[0] as string) AS null_count(c)#1358 will run on GPU\r\n      *Expression <Cast> cast(__pivot_count(c) AS `count(c)`#209[0] as string) will run on GPU\r\n        *Expression <GetArrayItem> __pivot_count(c) AS `count(c)`#209[0] will run on GPU\r\n    *Expression <Alias> cast(__pivot_max(c) AS `max(c)`#401[0] as string) AS null_max(c)#1359 will run on GPU\r\n      *Expression <Cast> cast(__pivot_max(c) AS `max(c)`#401[0] as string) will run on GPU\r\n        *Expression <GetArrayItem> __pivot_max(c) AS `max(c)`#401[0] will run on GPU\r\n......\r\n```\r\n\r\nThere is a `Cast` node in the plan for the `show` method, but not for the `take` method, I'm not sure if this is the reason for the different results.\r\n\r\nAlso, the results for `take` are not always the same every time. It will produce different and wrong results with same data.\r\n\r\nHere is the script I used to run the test:\r\n\r\n```python\r\nfrom pyspark.sql.types import *\r\n\r\nimport pyspark.sql.functions as f\r\n\r\ndata = [(-4845943781170555252, -1, 845188426061929355), (7350351203911181009, -1834450793, -8329883561935981210), (-6474373677523860195, -199278150, 9152903973058550378), (-3932771648075861385, -1678969406, 598714061780169842), (None, 801881452, -4466412165968923070), (-3652577983080905586, 1540102964, 47268640572211013), (4545717671238472990, 1947938927, None), (-8298661160006568201, None, 6854480935057369726), (-7616214595191846290, -1949955096, 0), (-7289328883642000118, 272299328, 2884476978744622358), (None, 1160260740, -6052237597774996739), (-9223372036854775808, -493879135, 6203771033123822312), (-6614098684129949450, -584802307, -3071555407446211853), (-9003145117425481384, -757788614, 7929562070840347149), (-9223372036854775808, -228071647, 2906400750731819474), (5732395791703362947, -2147483648, -3970425384979120781), (-1564274735105258826, 996967482, -1484437957559815242), (5526867606258508741, -1575882867, 6239854566349019265), (-9223372036854775808, -334761671, -4112306351109120101), (4244671825864794863, 981450318, 7465382293241571108), (-448440415840524957, 394207378, None), (-4073146087272737548, 208913219, 2562680179324889398), (-7321272388955223843, 732061080, -5794879109021556367), (860502963007932720, 1402155938, -3954084267791354691), (-4821486473017204446, 1315353396, 1347206884473686984), (3016210088861611029, -1456892421, 3583186219866217910), (-8846374268221322244, 0, -6858830960164213997), (-518664528608335071, -1268577466, 5720376452508829361), (2586987693939428128, -1968521231, 4186863789914269115), (4315088642471474100, -318667079, None), (-5113086506103862658, 1192991751, 3739428740990641749), (-2120010059318291246, -140200524, -3868910921495005039), (6836723189324294794, -1441161803, 9145430657210176353), (-3404440819830080875, 311543893, -2121016320289730914), (-8267335710692130228, 101892561, -7989940178650011946), (-154826107042624785, -1805786100, 167944445750808798), (4310854391155890700, 1025117499, 8102289978239659013), (3691614150816130938, -1222608032, 0), (-4898102975906729231, 1206436070, -1156663457190611290), (5780839774576522093, -938054806, 215654183084134840), (-3990677385327099340, -60005380, 2446406909182780340), (3558684623224462755, 1100654780, -3561235334131684560), (None, 598840759, 6880829832614805175), (2587651536519945797, -848441474, -8944550910905869417), (None, -1867029195, 7292092528479130246), (6483492345442125574, 1423197063, -7562444454753075438), (-309680615801512125, 635403706, None), (-2660137861258255564, -1580709119, -1317365564804702773), (-4805714711362703732, 1977765468, 5355716940028229540), (806134238988331049, -21753199, -5982077157730834146), (-2320179344785250342, 915815532, -924102870416173362), (None, -1638025670, None), (-5335012076263087262, 998390663, 7614229944302801432), (-8003442832786541311, 895630555, 1), (8962746789636867990, None, 7838149056358927259), (-3474654754894809539, None, 3134278270126018378), (-8855593812501704849, 2054085988, 2855154093732021075), (-7091849916600089089, None, -6417530363343090288), (-222013359233028811, -1006587236, 5138405147626324023), (6147863345995281135, -1343496055, -5605747624660684039), (2412508725397414376, 1750760724, 0), (6746130822817653164, 1119642812, 4321955607259744754), (-4522555907557220644, 747294963, 1902336294480137280), (-7124479271795897431, 618657031, -6384732039486542304), (-3016538980443125232, -971305592, 5961924950591751584), (36773415627206426, 1566835821, 3212457428261779419), (-3760560561437195364, -380125779, 4269719979332759241), (-4248829775503459426, 1070853851, 3760713768439915058), (-5923932160264549958, 1594768906, -393161711644537657), (1157815137441274869, 2084691734, -7858213111740624985), (-2199684093812713901, 11523829, -1594686429977057152), (0, -814837712, 4596534695065757359), (-3849151964918279414, -68879409, 5986326621238269570), (-7398018555027505285, -1631793792, -3473982566533875127), (4932966234951301523, 736936302, -4363781202623852301), (-3580853073542804157, -883765153, 8365114787068696630), (-50917646897929622, 1826610949, 8079244073851440946), (-3677281010338202811, 1360663342, 1990897617129644958), (5462740808011170473, 361204030, None), (None, -158654865, 8715253034384927926), (-4823423393556183648, 1863243438, -4120580680305907585), (-2094967163472758289, 1746245479, 4379449978340264045), (-7317633614294497645, 1126381026, -4684053213402982061), (1038911458266308727, -731208496, -1357558607203886826), (6238027844923655492, None, -1365950448597480252), (-463854078867593653, -1770484043, -6170126774260820756), (7022405428698357996, 1047662067, -6459373991120808345), (3224891226649524714, 85681293, 1), (1497870743195662602, -225772735, 6706375643237237900), (-2270318763267742179, -1246742999, -7480138770689422386), (-1, -1221487735, 7193799890519656756), (9033902131006707423, 1313705388, None), (9074230953825881152, -1378244309, -3631319698309137830), (-1227617950894814242, 88538877, 8888801943813690819), (-4943246025205215864, -820790410, 6939343468978651959), (4655205048401744152, -1202186285, 8659688436647848697), (-9018433402683060375, 865863905, 57130699251065081), (6984748109983071784, 0, 5106579162908166122), (None, 857006179, -783620458450576957), (-3380402600221637564, -1832167886, -4323246307621457475)]\r\n\r\nschema = StructType([StructField('a', LongType(), True), StructField('b', IntegerType(), True), StructField('c', LongType(), True)])\r\n\r\ndf = spark.createDataFrame(data, schema)\r\n\r\n# collect or take, wrong and unstable results\r\n\r\ncollect = df.groupby('a','b').pivot('b').agg(f.count('c'), f.max('c')).take(1000)\r\n\r\nfor row in collect:\r\n    print(row)\r\n\r\n# show, correct results\r\n\r\ndf.groupby('a','b').pivot('b').agg(f.count('c'), f.max('c')).show(1000, False)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1918665956/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1970726606",
        "html_url": "https://github.com/NVIDIA/spark-rapids/issues/10062#issuecomment-1970726606",
        "issue_url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/10062",
        "id": 1970726606,
        "node_id": "IC_kwDOD7z77c51dubO",
        "user": {
            "login": "thirtiseven",
            "id": 7326403,
            "node_id": "MDQ6VXNlcjczMjY0MDM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7326403?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thirtiseven",
            "html_url": "https://github.com/thirtiseven",
            "followers_url": "https://api.github.com/users/thirtiseven/followers",
            "following_url": "https://api.github.com/users/thirtiseven/following{/other_user}",
            "gists_url": "https://api.github.com/users/thirtiseven/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thirtiseven/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thirtiseven/subscriptions",
            "organizations_url": "https://api.github.com/users/thirtiseven/orgs",
            "repos_url": "https://api.github.com/users/thirtiseven/repos",
            "events_url": "https://api.github.com/users/thirtiseven/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thirtiseven/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2024-02-29T09:20:17Z",
        "updated_at": "2024-02-29T09:22:08Z",
        "author_association": "COLLABORATOR",
        "body": "Seems not to be a bug in `PivotFirst` or `AggregateExpression`, the test still fails when them are disabled.\r\n\r\nNow I think it is an issue from `GetArrayItem` because when I disabled it by setting `spark.rapids.sql.expression.GetArrayItem` to false, the test passed.",
        "reactions": {
            "url": "https://api.github.com/repos/NVIDIA/spark-rapids/issues/comments/1970726606/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]