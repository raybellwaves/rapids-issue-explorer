{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORORG = \"rapidsai\"\n",
    "REPO = \"cudf\"\n",
    "BOTS = [\"dependabot[bot]\", \"GPUtester\", \"github-actions[bot]\"]\n",
    "import os  # noqa: E402\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "repo: str = REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import pandas as pd\n",
    "    from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "    from langchain_openai import OpenAI as OpenAI_langchain\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from pymilvus import MilvusClient\n",
    "\n",
    "    df_issues = pd.read_parquet(f\"{repo}_issue_summary.parquet\")\n",
    "    # drop the issue_text column as context is too large for agent\n",
    "    # we will use the vector database instead\n",
    "    df_issues = df_issues.drop(\n",
    "        columns=[\n",
    "            \"issue_text\",\n",
    "            \"LLM_title_subject\",\n",
    "            \"label_names\",\n",
    "            \"issue_text_tokens\",\n",
    "            \"issue_created_at\",\n",
    "            \"issue_updated_at\",\n",
    "            \"issue_reactions.+1\",\n",
    "            \"issue_reactions.-1\",\n",
    "            \"issue_reactions.laugh\",\n",
    "            \"issue_reactions.hooray\",\n",
    "            \"issue_reactions.confused\",\n",
    "            \"issue_reactions.heart\",\n",
    "            \"issue_reactions.rocket\",\n",
    "            \"issue_reactions.eyes\",\n",
    "            \"issue_user.login_location_lat\",\n",
    "            \"issue_user.login_location_lon\",\n",
    "        ]\n",
    "    )\n",
    "    # Create simple column names to help the agent\n",
    "    df_issues = df_issues.rename(\n",
    "        columns={\n",
    "            \"number\": f\"{repo}_issue_number\",\n",
    "            \"title\": f\"{repo}_issue_title\",\n",
    "            \"author_association\": f\"association_to_{repo}\",\n",
    "            \"issue_reactions.total_count\": \"number_of_reactions_on_issue\",\n",
    "            \"n_comments\": \"number_of_comments\",\n",
    "            \"issue_user.login_email\": \"email\",\n",
    "            \"issue_user.login_name\": \"name\",\n",
    "            \"issue_user.login_company\": \"company\",\n",
    "            \"issue_user.login_name_company\": \"name_company\",\n",
    "            \"issue_user.login_location\": \"location\",\n",
    "            \"issue_user.login_followers\": \"github_followers\",\n",
    "            \"comment_reactions.total_count\": \"number_of_reactions_on_comments\",\n",
    "        }\n",
    "    )\n",
    "    print(df_issues[\"company\"].value_counts())\n",
    "    agent = create_pandas_dataframe_agent(\n",
    "        OpenAI_langchain(\n",
    "            temperature=0,\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            openai_api_key=OPENAI_API_KEY,\n",
    "        ),\n",
    "        df_issues,\n",
    "        verbose=True,\n",
    "    )\n",
    "    print(df_issues[df_issues[\"company\"] == \"Walmart\"])\n",
    "    response = agent_response(agent, \"What issues are Walmart most interested in?\")\n",
    "    print(response)\n",
    "    if \":\" in response:\n",
    "        response = response.split(\":\")[1].strip()\n",
    "\n",
    "    question = f\"What issues are similar to {response}?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"What issues are similar to {response}?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    question_embeddings = embeddings_model.embed_documents([question])\n",
    "    client = MilvusClient(f\"./milvus_{repo}.db\")\n",
    "    res = client.search(\n",
    "        collection_name=\"issue_text\",\n",
    "        data=question_embeddings,\n",
    "        limit=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.search(\n",
    "    collection_name=\"issue_text\",\n",
    "    data=question_embeddings,\n",
    "    limit=2,\n",
    ")\n",
    "similar_issue_1 = res[0][0][\"id\"]\n",
    "similar_issue_2 = res[0][1][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issues[df_issues[f\"{repo}_issue_number\"] == similar_issue_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issues[df_issues[f\"{repo}_issue_number\"] == similar_issue_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
